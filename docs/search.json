[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hyeun-Wook Oh",
    "section": "",
    "text": "Hyeun-Wook Oh(a.k.a. yongraegod) is a person who is interested in studying Big data analysis and National health insurance service.\n\n \n  \n   \n  \n    \n     GitHub\n  \n  \n    \n     네이버 Blog\n  \n  \n    \n     Instagram\n  \n  \n    \n     Email"
  },
  {
    "objectID": "hw1.html",
    "href": "hw1.html",
    "title": "hw1",
    "section": "",
    "text": "#!pip install pandas\nimport pandas as pd\n\ndf = pd.DataFrame({\"제품\"   : [\"사과\",\"딸기\",\"수박\"],\n                   \"가격\"   : [1800, 1500, 3000],\n                   \"판매량\" : [24, 38, 13]})\ndf\n\n\n\n\n\n\n\n\n제품\n가격\n판매량\n\n\n\n\n0\n사과\n1800\n24\n\n\n1\n딸기\n1500\n38\n\n\n2\n수박\n3000\n13\n\n\n\n\n\n\n\n\n\n\n\n\nprice_avg = sum(df[\"가격\"]) / 3\nvol_avg = sum(df[\"판매량\"]) / 3\n\nprint(\"과일 가격의 평균은\", price_avg)\nprint(\"과일 판매량의 평균은\", vol_avg)\n\n과일 가격의 평균은 2100.0\n과일 판매량의 평균은 25.0"
  },
  {
    "objectID": "hw1.html#다음-표의-내용을-데이터-프레임으로-만들어-출력해-보세요.",
    "href": "hw1.html#다음-표의-내용을-데이터-프레임으로-만들어-출력해-보세요.",
    "title": "hw1",
    "section": "",
    "text": "#!pip install pandas\nimport pandas as pd\n\ndf = pd.DataFrame({\"제품\"   : [\"사과\",\"딸기\",\"수박\"],\n                   \"가격\"   : [1800, 1500, 3000],\n                   \"판매량\" : [24, 38, 13]})\ndf\n\n\n\n\n\n\n\n\n제품\n가격\n판매량\n\n\n\n\n0\n사과\n1800\n24\n\n\n1\n딸기\n1500\n38\n\n\n2\n수박\n3000\n13\n\n\n\n\n\n\n\n\nsum(df[\"가격\"]) / 3\nsum(df[\"판매량\"]) / 3\n\n25.0"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About me"
  },
  {
    "objectID": "hw1.html#숙제하기",
    "href": "hw1.html#숙제하기",
    "title": "hw1",
    "section": "",
    "text": "#!pip install pandas\nimport pandas as pd\n\ndf = pd.DataFrame({\"제품\"   : [\"사과\",\"딸기\",\"수박\"],\n                   \"가격\"   : [1800, 1500, 3000],\n                   \"판매량\" : [24, 38, 13]})\ndf\n\n\n\n\n\n\n\n\n제품\n가격\n판매량\n\n\n\n\n0\n사과\n1800\n24\n\n\n1\n딸기\n1500\n38\n\n\n2\n수박\n3000\n13\n\n\n\n\n\n\n\n\n\n\n\nsum(df[\"가격\"]) / 3\nsum(df[\"판매량\"]) / 3\n\n25.0"
  },
  {
    "objectID": "hw1.html#숙제해라-공부해라",
    "href": "hw1.html#숙제해라-공부해라",
    "title": "hw1",
    "section": "",
    "text": "#!pip install pandas\nimport pandas as pd\n\ndf = pd.DataFrame({\"제품\"   : [\"사과\",\"딸기\",\"수박\"],\n                   \"가격\"   : [1800, 1500, 3000],\n                   \"판매량\" : [24, 38, 13]})\ndf\n\n\n\n\n\n\n\n\n제품\n가격\n판매량\n\n\n\n\n0\n사과\n1800\n24\n\n\n1\n딸기\n1500\n38\n\n\n2\n수박\n3000\n13\n\n\n\n\n\n\n\n\n\n\n\nprice_avg = sum(df[\"가격\"]) / 3\nvol_avg = sum(df[\"판매량\"]) / 3\n\nprint(\"과일 가격의 평균은\", price_avg)\nprint(\"과일 판매량의 평균은\", vol_avg)\n\n과일 가격의 평균은 2100.0\n과일 판매량의 평균은 25.0\n\n\n\n\n\n\n\n# mpg 데이터 불러오기\nmpg_raw = pd.read_csv('C:/Users/USER/Documents/LS빅데이터스쿨/lsbigdata-project1/data/mpg.csv')\nmpg_new = mpg_raw.copy()\nmpg_new\n\n\n\n\n\n\n\n\nmanufacturer\nmodel\ndispl\nyear\ncyl\ntrans\ndrv\ncty\nhwy\nfl\ncategory\n\n\n\n\n0\naudi\na4\n1.8\n1999\n4\nauto(l5)\nf\n18\n29\np\ncompact\n\n\n1\naudi\na4\n1.8\n1999\n4\nmanual(m5)\nf\n21\n29\np\ncompact\n\n\n2\naudi\na4\n2.0\n2008\n4\nmanual(m6)\nf\n20\n31\np\ncompact\n\n\n3\naudi\na4\n2.0\n2008\n4\nauto(av)\nf\n21\n30\np\ncompact\n\n\n4\naudi\na4\n2.8\n1999\n6\nauto(l5)\nf\n16\n26\np\ncompact\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n229\nvolkswagen\npassat\n2.0\n2008\n4\nauto(s6)\nf\n19\n28\np\nmidsize\n\n\n230\nvolkswagen\npassat\n2.0\n2008\n4\nmanual(m6)\nf\n21\n29\np\nmidsize\n\n\n231\nvolkswagen\npassat\n2.8\n1999\n6\nauto(l5)\nf\n16\n26\np\nmidsize\n\n\n232\nvolkswagen\npassat\n2.8\n1999\n6\nmanual(m5)\nf\n18\n26\np\nmidsize\n\n\n233\nvolkswagen\npassat\n3.6\n2008\n6\nauto(s6)\nf\n17\n26\np\nmidsize\n\n\n\n\n234 rows × 11 columns\n\n\n\n\n\n\n\n#cty -&gt; city\nmpg_new = mpg_new.rename(columns = {'cty' : 'city'})\n\n#hwy -&gt; highway\nmpg_new = mpg_new.rename(columns = {'hwy' : 'highway'})\n\n\n\n\n\nmpg_new.head()\n\n\n\n\n\n\n\n\nmanufacturer\nmodel\ndispl\nyear\ncyl\ntrans\ndrv\ncity\nhighway\nfl\ncategory\n\n\n\n\n0\naudi\na4\n1.8\n1999\n4\nauto(l5)\nf\n18\n29\np\ncompact\n\n\n1\naudi\na4\n1.8\n1999\n4\nmanual(m5)\nf\n21\n29\np\ncompact\n\n\n2\naudi\na4\n2.0\n2008\n4\nmanual(m6)\nf\n20\n31\np\ncompact\n\n\n3\naudi\na4\n2.0\n2008\n4\nauto(av)\nf\n21\n30\np\ncompact\n\n\n4\naudi\na4\n2.8\n1999\n6\nauto(l5)\nf\n16\n26\np\ncompact\n\n\n\n\n\n\n\n\n\n\n\n\n# midwest.csv 데이터 불러오기\nmidwest_raw = pd.read_csv('C:/Users/USER/Documents/LS빅데이터스쿨/lsbigdata-project1/data/midwest.csv')\nmidwest_new = midwest_raw.copy()\nmidwest_new\n\nmidwest_new.head()\nmidwest_new.tail()\nmidwest_new.shape\nmidwest_new.info()\nmidwest_new.describe()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 437 entries, 0 to 436\nData columns (total 28 columns):\n #   Column                Non-Null Count  Dtype  \n---  ------                --------------  -----  \n 0   PID                   437 non-null    int64  \n 1   county                437 non-null    object \n 2   state                 437 non-null    object \n 3   area                  437 non-null    float64\n 4   poptotal              437 non-null    int64  \n 5   popdensity            437 non-null    float64\n 6   popwhite              437 non-null    int64  \n 7   popblack              437 non-null    int64  \n 8   popamerindian         437 non-null    int64  \n 9   popasian              437 non-null    int64  \n 10  popother              437 non-null    int64  \n 11  percwhite             437 non-null    float64\n 12  percblack             437 non-null    float64\n 13  percamerindan         437 non-null    float64\n 14  percasian             437 non-null    float64\n 15  percother             437 non-null    float64\n 16  popadults             437 non-null    int64  \n 17  perchsd               437 non-null    float64\n 18  percollege            437 non-null    float64\n 19  percprof              437 non-null    float64\n 20  poppovertyknown       437 non-null    int64  \n 21  percpovertyknown      437 non-null    float64\n 22  percbelowpoverty      437 non-null    float64\n 23  percchildbelowpovert  437 non-null    float64\n 24  percadultpoverty      437 non-null    float64\n 25  percelderlypoverty    437 non-null    float64\n 26  inmetro               437 non-null    int64  \n 27  category              437 non-null    object \ndtypes: float64(15), int64(10), object(3)\nmemory usage: 95.7+ KB\n\n\n\n\n\n\n\n\n\nPID\narea\npoptotal\npopdensity\npopwhite\npopblack\npopamerindian\npopasian\npopother\npercwhite\n...\nperchsd\npercollege\npercprof\npoppovertyknown\npercpovertyknown\npercbelowpoverty\npercchildbelowpovert\npercadultpoverty\npercelderlypoverty\ninmetro\n\n\n\n\ncount\n437.000000\n437.000000\n4.370000e+02\n437.000000\n4.370000e+02\n4.370000e+02\n437.000000\n437.000000\n437.000000\n437.000000\n...\n437.000000\n437.000000\n437.000000\n4.370000e+02\n437.000000\n437.000000\n437.000000\n437.000000\n437.000000\n437.000000\n\n\nmean\n1437.338673\n0.033169\n9.613030e+04\n3097.742985\n8.183992e+04\n1.102388e+04\n343.109840\n1310.464531\n1612.931350\n95.558441\n...\n73.965546\n18.272736\n4.447259\n9.364228e+04\n97.110267\n12.510505\n16.447464\n10.918798\n11.389043\n0.343249\n\n\nstd\n876.390266\n0.014679\n2.981705e+05\n7664.751786\n2.001966e+05\n7.895827e+04\n868.926751\n9518.394189\n18526.540699\n7.087358\n...\n5.843177\n6.261908\n2.408427\n2.932351e+05\n2.749863\n5.150155\n7.228634\n5.109166\n3.661259\n0.475338\n\n\nmin\n561.000000\n0.005000\n1.701000e+03\n85.050000\n4.160000e+02\n0.000000e+00\n4.000000\n0.000000\n0.000000\n10.694087\n...\n46.912261\n7.336108\n0.520291\n1.696000e+03\n80.902441\n2.180168\n1.918955\n1.938504\n3.547067\n0.000000\n\n\n25%\n670.000000\n0.024000\n1.884000e+04\n622.407407\n1.863000e+04\n2.900000e+01\n44.000000\n35.000000\n20.000000\n94.886032\n...\n71.325329\n14.113725\n2.997957\n1.836400e+04\n96.894572\n9.198715\n11.624088\n7.668009\n8.911763\n0.000000\n\n\n50%\n1221.000000\n0.030000\n3.532400e+04\n1156.208330\n3.447100e+04\n2.010000e+02\n94.000000\n102.000000\n66.000000\n98.032742\n...\n74.246891\n16.797562\n3.814239\n3.378800e+04\n98.169562\n11.822313\n15.270164\n10.007610\n10.869119\n0.000000\n\n\n75%\n2059.000000\n0.038000\n7.565100e+04\n2330.000000\n7.296800e+04\n1.291000e+03\n288.000000\n401.000000\n345.000000\n99.074935\n...\n77.195345\n20.549893\n4.949324\n7.284000e+04\n98.598636\n15.133226\n20.351878\n13.182182\n13.412162\n1.000000\n\n\nmax\n3052.000000\n0.110000\n5.105067e+06\n88018.396600\n3.204947e+06\n1.317147e+06\n10289.000000\n188565.000000\n384119.000000\n99.822821\n...\n88.898674\n48.078510\n20.791321\n5.023523e+06\n99.860384\n48.691099\n64.308477\n43.312464\n31.161972\n1.000000\n\n\n\n\n8 rows × 25 columns\n\n\n\n\n\n\n\n#poptotal -&gt; total\nmidwest_new = midwest_new.rename(columns = {'poptotal' : 'total'})\n\n#popasian -&gt; asian\nmidwest_new = midwest_new.rename(columns = {'popasian' : 'asian'})\n\n\n\n\n\nmidwest_new['a_ratio'] = (midwest_new[\"asian\"] / midwest_new[\"total\"]) * 100\nmidwest_new['a_ratio'].plot.hist()\nimport matplotlib.pyplot as plt\nplt.show()\nplt.clf()\n\n\n\n\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;\n\n\n\n\n\n\nimport numpy as np\n#아시아 인구 백분율 전체 평균\nmidwest_new['a_mean'] = (midwest_new['a_ratio'].mean())\n\n#평균을 초과하는지 비교\nmidwest_new['vs_mean'] = np.where(midwest_new['a_ratio'] &gt; midwest_new['a_mean'], 'large', 'small')\nmidwest_new\n\n\n\n\n\n\n\n\nPID\ncounty\nstate\narea\ntotal\npopdensity\npopwhite\npopblack\npopamerindian\nasian\n...\npercpovertyknown\npercbelowpoverty\npercchildbelowpovert\npercadultpoverty\npercelderlypoverty\ninmetro\ncategory\na_ratio\na_mean\nvs_mean\n\n\n\n\n0\n561\nADAMS\nIL\n0.052\n66090\n1270.961540\n63917\n1702\n98\n249\n...\n96.274777\n13.151443\n18.011717\n11.009776\n12.443812\n0\nAAR\n0.376759\n0.487246\nsmall\n\n\n1\n562\nALEXANDER\nIL\n0.014\n10626\n759.000000\n7054\n3496\n19\n48\n...\n99.087145\n32.244278\n45.826514\n27.385647\n25.228976\n0\nLHR\n0.451722\n0.487246\nsmall\n\n\n2\n563\nBOND\nIL\n0.022\n14991\n681.409091\n14477\n429\n35\n16\n...\n94.956974\n12.068844\n14.036061\n10.852090\n12.697410\n0\nAAR\n0.106731\n0.487246\nsmall\n\n\n3\n564\nBOONE\nIL\n0.017\n30806\n1812.117650\n29344\n127\n46\n150\n...\n98.477569\n7.209019\n11.179536\n5.536013\n6.217047\n1\nALU\n0.486918\n0.487246\nsmall\n\n\n4\n565\nBROWN\nIL\n0.018\n5836\n324.222222\n5264\n547\n14\n5\n...\n82.505140\n13.520249\n13.022889\n11.143211\n19.200000\n0\nAAR\n0.085675\n0.487246\nsmall\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n432\n3048\nWAUKESHA\nWI\n0.034\n304715\n8962.205880\n298313\n1096\n672\n2699\n...\n98.387674\n3.121060\n3.785820\n2.590061\n4.085479\n1\nHLU\n0.885746\n0.487246\nlarge\n\n\n433\n3049\nWAUPACA\nWI\n0.045\n46104\n1024.533330\n45695\n22\n125\n92\n...\n96.330036\n8.488697\n10.071411\n6.953799\n10.338641\n0\nAAR\n0.199549\n0.487246\nsmall\n\n\n434\n3050\nWAUSHARA\nWI\n0.037\n19385\n523.918919\n19094\n29\n70\n43\n...\n98.854785\n13.786985\n20.050708\n11.695784\n11.804558\n0\nAAR\n0.221821\n0.487246\nsmall\n\n\n435\n3051\nWINNEBAGO\nWI\n0.035\n140320\n4009.142860\n136822\n697\n685\n1728\n...\n95.460376\n8.804031\n10.592031\n8.660587\n6.661094\n1\nHAU\n1.231471\n0.487246\nlarge\n\n\n436\n3052\nWOOD\nWI\n0.048\n73605\n1533.437500\n72157\n90\n481\n722\n...\n98.750085\n8.525831\n11.162997\n7.375656\n7.882918\n0\nAAR\n0.980912\n0.487246\nlarge\n\n\n\n\n437 rows × 31 columns\n\n\n\n\n\n\n\n#빈도 구하기\ncount_vs = midwest_new['vs_mean'].value_counts()\ncount_vs\n\n#막대 그래프 만들기\ncount_vs.plot.bar(rot = 0)"
  },
  {
    "objectID": "hw1.html#숙제해라-네",
    "href": "hw1.html#숙제해라-네",
    "title": "hw1",
    "section": "",
    "text": "#!pip install pandas\nimport pandas as pd\n\ndf = pd.DataFrame({\"제품\"   : [\"사과\",\"딸기\",\"수박\"],\n                   \"가격\"   : [1800, 1500, 3000],\n                   \"판매량\" : [24, 38, 13]})\ndf\n\n\n\n\n\n\n\n\n제품\n가격\n판매량\n\n\n\n\n0\n사과\n1800\n24\n\n\n1\n딸기\n1500\n38\n\n\n2\n수박\n3000\n13\n\n\n\n\n\n\n\n\n\n\n\n\nprice_avg = sum(df[\"가격\"]) / 3\nvol_avg = sum(df[\"판매량\"]) / 3\n\nprint(\"과일 가격의 평균은\", price_avg)\nprint(\"과일 판매량의 평균은\", vol_avg)\n\n과일 가격의 평균은 2100.0\n과일 판매량의 평균은 25.0\n\n\n\n\n\n\n\n# mpg 데이터 불러오기\nmpg_raw = pd.read_csv('C:/Users/USER/Documents/LS빅데이터스쿨/lsbigdata-project1/data/mpg.csv')\nmpg_new = mpg_raw.copy()\nmpg_new\n\n\n\n\n\n\n\n\nmanufacturer\nmodel\ndispl\nyear\ncyl\ntrans\ndrv\ncty\nhwy\nfl\ncategory\n\n\n\n\n0\naudi\na4\n1.8\n1999\n4\nauto(l5)\nf\n18\n29\np\ncompact\n\n\n1\naudi\na4\n1.8\n1999\n4\nmanual(m5)\nf\n21\n29\np\ncompact\n\n\n2\naudi\na4\n2.0\n2008\n4\nmanual(m6)\nf\n20\n31\np\ncompact\n\n\n3\naudi\na4\n2.0\n2008\n4\nauto(av)\nf\n21\n30\np\ncompact\n\n\n4\naudi\na4\n2.8\n1999\n6\nauto(l5)\nf\n16\n26\np\ncompact\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n229\nvolkswagen\npassat\n2.0\n2008\n4\nauto(s6)\nf\n19\n28\np\nmidsize\n\n\n230\nvolkswagen\npassat\n2.0\n2008\n4\nmanual(m6)\nf\n21\n29\np\nmidsize\n\n\n231\nvolkswagen\npassat\n2.8\n1999\n6\nauto(l5)\nf\n16\n26\np\nmidsize\n\n\n232\nvolkswagen\npassat\n2.8\n1999\n6\nmanual(m5)\nf\n18\n26\np\nmidsize\n\n\n233\nvolkswagen\npassat\n3.6\n2008\n6\nauto(s6)\nf\n17\n26\np\nmidsize\n\n\n\n\n234 rows × 11 columns\n\n\n\n\n\n\n\n\n#cty -&gt; city\nmpg_new = mpg_new.rename(columns = {'cty' : 'city'})\n\n#hwy -&gt; highway\nmpg_new = mpg_new.rename(columns = {'hwy' : 'highway'})\n\n\n\n\n\n\nmpg_new.head()\n\n\n\n\n\n\n\n\nmanufacturer\nmodel\ndispl\nyear\ncyl\ntrans\ndrv\ncity\nhighway\nfl\ncategory\n\n\n\n\n0\naudi\na4\n1.8\n1999\n4\nauto(l5)\nf\n18\n29\np\ncompact\n\n\n1\naudi\na4\n1.8\n1999\n4\nmanual(m5)\nf\n21\n29\np\ncompact\n\n\n2\naudi\na4\n2.0\n2008\n4\nmanual(m6)\nf\n20\n31\np\ncompact\n\n\n3\naudi\na4\n2.0\n2008\n4\nauto(av)\nf\n21\n30\np\ncompact\n\n\n4\naudi\na4\n2.8\n1999\n6\nauto(l5)\nf\n16\n26\np\ncompact\n\n\n\n\n\n\n\n\n\n\n\n\n\n# midwest.csv 데이터 불러오기\nmidwest_raw = pd.read_csv('C:/Users/USER/Documents/LS빅데이터스쿨/lsbigdata-project1/data/midwest.csv')\nmidwest_new = midwest_raw.copy()\nmidwest_new\n\nmidwest_new.head()\nmidwest_new.tail()\nmidwest_new.shape\nmidwest_new.info()\nmidwest_new.describe()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 437 entries, 0 to 436\nData columns (total 28 columns):\n #   Column                Non-Null Count  Dtype  \n---  ------                --------------  -----  \n 0   PID                   437 non-null    int64  \n 1   county                437 non-null    object \n 2   state                 437 non-null    object \n 3   area                  437 non-null    float64\n 4   poptotal              437 non-null    int64  \n 5   popdensity            437 non-null    float64\n 6   popwhite              437 non-null    int64  \n 7   popblack              437 non-null    int64  \n 8   popamerindian         437 non-null    int64  \n 9   popasian              437 non-null    int64  \n 10  popother              437 non-null    int64  \n 11  percwhite             437 non-null    float64\n 12  percblack             437 non-null    float64\n 13  percamerindan         437 non-null    float64\n 14  percasian             437 non-null    float64\n 15  percother             437 non-null    float64\n 16  popadults             437 non-null    int64  \n 17  perchsd               437 non-null    float64\n 18  percollege            437 non-null    float64\n 19  percprof              437 non-null    float64\n 20  poppovertyknown       437 non-null    int64  \n 21  percpovertyknown      437 non-null    float64\n 22  percbelowpoverty      437 non-null    float64\n 23  percchildbelowpovert  437 non-null    float64\n 24  percadultpoverty      437 non-null    float64\n 25  percelderlypoverty    437 non-null    float64\n 26  inmetro               437 non-null    int64  \n 27  category              437 non-null    object \ndtypes: float64(15), int64(10), object(3)\nmemory usage: 95.7+ KB\n\n\n\n\n\n\n\n\n\nPID\narea\npoptotal\npopdensity\npopwhite\npopblack\npopamerindian\npopasian\npopother\npercwhite\n...\nperchsd\npercollege\npercprof\npoppovertyknown\npercpovertyknown\npercbelowpoverty\npercchildbelowpovert\npercadultpoverty\npercelderlypoverty\ninmetro\n\n\n\n\ncount\n437.000000\n437.000000\n4.370000e+02\n437.000000\n4.370000e+02\n4.370000e+02\n437.000000\n437.000000\n437.000000\n437.000000\n...\n437.000000\n437.000000\n437.000000\n4.370000e+02\n437.000000\n437.000000\n437.000000\n437.000000\n437.000000\n437.000000\n\n\nmean\n1437.338673\n0.033169\n9.613030e+04\n3097.742985\n8.183992e+04\n1.102388e+04\n343.109840\n1310.464531\n1612.931350\n95.558441\n...\n73.965546\n18.272736\n4.447259\n9.364228e+04\n97.110267\n12.510505\n16.447464\n10.918798\n11.389043\n0.343249\n\n\nstd\n876.390266\n0.014679\n2.981705e+05\n7664.751786\n2.001966e+05\n7.895827e+04\n868.926751\n9518.394189\n18526.540699\n7.087358\n...\n5.843177\n6.261908\n2.408427\n2.932351e+05\n2.749863\n5.150155\n7.228634\n5.109166\n3.661259\n0.475338\n\n\nmin\n561.000000\n0.005000\n1.701000e+03\n85.050000\n4.160000e+02\n0.000000e+00\n4.000000\n0.000000\n0.000000\n10.694087\n...\n46.912261\n7.336108\n0.520291\n1.696000e+03\n80.902441\n2.180168\n1.918955\n1.938504\n3.547067\n0.000000\n\n\n25%\n670.000000\n0.024000\n1.884000e+04\n622.407407\n1.863000e+04\n2.900000e+01\n44.000000\n35.000000\n20.000000\n94.886032\n...\n71.325329\n14.113725\n2.997957\n1.836400e+04\n96.894572\n9.198715\n11.624088\n7.668009\n8.911763\n0.000000\n\n\n50%\n1221.000000\n0.030000\n3.532400e+04\n1156.208330\n3.447100e+04\n2.010000e+02\n94.000000\n102.000000\n66.000000\n98.032742\n...\n74.246891\n16.797562\n3.814239\n3.378800e+04\n98.169562\n11.822313\n15.270164\n10.007610\n10.869119\n0.000000\n\n\n75%\n2059.000000\n0.038000\n7.565100e+04\n2330.000000\n7.296800e+04\n1.291000e+03\n288.000000\n401.000000\n345.000000\n99.074935\n...\n77.195345\n20.549893\n4.949324\n7.284000e+04\n98.598636\n15.133226\n20.351878\n13.182182\n13.412162\n1.000000\n\n\nmax\n3052.000000\n0.110000\n5.105067e+06\n88018.396600\n3.204947e+06\n1.317147e+06\n10289.000000\n188565.000000\n384119.000000\n99.822821\n...\n88.898674\n48.078510\n20.791321\n5.023523e+06\n99.860384\n48.691099\n64.308477\n43.312464\n31.161972\n1.000000\n\n\n\n\n8 rows × 25 columns\n\n\n\n\n\n\n\n\n#poptotal -&gt; total\nmidwest_new = midwest_new.rename(columns = {'poptotal' : 'total'})\n\n#popasian -&gt; asian\nmidwest_new = midwest_new.rename(columns = {'popasian' : 'asian'})\n\n\n\n\n\n\nmidwest_new['a_ratio'] = (midwest_new[\"asian\"] / midwest_new[\"total\"]) * 100\nmidwest_new['a_ratio'].plot.hist()\nimport matplotlib.pyplot as plt\nplt.show()\nplt.clf()\n\n\n\n\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;\n\n\n\n\n\n\n\nimport numpy as np\n#아시아 인구 백분율 전체 평균\nmidwest_new['a_mean'] = (midwest_new['a_ratio'].mean())\n\n#평균을 초과하는지 비교\nmidwest_new['vs_mean'] = np.where(midwest_new['a_ratio'] &gt; midwest_new['a_mean'], 'large', 'small')\nmidwest_new\n\n\n\n\n\n\n\n\nPID\ncounty\nstate\narea\ntotal\npopdensity\npopwhite\npopblack\npopamerindian\nasian\n...\npercpovertyknown\npercbelowpoverty\npercchildbelowpovert\npercadultpoverty\npercelderlypoverty\ninmetro\ncategory\na_ratio\na_mean\nvs_mean\n\n\n\n\n0\n561\nADAMS\nIL\n0.052\n66090\n1270.961540\n63917\n1702\n98\n249\n...\n96.274777\n13.151443\n18.011717\n11.009776\n12.443812\n0\nAAR\n0.376759\n0.487246\nsmall\n\n\n1\n562\nALEXANDER\nIL\n0.014\n10626\n759.000000\n7054\n3496\n19\n48\n...\n99.087145\n32.244278\n45.826514\n27.385647\n25.228976\n0\nLHR\n0.451722\n0.487246\nsmall\n\n\n2\n563\nBOND\nIL\n0.022\n14991\n681.409091\n14477\n429\n35\n16\n...\n94.956974\n12.068844\n14.036061\n10.852090\n12.697410\n0\nAAR\n0.106731\n0.487246\nsmall\n\n\n3\n564\nBOONE\nIL\n0.017\n30806\n1812.117650\n29344\n127\n46\n150\n...\n98.477569\n7.209019\n11.179536\n5.536013\n6.217047\n1\nALU\n0.486918\n0.487246\nsmall\n\n\n4\n565\nBROWN\nIL\n0.018\n5836\n324.222222\n5264\n547\n14\n5\n...\n82.505140\n13.520249\n13.022889\n11.143211\n19.200000\n0\nAAR\n0.085675\n0.487246\nsmall\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n432\n3048\nWAUKESHA\nWI\n0.034\n304715\n8962.205880\n298313\n1096\n672\n2699\n...\n98.387674\n3.121060\n3.785820\n2.590061\n4.085479\n1\nHLU\n0.885746\n0.487246\nlarge\n\n\n433\n3049\nWAUPACA\nWI\n0.045\n46104\n1024.533330\n45695\n22\n125\n92\n...\n96.330036\n8.488697\n10.071411\n6.953799\n10.338641\n0\nAAR\n0.199549\n0.487246\nsmall\n\n\n434\n3050\nWAUSHARA\nWI\n0.037\n19385\n523.918919\n19094\n29\n70\n43\n...\n98.854785\n13.786985\n20.050708\n11.695784\n11.804558\n0\nAAR\n0.221821\n0.487246\nsmall\n\n\n435\n3051\nWINNEBAGO\nWI\n0.035\n140320\n4009.142860\n136822\n697\n685\n1728\n...\n95.460376\n8.804031\n10.592031\n8.660587\n6.661094\n1\nHAU\n1.231471\n0.487246\nlarge\n\n\n436\n3052\nWOOD\nWI\n0.048\n73605\n1533.437500\n72157\n90\n481\n722\n...\n98.750085\n8.525831\n11.162997\n7.375656\n7.882918\n0\nAAR\n0.980912\n0.487246\nlarge\n\n\n\n\n437 rows × 31 columns\n\n\n\n\n\n\n\n\n#빈도 구하기\ncount_vs = midwest_new['vs_mean'].value_counts()\ncount_vs\n\n#막대 그래프 만들기\ncount_vs.plot.bar(rot = 0)"
  },
  {
    "objectID": "hw1.html#페이지",
    "href": "hw1.html#페이지",
    "title": "hw1",
    "section": "",
    "text": "#!pip install pandas\nimport pandas as pd\n\ndf = pd.DataFrame({\"제품\"   : [\"사과\",\"딸기\",\"수박\"],\n                   \"가격\"   : [1800, 1500, 3000],\n                   \"판매량\" : [24, 38, 13]})\ndf\n\n\n\n\n\n\n\n\n제품\n가격\n판매량\n\n\n\n\n0\n사과\n1800\n24\n\n\n1\n딸기\n1500\n38\n\n\n2\n수박\n3000\n13\n\n\n\n\n\n\n\n\n\n\n\n\nprice_avg = sum(df[\"가격\"]) / 3\nvol_avg = sum(df[\"판매량\"]) / 3\n\nprint(\"과일 가격의 평균은\", price_avg)\nprint(\"과일 판매량의 평균은\", vol_avg)\n\n과일 가격의 평균은 2100.0\n과일 판매량의 평균은 25.0"
  },
  {
    "objectID": "hw1.html#페이지-1",
    "href": "hw1.html#페이지-1",
    "title": "hw1",
    "section": "115 페이지",
    "text": "115 페이지\n\nQ1. mpg 데이터를 불러와 복사본을 만드세요.\n\n# mpg 데이터 불러오기\nmpg_raw = pd.read_csv('C:/Users/USER/Documents/LS빅데이터스쿨/lsbigdata-project1/data/mpg.csv')\nmpg_new = mpg_raw.copy()\nmpg_new\n\n\n\n\n\n\n\n\nmanufacturer\nmodel\ndispl\nyear\ncyl\ntrans\ndrv\ncty\nhwy\nfl\ncategory\n\n\n\n\n0\naudi\na4\n1.8\n1999\n4\nauto(l5)\nf\n18\n29\np\ncompact\n\n\n1\naudi\na4\n1.8\n1999\n4\nmanual(m5)\nf\n21\n29\np\ncompact\n\n\n2\naudi\na4\n2.0\n2008\n4\nmanual(m6)\nf\n20\n31\np\ncompact\n\n\n3\naudi\na4\n2.0\n2008\n4\nauto(av)\nf\n21\n30\np\ncompact\n\n\n4\naudi\na4\n2.8\n1999\n6\nauto(l5)\nf\n16\n26\np\ncompact\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n229\nvolkswagen\npassat\n2.0\n2008\n4\nauto(s6)\nf\n19\n28\np\nmidsize\n\n\n230\nvolkswagen\npassat\n2.0\n2008\n4\nmanual(m6)\nf\n21\n29\np\nmidsize\n\n\n231\nvolkswagen\npassat\n2.8\n1999\n6\nauto(l5)\nf\n16\n26\np\nmidsize\n\n\n232\nvolkswagen\npassat\n2.8\n1999\n6\nmanual(m5)\nf\n18\n26\np\nmidsize\n\n\n233\nvolkswagen\npassat\n3.6\n2008\n6\nauto(s6)\nf\n17\n26\np\nmidsize\n\n\n\n\n234 rows × 11 columns\n\n\n\n\n\n\nQ2. 복사본 데이터를 이용해 cty는 city로, hwy는 highway로 수정하세요.\n\n#cty -&gt; city\nmpg_new = mpg_new.rename(columns = {'cty' : 'city'})\n\n#hwy -&gt; highway\nmpg_new = mpg_new.rename(columns = {'hwy' : 'highway'})\n\n\n\n\nQ3. 데이터 일부를 출력해 변수명이 바뀌었는지 확인해 보세요. 다음과 같은 결과물이 출력되어야 합니다.\n\nmpg_new.head()\n\n\n\n\n\n\n\n\nmanufacturer\nmodel\ndispl\nyear\ncyl\ntrans\ndrv\ncity\nhighway\nfl\ncategory\n\n\n\n\n0\naudi\na4\n1.8\n1999\n4\nauto(l5)\nf\n18\n29\np\ncompact\n\n\n1\naudi\na4\n1.8\n1999\n4\nmanual(m5)\nf\n21\n29\np\ncompact\n\n\n2\naudi\na4\n2.0\n2008\n4\nmanual(m6)\nf\n20\n31\np\ncompact\n\n\n3\naudi\na4\n2.0\n2008\n4\nauto(av)\nf\n21\n30\np\ncompact\n\n\n4\naudi\na4\n2.8\n1999\n6\nauto(l5)\nf\n16\n26\np\ncompact"
  },
  {
    "objectID": "hw1.html#페이지-2",
    "href": "hw1.html#페이지-2",
    "title": "hw1",
    "section": "130 페이지",
    "text": "130 페이지\n\nQ1. midwest.csv를 불러와 데이터의 특징을 파악하세요.\n\n# midwest.csv 데이터 불러오기\nmidwest_raw = pd.read_csv('C:/Users/USER/Documents/LS빅데이터스쿨/lsbigdata-project1/data/midwest.csv')\nmidwest_new = midwest_raw.copy()\nmidwest_new\n\nmidwest_new.head()\nmidwest_new.tail()\nmidwest_new.shape\nmidwest_new.info()\nmidwest_new.describe()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 437 entries, 0 to 436\nData columns (total 28 columns):\n #   Column                Non-Null Count  Dtype  \n---  ------                --------------  -----  \n 0   PID                   437 non-null    int64  \n 1   county                437 non-null    object \n 2   state                 437 non-null    object \n 3   area                  437 non-null    float64\n 4   poptotal              437 non-null    int64  \n 5   popdensity            437 non-null    float64\n 6   popwhite              437 non-null    int64  \n 7   popblack              437 non-null    int64  \n 8   popamerindian         437 non-null    int64  \n 9   popasian              437 non-null    int64  \n 10  popother              437 non-null    int64  \n 11  percwhite             437 non-null    float64\n 12  percblack             437 non-null    float64\n 13  percamerindan         437 non-null    float64\n 14  percasian             437 non-null    float64\n 15  percother             437 non-null    float64\n 16  popadults             437 non-null    int64  \n 17  perchsd               437 non-null    float64\n 18  percollege            437 non-null    float64\n 19  percprof              437 non-null    float64\n 20  poppovertyknown       437 non-null    int64  \n 21  percpovertyknown      437 non-null    float64\n 22  percbelowpoverty      437 non-null    float64\n 23  percchildbelowpovert  437 non-null    float64\n 24  percadultpoverty      437 non-null    float64\n 25  percelderlypoverty    437 non-null    float64\n 26  inmetro               437 non-null    int64  \n 27  category              437 non-null    object \ndtypes: float64(15), int64(10), object(3)\nmemory usage: 95.7+ KB\n\n\n\n\n\n\n\n\n\nPID\narea\npoptotal\npopdensity\npopwhite\npopblack\npopamerindian\npopasian\npopother\npercwhite\n...\nperchsd\npercollege\npercprof\npoppovertyknown\npercpovertyknown\npercbelowpoverty\npercchildbelowpovert\npercadultpoverty\npercelderlypoverty\ninmetro\n\n\n\n\ncount\n437.000000\n437.000000\n4.370000e+02\n437.000000\n4.370000e+02\n4.370000e+02\n437.000000\n437.000000\n437.000000\n437.000000\n...\n437.000000\n437.000000\n437.000000\n4.370000e+02\n437.000000\n437.000000\n437.000000\n437.000000\n437.000000\n437.000000\n\n\nmean\n1437.338673\n0.033169\n9.613030e+04\n3097.742985\n8.183992e+04\n1.102388e+04\n343.109840\n1310.464531\n1612.931350\n95.558441\n...\n73.965546\n18.272736\n4.447259\n9.364228e+04\n97.110267\n12.510505\n16.447464\n10.918798\n11.389043\n0.343249\n\n\nstd\n876.390266\n0.014679\n2.981705e+05\n7664.751786\n2.001966e+05\n7.895827e+04\n868.926751\n9518.394189\n18526.540699\n7.087358\n...\n5.843177\n6.261908\n2.408427\n2.932351e+05\n2.749863\n5.150155\n7.228634\n5.109166\n3.661259\n0.475338\n\n\nmin\n561.000000\n0.005000\n1.701000e+03\n85.050000\n4.160000e+02\n0.000000e+00\n4.000000\n0.000000\n0.000000\n10.694087\n...\n46.912261\n7.336108\n0.520291\n1.696000e+03\n80.902441\n2.180168\n1.918955\n1.938504\n3.547067\n0.000000\n\n\n25%\n670.000000\n0.024000\n1.884000e+04\n622.407407\n1.863000e+04\n2.900000e+01\n44.000000\n35.000000\n20.000000\n94.886032\n...\n71.325329\n14.113725\n2.997957\n1.836400e+04\n96.894572\n9.198715\n11.624088\n7.668009\n8.911763\n0.000000\n\n\n50%\n1221.000000\n0.030000\n3.532400e+04\n1156.208330\n3.447100e+04\n2.010000e+02\n94.000000\n102.000000\n66.000000\n98.032742\n...\n74.246891\n16.797562\n3.814239\n3.378800e+04\n98.169562\n11.822313\n15.270164\n10.007610\n10.869119\n0.000000\n\n\n75%\n2059.000000\n0.038000\n7.565100e+04\n2330.000000\n7.296800e+04\n1.291000e+03\n288.000000\n401.000000\n345.000000\n99.074935\n...\n77.195345\n20.549893\n4.949324\n7.284000e+04\n98.598636\n15.133226\n20.351878\n13.182182\n13.412162\n1.000000\n\n\nmax\n3052.000000\n0.110000\n5.105067e+06\n88018.396600\n3.204947e+06\n1.317147e+06\n10289.000000\n188565.000000\n384119.000000\n99.822821\n...\n88.898674\n48.078510\n20.791321\n5.023523e+06\n99.860384\n48.691099\n64.308477\n43.312464\n31.161972\n1.000000\n\n\n\n\n8 rows × 25 columns\n\n\n\n\n\n\nQ2. poptotal(전체 인구) 변수를 total로, popasian(아시아 인구)변수를 asian으로 수정하세요.\n\n#poptotal -&gt; total\nmidwest_new = midwest_new.rename(columns = {'poptotal' : 'total'})\n\n#popasian -&gt; asian\nmidwest_new = midwest_new.rename(columns = {'popasian' : 'asian'})\n\n\n\n\nQ3. total, asian 변수를 이용해 ‘전체 인구 대비 아시아 인구 백분율’ 파생변수를 추가하고, 히스토그램을 만들어 분포를 살펴보세요.\n\nmidwest_new['a_ratio'] = (midwest_new[\"asian\"] / midwest_new[\"total\"]) * 100\nmidwest_new['a_ratio'].plot.hist()\nimport matplotlib.pyplot as plt\nplt.show()\nplt.clf()\n\n\n\n\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;\n\n\n\n\n\nQ4. 아시아 인구 백분율 전체 평균을 구하고, 평균을 초과하면 'large', 그 외에는 'small'을 부여한 파생변수를 만들어 보세요.\n\nimport numpy as np\n#아시아 인구 백분율 전체 평균\nmidwest_new['a_mean'] = (midwest_new['a_ratio'].mean())\n\n#평균을 초과하는지 비교\nmidwest_new['vs_mean'] = np.where(midwest_new['a_ratio'] &gt; midwest_new['a_mean'], 'large', 'small')\nmidwest_new\n\n\n\n\n\n\n\n\nPID\ncounty\nstate\narea\ntotal\npopdensity\npopwhite\npopblack\npopamerindian\nasian\n...\npercpovertyknown\npercbelowpoverty\npercchildbelowpovert\npercadultpoverty\npercelderlypoverty\ninmetro\ncategory\na_ratio\na_mean\nvs_mean\n\n\n\n\n0\n561\nADAMS\nIL\n0.052\n66090\n1270.961540\n63917\n1702\n98\n249\n...\n96.274777\n13.151443\n18.011717\n11.009776\n12.443812\n0\nAAR\n0.376759\n0.487246\nsmall\n\n\n1\n562\nALEXANDER\nIL\n0.014\n10626\n759.000000\n7054\n3496\n19\n48\n...\n99.087145\n32.244278\n45.826514\n27.385647\n25.228976\n0\nLHR\n0.451722\n0.487246\nsmall\n\n\n2\n563\nBOND\nIL\n0.022\n14991\n681.409091\n14477\n429\n35\n16\n...\n94.956974\n12.068844\n14.036061\n10.852090\n12.697410\n0\nAAR\n0.106731\n0.487246\nsmall\n\n\n3\n564\nBOONE\nIL\n0.017\n30806\n1812.117650\n29344\n127\n46\n150\n...\n98.477569\n7.209019\n11.179536\n5.536013\n6.217047\n1\nALU\n0.486918\n0.487246\nsmall\n\n\n4\n565\nBROWN\nIL\n0.018\n5836\n324.222222\n5264\n547\n14\n5\n...\n82.505140\n13.520249\n13.022889\n11.143211\n19.200000\n0\nAAR\n0.085675\n0.487246\nsmall\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n432\n3048\nWAUKESHA\nWI\n0.034\n304715\n8962.205880\n298313\n1096\n672\n2699\n...\n98.387674\n3.121060\n3.785820\n2.590061\n4.085479\n1\nHLU\n0.885746\n0.487246\nlarge\n\n\n433\n3049\nWAUPACA\nWI\n0.045\n46104\n1024.533330\n45695\n22\n125\n92\n...\n96.330036\n8.488697\n10.071411\n6.953799\n10.338641\n0\nAAR\n0.199549\n0.487246\nsmall\n\n\n434\n3050\nWAUSHARA\nWI\n0.037\n19385\n523.918919\n19094\n29\n70\n43\n...\n98.854785\n13.786985\n20.050708\n11.695784\n11.804558\n0\nAAR\n0.221821\n0.487246\nsmall\n\n\n435\n3051\nWINNEBAGO\nWI\n0.035\n140320\n4009.142860\n136822\n697\n685\n1728\n...\n95.460376\n8.804031\n10.592031\n8.660587\n6.661094\n1\nHAU\n1.231471\n0.487246\nlarge\n\n\n436\n3052\nWOOD\nWI\n0.048\n73605\n1533.437500\n72157\n90\n481\n722\n...\n98.750085\n8.525831\n11.162997\n7.375656\n7.882918\n0\nAAR\n0.980912\n0.487246\nlarge\n\n\n\n\n437 rows × 31 columns\n\n\n\n\n\n\nQ5. 'large'와 'small'에 해당하는 지역이 얼마나 많은지 빈도표와 빈도 막대 그래프를 만들어 확인해 보세요.\n\n#빈도 구하기\ncount_vs = midwest_new['vs_mean'].value_counts()\ncount_vs\n\n#막대 그래프 만들기\ncount_vs.plot.bar(rot = 0)"
  },
  {
    "objectID": "hw2.html",
    "href": "hw2.html",
    "title": "hw2",
    "section": "",
    "text": "# mpg 데이터 불러오기\nimport pandas as pd\nimport numpy as np\nmpg = pd.read_csv('C:/Users/USER/Documents/LS빅데이터스쿨/lsbigdata-project1/data/mpg.csv')\n\nmpg_a = mpg.query('displ &lt;= 4')\nmpg_b = mpg.query('displ &gt;= 5')\n\nmpg_a['hwy'].mean(), mpg_b['hwy'].mean()\n\n(np.float64(25.96319018404908), np.float64(18.07894736842105))\n\n\n\n\n\n\nmpg_audi = mpg.query(\"manufacturer == 'audi'\")\nmpg_toyota = mpg.query(\"manufacturer == 'toyota'\")\n\nmpg_audi['cty'].mean(), mpg_toyota['cty'].mean()\n\n(np.float64(17.61111111111111), np.float64(18.529411764705884))\n\n\n\n\n\n\nmpg_new = mpg.query('manufacturer in [\"chevrolet\", \"ford\", \"honda\"]')\nmpg_new['hwy'].mean()\n\nnp.float64(22.50943396226415)"
  },
  {
    "objectID": "hw2.html#페이지",
    "href": "hw2.html#페이지",
    "title": "hw2",
    "section": "",
    "text": "# mpg 데이터 불러오기\nimport pandas as pd\nimport numpy as np\nmpg = pd.read_csv('C:/Users/USER/Documents/LS빅데이터스쿨/lsbigdata-project1/data/mpg.csv')\n\nmpg_a = mpg.query('displ &lt;= 4')\nmpg_b = mpg.query('displ &gt;= 5')\n\nmpg_a['hwy'].mean(), mpg_b['hwy'].mean()\n\n(np.float64(25.96319018404908), np.float64(18.07894736842105))\n\n\n\n\n\n\nmpg_audi = mpg.query(\"manufacturer == 'audi'\")\nmpg_toyota = mpg.query(\"manufacturer == 'toyota'\")\n\nmpg_audi['cty'].mean(), mpg_toyota['cty'].mean()\n\n(np.float64(17.61111111111111), np.float64(18.529411764705884))\n\n\n\n\n\n\nmpg_new = mpg.query('manufacturer in [\"chevrolet\", \"ford\", \"honda\"]')\nmpg_new['hwy'].mean()\n\nnp.float64(22.50943396226415)"
  },
  {
    "objectID": "hw2.html#페이지-1",
    "href": "hw2.html#페이지-1",
    "title": "hw2",
    "section": "153 페이지",
    "text": "153 페이지\n\nQ1. 'audi'에서 생산한 자동차 중에 어떤 자동차 모델의 hwy(고속도로 연비)가 높은지 알아보려고 합니다. audi'에서 생산한 자동차 중 hwy가 1~5위에 해당하는 자동차의 데이터를 출력하세요.\n\naudi_mpg = mpg.query(\"manufacturer == 'audi'\")\naudi_mpg.sort_values('hwy', ascending = False).head()\n\nmpg.query(\"manufacturer == 'audi'\") \\\n   .sort_values('hwy', ascending = False) \\\n   .head()\n\n\n\n\n\n\n\n\nmanufacturer\nmodel\ndispl\nyear\ncyl\ntrans\ndrv\ncty\nhwy\nfl\ncategory\n\n\n\n\n2\naudi\na4\n2.0\n2008\n4\nmanual(m6)\nf\n20\n31\np\ncompact\n\n\n3\naudi\na4\n2.0\n2008\n4\nauto(av)\nf\n21\n30\np\ncompact\n\n\n1\naudi\na4\n1.8\n1999\n4\nmanual(m5)\nf\n21\n29\np\ncompact\n\n\n0\naudi\na4\n1.8\n1999\n4\nauto(l5)\nf\n18\n29\np\ncompact\n\n\n9\naudi\na4 quattro\n2.0\n2008\n4\nmanual(m6)\n4\n20\n28\np\ncompact"
  },
  {
    "objectID": "hw2.html#페이지-2",
    "href": "hw2.html#페이지-2",
    "title": "hw2",
    "section": "158 페이지",
    "text": "158 페이지\nmpg데이터는 연비를 나타내는 변수가 hwy(고속도로 연비), cty(도시 연비) 두 종류로 분리되어 있습니다. 두 변수는 각각 활용하는 대신 하나의 합산 연비 변수를 만들어 분석하려고 합니다.\n\nQ1. mpg데이터 복사본을 만들고, cty와 hwy를 더한 합산 연비 변수를 추가하세요.\n\nmpg_new = mpg.copy()\nmpg_new = mpg_new.assign(mileage = mpg_new['cty'] + mpg_new['hwy'])\nmpg_new.head()\n\n\n\n\n\n\n\n\nmanufacturer\nmodel\ndispl\nyear\ncyl\ntrans\ndrv\ncty\nhwy\nfl\ncategory\nmileage\n\n\n\n\n0\naudi\na4\n1.8\n1999\n4\nauto(l5)\nf\n18\n29\np\ncompact\n47\n\n\n1\naudi\na4\n1.8\n1999\n4\nmanual(m5)\nf\n21\n29\np\ncompact\n50\n\n\n2\naudi\na4\n2.0\n2008\n4\nmanual(m6)\nf\n20\n31\np\ncompact\n51\n\n\n3\naudi\na4\n2.0\n2008\n4\nauto(av)\nf\n21\n30\np\ncompact\n51\n\n\n4\naudi\na4\n2.8\n1999\n6\nauto(l5)\nf\n16\n26\np\ncompact\n42\n\n\n\n\n\n\n\n\n\n\nQ2. 앞에서 만든 ’합산 연비 변수’를 2로 나눠 ’평균 연비 변수’를 추가하세요.\n\nmpg_new = mpg_new.assign(mileage_mean = mpg_new['mileage'] / 2)\nmpg_new.head()\n\n\n\n\n\n\n\n\nmanufacturer\nmodel\ndispl\nyear\ncyl\ntrans\ndrv\ncty\nhwy\nfl\ncategory\nmileage\nmileage_mean\n\n\n\n\n0\naudi\na4\n1.8\n1999\n4\nauto(l5)\nf\n18\n29\np\ncompact\n47\n23.5\n\n\n1\naudi\na4\n1.8\n1999\n4\nmanual(m5)\nf\n21\n29\np\ncompact\n50\n25.0\n\n\n2\naudi\na4\n2.0\n2008\n4\nmanual(m6)\nf\n20\n31\np\ncompact\n51\n25.5\n\n\n3\naudi\na4\n2.0\n2008\n4\nauto(av)\nf\n21\n30\np\ncompact\n51\n25.5\n\n\n4\naudi\na4\n2.8\n1999\n6\nauto(l5)\nf\n16\n26\np\ncompact\n42\n21.0\n\n\n\n\n\n\n\n\n\n\nQ3. ’평균 연비 변수’가 가장 높은 자동차 3종의 데이터를 출력하세요.\n\nmpg_new.sort_values('mileage_mean', ascending = False).head(3)\n\n\n\n\n\n\n\n\nmanufacturer\nmodel\ndispl\nyear\ncyl\ntrans\ndrv\ncty\nhwy\nfl\ncategory\nmileage\nmileage_mean\n\n\n\n\n221\nvolkswagen\nnew beetle\n1.9\n1999\n4\nmanual(m5)\nf\n35\n44\nd\nsubcompact\n79\n39.5\n\n\n212\nvolkswagen\njetta\n1.9\n1999\n4\nmanual(m5)\nf\n33\n44\nd\ncompact\n77\n38.5\n\n\n222\nvolkswagen\nnew beetle\n1.9\n1999\n4\nauto(l4)\nf\n29\n41\nd\nsubcompact\n70\n35.0\n\n\n\n\n\n\n\n\n\n\nQ4. 1~3번 문제를 해결할 수 있는 하나로 연결된 pandas구문을 만들어 실행해 보세요. 데이터는 복사본 대신 mpg원본을 이용하세요.\n\nmpg.assign(mileage = mpg_new['cty'] + mpg_new['hwy']) \\\n   .assign(mileage_mean = mpg_new['mileage'] / 2) \\\n   .sort_values('mileage_mean', ascending = False).head(3)\n\n\n\n\n\n\n\n\nmanufacturer\nmodel\ndispl\nyear\ncyl\ntrans\ndrv\ncty\nhwy\nfl\ncategory\nmileage\nmileage_mean\n\n\n\n\n221\nvolkswagen\nnew beetle\n1.9\n1999\n4\nmanual(m5)\nf\n35\n44\nd\nsubcompact\n79\n39.5\n\n\n212\nvolkswagen\njetta\n1.9\n1999\n4\nmanual(m5)\nf\n33\n44\nd\ncompact\n77\n38.5\n\n\n222\nvolkswagen\nnew beetle\n1.9\n1999\n4\nauto(l4)\nf\n29\n41\nd\nsubcompact\n70\n35.0"
  },
  {
    "objectID": "posts/hw2/hw2.html",
    "href": "posts/hw2/hw2.html",
    "title": "hw2",
    "section": "",
    "text": "# mpg 데이터 불러오기\nimport pandas as pd\nimport numpy as np\nmpg = pd.read_csv('C:/Users/USER/Documents/LS빅데이터스쿨/lsbigdata-project1/data/mpg.csv')\n\nmpg_a = mpg.query('displ &lt;= 4')\nmpg_b = mpg.query('displ &gt;= 5')\n\nmpg_a['hwy'].mean(), mpg_b['hwy'].mean()\n\n(np.float64(25.96319018404908), np.float64(18.07894736842105))\n\n\n\n\n\n\nmpg_audi = mpg.query(\"manufacturer == 'audi'\")\nmpg_toyota = mpg.query(\"manufacturer == 'toyota'\")\n\nmpg_audi['cty'].mean(), mpg_toyota['cty'].mean()\n\n(np.float64(17.61111111111111), np.float64(18.529411764705884))\n\n\n\n\n\n\nmpg_new = mpg.query('manufacturer in [\"chevrolet\", \"ford\", \"honda\"]')\nmpg_new['hwy'].mean()\n\nnp.float64(22.50943396226415)"
  },
  {
    "objectID": "posts/hw2/hw2.html#페이지",
    "href": "posts/hw2/hw2.html#페이지",
    "title": "hw2",
    "section": "",
    "text": "# mpg 데이터 불러오기\nimport pandas as pd\nimport numpy as np\nmpg = pd.read_csv('C:/Users/USER/Documents/LS빅데이터스쿨/lsbigdata-project1/data/mpg.csv')\n\nmpg_a = mpg.query('displ &lt;= 4')\nmpg_b = mpg.query('displ &gt;= 5')\n\nmpg_a['hwy'].mean(), mpg_b['hwy'].mean()\n\n(np.float64(25.96319018404908), np.float64(18.07894736842105))\n\n\n\n\n\n\nmpg_audi = mpg.query(\"manufacturer == 'audi'\")\nmpg_toyota = mpg.query(\"manufacturer == 'toyota'\")\n\nmpg_audi['cty'].mean(), mpg_toyota['cty'].mean()\n\n(np.float64(17.61111111111111), np.float64(18.529411764705884))\n\n\n\n\n\n\nmpg_new = mpg.query('manufacturer in [\"chevrolet\", \"ford\", \"honda\"]')\nmpg_new['hwy'].mean()\n\nnp.float64(22.50943396226415)"
  },
  {
    "objectID": "posts/hw2/hw2.html#페이지-1",
    "href": "posts/hw2/hw2.html#페이지-1",
    "title": "hw2",
    "section": "153 페이지",
    "text": "153 페이지\n\nQ1. 'audi'에서 생산한 자동차 중에 어떤 자동차 모델의 hwy(고속도로 연비)가 높은지 알아보려고 합니다. audi'에서 생산한 자동차 중 hwy가 1~5위에 해당하는 자동차의 데이터를 출력하세요.\n\naudi_mpg = mpg.query(\"manufacturer == 'audi'\")\naudi_mpg.sort_values('hwy', ascending = False).head()\n\nmpg.query(\"manufacturer == 'audi'\") \\\n   .sort_values('hwy', ascending = False) \\\n   .head()\n\n\n\n\n\n\n\n\nmanufacturer\nmodel\ndispl\nyear\ncyl\ntrans\ndrv\ncty\nhwy\nfl\ncategory\n\n\n\n\n2\naudi\na4\n2.0\n2008\n4\nmanual(m6)\nf\n20\n31\np\ncompact\n\n\n3\naudi\na4\n2.0\n2008\n4\nauto(av)\nf\n21\n30\np\ncompact\n\n\n1\naudi\na4\n1.8\n1999\n4\nmanual(m5)\nf\n21\n29\np\ncompact\n\n\n0\naudi\na4\n1.8\n1999\n4\nauto(l5)\nf\n18\n29\np\ncompact\n\n\n9\naudi\na4 quattro\n2.0\n2008\n4\nmanual(m6)\n4\n20\n28\np\ncompact"
  },
  {
    "objectID": "posts/hw2/hw2.html#페이지-2",
    "href": "posts/hw2/hw2.html#페이지-2",
    "title": "hw2",
    "section": "158 페이지",
    "text": "158 페이지\nmpg데이터는 연비를 나타내는 변수가 hwy(고속도로 연비), cty(도시 연비) 두 종류로 분리되어 있습니다. 두 변수는 각각 활용하는 대신 하나의 합산 연비 변수를 만들어 분석하려고 합니다.\n\nQ1. mpg데이터 복사본을 만들고, cty와 hwy를 더한 합산 연비 변수를 추가하세요.\n\nmpg_new = mpg.copy()\nmpg_new = mpg_new.assign(mileage = mpg_new['cty'] + mpg_new['hwy'])\nmpg_new.head()\n\n\n\n\n\n\n\n\nmanufacturer\nmodel\ndispl\nyear\ncyl\ntrans\ndrv\ncty\nhwy\nfl\ncategory\nmileage\n\n\n\n\n0\naudi\na4\n1.8\n1999\n4\nauto(l5)\nf\n18\n29\np\ncompact\n47\n\n\n1\naudi\na4\n1.8\n1999\n4\nmanual(m5)\nf\n21\n29\np\ncompact\n50\n\n\n2\naudi\na4\n2.0\n2008\n4\nmanual(m6)\nf\n20\n31\np\ncompact\n51\n\n\n3\naudi\na4\n2.0\n2008\n4\nauto(av)\nf\n21\n30\np\ncompact\n51\n\n\n4\naudi\na4\n2.8\n1999\n6\nauto(l5)\nf\n16\n26\np\ncompact\n42\n\n\n\n\n\n\n\n\n\n\nQ2. 앞에서 만든 ’합산 연비 변수’를 2로 나눠 ’평균 연비 변수’를 추가하세요.\n\nmpg_new = mpg_new.assign(mileage_mean = mpg_new['mileage'] / 2)\nmpg_new.head()\n\n\n\n\n\n\n\n\nmanufacturer\nmodel\ndispl\nyear\ncyl\ntrans\ndrv\ncty\nhwy\nfl\ncategory\nmileage\nmileage_mean\n\n\n\n\n0\naudi\na4\n1.8\n1999\n4\nauto(l5)\nf\n18\n29\np\ncompact\n47\n23.5\n\n\n1\naudi\na4\n1.8\n1999\n4\nmanual(m5)\nf\n21\n29\np\ncompact\n50\n25.0\n\n\n2\naudi\na4\n2.0\n2008\n4\nmanual(m6)\nf\n20\n31\np\ncompact\n51\n25.5\n\n\n3\naudi\na4\n2.0\n2008\n4\nauto(av)\nf\n21\n30\np\ncompact\n51\n25.5\n\n\n4\naudi\na4\n2.8\n1999\n6\nauto(l5)\nf\n16\n26\np\ncompact\n42\n21.0\n\n\n\n\n\n\n\n\n\n\nQ3. ’평균 연비 변수’가 가장 높은 자동차 3종의 데이터를 출력하세요.\n\nmpg_new.sort_values('mileage_mean', ascending = False).head(3)\n\n\n\n\n\n\n\n\nmanufacturer\nmodel\ndispl\nyear\ncyl\ntrans\ndrv\ncty\nhwy\nfl\ncategory\nmileage\nmileage_mean\n\n\n\n\n221\nvolkswagen\nnew beetle\n1.9\n1999\n4\nmanual(m5)\nf\n35\n44\nd\nsubcompact\n79\n39.5\n\n\n212\nvolkswagen\njetta\n1.9\n1999\n4\nmanual(m5)\nf\n33\n44\nd\ncompact\n77\n38.5\n\n\n222\nvolkswagen\nnew beetle\n1.9\n1999\n4\nauto(l4)\nf\n29\n41\nd\nsubcompact\n70\n35.0\n\n\n\n\n\n\n\n\n\n\nQ4. 1~3번 문제를 해결할 수 있는 하나로 연결된 pandas구문을 만들어 실행해 보세요. 데이터는 복사본 대신 mpg원본을 이용하세요.\n\nmpg.assign(mileage = mpg_new['cty'] + mpg_new['hwy']) \\\n   .assign(mileage_mean = mpg_new['mileage'] / 2) \\\n   .sort_values('mileage_mean', ascending = False).head(3)\n\n\n\n\n\n\n\n\nmanufacturer\nmodel\ndispl\nyear\ncyl\ntrans\ndrv\ncty\nhwy\nfl\ncategory\nmileage\nmileage_mean\n\n\n\n\n221\nvolkswagen\nnew beetle\n1.9\n1999\n4\nmanual(m5)\nf\n35\n44\nd\nsubcompact\n79\n39.5\n\n\n212\nvolkswagen\njetta\n1.9\n1999\n4\nmanual(m5)\nf\n33\n44\nd\ncompact\n77\n38.5\n\n\n222\nvolkswagen\nnew beetle\n1.9\n1999\n4\nauto(l4)\nf\n29\n41\nd\nsubcompact\n70\n35.0"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "myblog",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n로지스틱 회귀분석 문제세트\n\n\n\nSep 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nLS 빅데이터 스쿨 Homework 7\n\n\n\nSep 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nLS 빅데이터 스쿨 Homework 6\n\n\n\nAug 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nLS 빅데이터 스쿨 Homework 5\n\n\n\nJul 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nLS 빅데이터 스쿨 Homework 4\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nLS 빅데이터 스쿨 Homework 3\n\n\n\nJul 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nLS 빅데이터 스쿨 Homework 2-3\n\n\n\nJul 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n교과서 챕터 8\n\n\n\nJul 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nLS 빅데이터 스쿨 Homework 2-2\n\n\n\nJul 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nLS 빅데이터 스쿨 Homework 2-1\n\n\n\nJul 16, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nLS 빅데이터 스쿨 Homework 1\n\n\n\nJul 12, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/hw1/hw1.html",
    "href": "posts/hw1/hw1.html",
    "title": "hw1",
    "section": "",
    "text": "#!pip install pandas\nimport pandas as pd\n\ndf = pd.DataFrame({\"제품\"   : [\"사과\",\"딸기\",\"수박\"],\n                   \"가격\"   : [1800, 1500, 3000],\n                   \"판매량\" : [24, 38, 13]})\ndf\n\n\n\n\n\n\n\n\n제품\n가격\n판매량\n\n\n\n\n0\n사과\n1800\n24\n\n\n1\n딸기\n1500\n38\n\n\n2\n수박\n3000\n13\n\n\n\n\n\n\n\n\n\n\n\n\nprice_avg = sum(df[\"가격\"]) / 3\nvol_avg = sum(df[\"판매량\"]) / 3\n\nprint(\"과일 가격의 평균은\", price_avg)\nprint(\"과일 판매량의 평균은\", vol_avg)\n\n과일 가격의 평균은 2100.0\n과일 판매량의 평균은 25.0"
  },
  {
    "objectID": "posts/hw1/hw1.html#페이지",
    "href": "posts/hw1/hw1.html#페이지",
    "title": "hw1",
    "section": "",
    "text": "#!pip install pandas\nimport pandas as pd\n\ndf = pd.DataFrame({\"제품\"   : [\"사과\",\"딸기\",\"수박\"],\n                   \"가격\"   : [1800, 1500, 3000],\n                   \"판매량\" : [24, 38, 13]})\ndf\n\n\n\n\n\n\n\n\n제품\n가격\n판매량\n\n\n\n\n0\n사과\n1800\n24\n\n\n1\n딸기\n1500\n38\n\n\n2\n수박\n3000\n13\n\n\n\n\n\n\n\n\n\n\n\n\nprice_avg = sum(df[\"가격\"]) / 3\nvol_avg = sum(df[\"판매량\"]) / 3\n\nprint(\"과일 가격의 평균은\", price_avg)\nprint(\"과일 판매량의 평균은\", vol_avg)\n\n과일 가격의 평균은 2100.0\n과일 판매량의 평균은 25.0"
  },
  {
    "objectID": "posts/hw1/hw1.html#페이지-1",
    "href": "posts/hw1/hw1.html#페이지-1",
    "title": "hw1",
    "section": "115 페이지",
    "text": "115 페이지\n\nQ1. mpg 데이터를 불러와 복사본을 만드세요.\n\n# mpg 데이터 불러오기\nmpg_raw = pd.read_csv('C:/Users/USER/Documents/LS빅데이터스쿨/lsbigdata-project1/data/mpg.csv')\nmpg_new = mpg_raw.copy()\nmpg_new\n\n\n\n\n\n\n\n\nmanufacturer\nmodel\ndispl\nyear\ncyl\ntrans\ndrv\ncty\nhwy\nfl\ncategory\n\n\n\n\n0\naudi\na4\n1.8\n1999\n4\nauto(l5)\nf\n18\n29\np\ncompact\n\n\n1\naudi\na4\n1.8\n1999\n4\nmanual(m5)\nf\n21\n29\np\ncompact\n\n\n2\naudi\na4\n2.0\n2008\n4\nmanual(m6)\nf\n20\n31\np\ncompact\n\n\n3\naudi\na4\n2.0\n2008\n4\nauto(av)\nf\n21\n30\np\ncompact\n\n\n4\naudi\na4\n2.8\n1999\n6\nauto(l5)\nf\n16\n26\np\ncompact\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n229\nvolkswagen\npassat\n2.0\n2008\n4\nauto(s6)\nf\n19\n28\np\nmidsize\n\n\n230\nvolkswagen\npassat\n2.0\n2008\n4\nmanual(m6)\nf\n21\n29\np\nmidsize\n\n\n231\nvolkswagen\npassat\n2.8\n1999\n6\nauto(l5)\nf\n16\n26\np\nmidsize\n\n\n232\nvolkswagen\npassat\n2.8\n1999\n6\nmanual(m5)\nf\n18\n26\np\nmidsize\n\n\n233\nvolkswagen\npassat\n3.6\n2008\n6\nauto(s6)\nf\n17\n26\np\nmidsize\n\n\n\n\n234 rows × 11 columns\n\n\n\n\n\n\nQ2. 복사본 데이터를 이용해 cty는 city로, hwy는 highway로 수정하세요.\n\n#cty -&gt; city\nmpg_new = mpg_new.rename(columns = {'cty' : 'city'})\n\n#hwy -&gt; highway\nmpg_new = mpg_new.rename(columns = {'hwy' : 'highway'})\n\n\n\n\nQ3. 데이터 일부를 출력해 변수명이 바뀌었는지 확인해 보세요. 다음과 같은 결과물이 출력되어야 합니다.\n\nmpg_new.head()\n\n\n\n\n\n\n\n\nmanufacturer\nmodel\ndispl\nyear\ncyl\ntrans\ndrv\ncity\nhighway\nfl\ncategory\n\n\n\n\n0\naudi\na4\n1.8\n1999\n4\nauto(l5)\nf\n18\n29\np\ncompact\n\n\n1\naudi\na4\n1.8\n1999\n4\nmanual(m5)\nf\n21\n29\np\ncompact\n\n\n2\naudi\na4\n2.0\n2008\n4\nmanual(m6)\nf\n20\n31\np\ncompact\n\n\n3\naudi\na4\n2.0\n2008\n4\nauto(av)\nf\n21\n30\np\ncompact\n\n\n4\naudi\na4\n2.8\n1999\n6\nauto(l5)\nf\n16\n26\np\ncompact"
  },
  {
    "objectID": "posts/hw1/hw1.html#페이지-2",
    "href": "posts/hw1/hw1.html#페이지-2",
    "title": "hw1",
    "section": "130 페이지",
    "text": "130 페이지\n\nQ1. midwest.csv를 불러와 데이터의 특징을 파악하세요.\n\n# midwest.csv 데이터 불러오기\nmidwest_raw = pd.read_csv('C:/Users/USER/Documents/LS빅데이터스쿨/lsbigdata-project1/data/midwest.csv')\nmidwest_new = midwest_raw.copy()\nmidwest_new\n\nmidwest_new.head()\nmidwest_new.tail()\nmidwest_new.shape\nmidwest_new.info()\nmidwest_new.describe()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 437 entries, 0 to 436\nData columns (total 28 columns):\n #   Column                Non-Null Count  Dtype  \n---  ------                --------------  -----  \n 0   PID                   437 non-null    int64  \n 1   county                437 non-null    object \n 2   state                 437 non-null    object \n 3   area                  437 non-null    float64\n 4   poptotal              437 non-null    int64  \n 5   popdensity            437 non-null    float64\n 6   popwhite              437 non-null    int64  \n 7   popblack              437 non-null    int64  \n 8   popamerindian         437 non-null    int64  \n 9   popasian              437 non-null    int64  \n 10  popother              437 non-null    int64  \n 11  percwhite             437 non-null    float64\n 12  percblack             437 non-null    float64\n 13  percamerindan         437 non-null    float64\n 14  percasian             437 non-null    float64\n 15  percother             437 non-null    float64\n 16  popadults             437 non-null    int64  \n 17  perchsd               437 non-null    float64\n 18  percollege            437 non-null    float64\n 19  percprof              437 non-null    float64\n 20  poppovertyknown       437 non-null    int64  \n 21  percpovertyknown      437 non-null    float64\n 22  percbelowpoverty      437 non-null    float64\n 23  percchildbelowpovert  437 non-null    float64\n 24  percadultpoverty      437 non-null    float64\n 25  percelderlypoverty    437 non-null    float64\n 26  inmetro               437 non-null    int64  \n 27  category              437 non-null    object \ndtypes: float64(15), int64(10), object(3)\nmemory usage: 95.7+ KB\n\n\n\n\n\n\n\n\n\nPID\narea\npoptotal\npopdensity\npopwhite\npopblack\npopamerindian\npopasian\npopother\npercwhite\n...\nperchsd\npercollege\npercprof\npoppovertyknown\npercpovertyknown\npercbelowpoverty\npercchildbelowpovert\npercadultpoverty\npercelderlypoverty\ninmetro\n\n\n\n\ncount\n437.000000\n437.000000\n4.370000e+02\n437.000000\n4.370000e+02\n4.370000e+02\n437.000000\n437.000000\n437.000000\n437.000000\n...\n437.000000\n437.000000\n437.000000\n4.370000e+02\n437.000000\n437.000000\n437.000000\n437.000000\n437.000000\n437.000000\n\n\nmean\n1437.338673\n0.033169\n9.613030e+04\n3097.742985\n8.183992e+04\n1.102388e+04\n343.109840\n1310.464531\n1612.931350\n95.558441\n...\n73.965546\n18.272736\n4.447259\n9.364228e+04\n97.110267\n12.510505\n16.447464\n10.918798\n11.389043\n0.343249\n\n\nstd\n876.390266\n0.014679\n2.981705e+05\n7664.751786\n2.001966e+05\n7.895827e+04\n868.926751\n9518.394189\n18526.540699\n7.087358\n...\n5.843177\n6.261908\n2.408427\n2.932351e+05\n2.749863\n5.150155\n7.228634\n5.109166\n3.661259\n0.475338\n\n\nmin\n561.000000\n0.005000\n1.701000e+03\n85.050000\n4.160000e+02\n0.000000e+00\n4.000000\n0.000000\n0.000000\n10.694087\n...\n46.912261\n7.336108\n0.520291\n1.696000e+03\n80.902441\n2.180168\n1.918955\n1.938504\n3.547067\n0.000000\n\n\n25%\n670.000000\n0.024000\n1.884000e+04\n622.407407\n1.863000e+04\n2.900000e+01\n44.000000\n35.000000\n20.000000\n94.886032\n...\n71.325329\n14.113725\n2.997957\n1.836400e+04\n96.894572\n9.198715\n11.624088\n7.668009\n8.911763\n0.000000\n\n\n50%\n1221.000000\n0.030000\n3.532400e+04\n1156.208330\n3.447100e+04\n2.010000e+02\n94.000000\n102.000000\n66.000000\n98.032742\n...\n74.246891\n16.797562\n3.814239\n3.378800e+04\n98.169562\n11.822313\n15.270164\n10.007610\n10.869119\n0.000000\n\n\n75%\n2059.000000\n0.038000\n7.565100e+04\n2330.000000\n7.296800e+04\n1.291000e+03\n288.000000\n401.000000\n345.000000\n99.074935\n...\n77.195345\n20.549893\n4.949324\n7.284000e+04\n98.598636\n15.133226\n20.351878\n13.182182\n13.412162\n1.000000\n\n\nmax\n3052.000000\n0.110000\n5.105067e+06\n88018.396600\n3.204947e+06\n1.317147e+06\n10289.000000\n188565.000000\n384119.000000\n99.822821\n...\n88.898674\n48.078510\n20.791321\n5.023523e+06\n99.860384\n48.691099\n64.308477\n43.312464\n31.161972\n1.000000\n\n\n\n\n8 rows × 25 columns\n\n\n\n\n\n\nQ2. poptotal(전체 인구) 변수를 total로, popasian(아시아 인구)변수를 asian으로 수정하세요.\n\n#poptotal -&gt; total\nmidwest_new = midwest_new.rename(columns = {'poptotal' : 'total'})\n\n#popasian -&gt; asian\nmidwest_new = midwest_new.rename(columns = {'popasian' : 'asian'})\n\n\n\n\nQ3. total, asian 변수를 이용해 ‘전체 인구 대비 아시아 인구 백분율’ 파생변수를 추가하고, 히스토그램을 만들어 분포를 살펴보세요.\n\nmidwest_new['a_ratio'] = (midwest_new[\"asian\"] / midwest_new[\"total\"]) * 100\nmidwest_new['a_ratio'].plot.hist()\nimport matplotlib.pyplot as plt\nplt.show()\nplt.clf()\n\n\n\n\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;\n\n\n\n\n\nQ4. 아시아 인구 백분율 전체 평균을 구하고, 평균을 초과하면 'large', 그 외에는 'small'을 부여한 파생변수를 만들어 보세요.\n\nimport numpy as np\n#아시아 인구 백분율 전체 평균\nmidwest_new['a_mean'] = (midwest_new['a_ratio'].mean())\n\n#평균을 초과하는지 비교\nmidwest_new['vs_mean'] = np.where(midwest_new['a_ratio'] &gt; midwest_new['a_mean'], 'large', 'small')\nmidwest_new\n\n\n\n\n\n\n\n\nPID\ncounty\nstate\narea\ntotal\npopdensity\npopwhite\npopblack\npopamerindian\nasian\n...\npercpovertyknown\npercbelowpoverty\npercchildbelowpovert\npercadultpoverty\npercelderlypoverty\ninmetro\ncategory\na_ratio\na_mean\nvs_mean\n\n\n\n\n0\n561\nADAMS\nIL\n0.052\n66090\n1270.961540\n63917\n1702\n98\n249\n...\n96.274777\n13.151443\n18.011717\n11.009776\n12.443812\n0\nAAR\n0.376759\n0.487246\nsmall\n\n\n1\n562\nALEXANDER\nIL\n0.014\n10626\n759.000000\n7054\n3496\n19\n48\n...\n99.087145\n32.244278\n45.826514\n27.385647\n25.228976\n0\nLHR\n0.451722\n0.487246\nsmall\n\n\n2\n563\nBOND\nIL\n0.022\n14991\n681.409091\n14477\n429\n35\n16\n...\n94.956974\n12.068844\n14.036061\n10.852090\n12.697410\n0\nAAR\n0.106731\n0.487246\nsmall\n\n\n3\n564\nBOONE\nIL\n0.017\n30806\n1812.117650\n29344\n127\n46\n150\n...\n98.477569\n7.209019\n11.179536\n5.536013\n6.217047\n1\nALU\n0.486918\n0.487246\nsmall\n\n\n4\n565\nBROWN\nIL\n0.018\n5836\n324.222222\n5264\n547\n14\n5\n...\n82.505140\n13.520249\n13.022889\n11.143211\n19.200000\n0\nAAR\n0.085675\n0.487246\nsmall\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n432\n3048\nWAUKESHA\nWI\n0.034\n304715\n8962.205880\n298313\n1096\n672\n2699\n...\n98.387674\n3.121060\n3.785820\n2.590061\n4.085479\n1\nHLU\n0.885746\n0.487246\nlarge\n\n\n433\n3049\nWAUPACA\nWI\n0.045\n46104\n1024.533330\n45695\n22\n125\n92\n...\n96.330036\n8.488697\n10.071411\n6.953799\n10.338641\n0\nAAR\n0.199549\n0.487246\nsmall\n\n\n434\n3050\nWAUSHARA\nWI\n0.037\n19385\n523.918919\n19094\n29\n70\n43\n...\n98.854785\n13.786985\n20.050708\n11.695784\n11.804558\n0\nAAR\n0.221821\n0.487246\nsmall\n\n\n435\n3051\nWINNEBAGO\nWI\n0.035\n140320\n4009.142860\n136822\n697\n685\n1728\n...\n95.460376\n8.804031\n10.592031\n8.660587\n6.661094\n1\nHAU\n1.231471\n0.487246\nlarge\n\n\n436\n3052\nWOOD\nWI\n0.048\n73605\n1533.437500\n72157\n90\n481\n722\n...\n98.750085\n8.525831\n11.162997\n7.375656\n7.882918\n0\nAAR\n0.980912\n0.487246\nlarge\n\n\n\n\n437 rows × 31 columns\n\n\n\n\n\n\nQ5. 'large'와 'small'에 해당하는 지역이 얼마나 많은지 빈도표와 빈도 막대 그래프를 만들어 확인해 보세요.\n\n#빈도 구하기\ncount_vs = midwest_new['vs_mean'].value_counts()\ncount_vs\n\n#막대 그래프 만들기\ncount_vs.plot.bar(rot = 0)"
  },
  {
    "objectID": "posts/hw1/index.html",
    "href": "posts/hw1/index.html",
    "title": "LS 빅데이터 스쿨 Homework 1",
    "section": "",
    "text": "1일차|2x2"
  },
  {
    "objectID": "posts/hw1/index.html#페이지",
    "href": "posts/hw1/index.html#페이지",
    "title": "LS 빅데이터 스쿨 Homework 1",
    "section": "84 페이지",
    "text": "84 페이지\n\nQ1. 다음 표의 내용을 데이터 프레임으로 만들어 출력해 보세요.\n\n#!pip install pandas\nimport pandas as pd\n\ndf = pd.DataFrame({\"제품\"   : [\"사과\",\"딸기\",\"수박\"],\n                   \"가격\"   : [1800, 1500, 3000],\n                   \"판매량\" : [24, 38, 13]})\ndf\n\n\n\n\n\n\n\n\n제품\n가격\n판매량\n\n\n\n\n0\n사과\n1800\n24\n\n\n1\n딸기\n1500\n38\n\n\n2\n수박\n3000\n13\n\n\n\n\n\n\n\n\n\n\nQ2. 앞에서 만든 데이터 프레임을 이용해 과일의 가격 평균과 판매량 평균을 구해 보세요.\n\nprice_avg = sum(df[\"가격\"]) / 3\nvol_avg = sum(df[\"판매량\"]) / 3\n\nprint(\"과일 가격의 평균은\", price_avg)\nprint(\"과일 판매량의 평균은\", vol_avg)\n\n과일 가격의 평균은 2100.0\n과일 판매량의 평균은 25.0"
  },
  {
    "objectID": "posts/hw1/index.html#페이지-1",
    "href": "posts/hw1/index.html#페이지-1",
    "title": "LS 빅데이터 스쿨 Homework 1",
    "section": "115 페이지",
    "text": "115 페이지\n\nQ1. mpg 데이터를 불러와 복사본을 만드세요.\n\n# mpg 데이터 불러오기\nmpg_raw = pd.read_csv('C:/Users/USER/Documents/LS빅데이터스쿨/lsbigdata-project1/data/mpg.csv')\nmpg_new = mpg_raw.copy()\nmpg_new\n\n\n\n\n\n\n\n\nmanufacturer\nmodel\ndispl\nyear\ncyl\ntrans\ndrv\ncty\nhwy\nfl\ncategory\n\n\n\n\n0\naudi\na4\n1.8\n1999\n4\nauto(l5)\nf\n18\n29\np\ncompact\n\n\n1\naudi\na4\n1.8\n1999\n4\nmanual(m5)\nf\n21\n29\np\ncompact\n\n\n2\naudi\na4\n2.0\n2008\n4\nmanual(m6)\nf\n20\n31\np\ncompact\n\n\n3\naudi\na4\n2.0\n2008\n4\nauto(av)\nf\n21\n30\np\ncompact\n\n\n4\naudi\na4\n2.8\n1999\n6\nauto(l5)\nf\n16\n26\np\ncompact\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n229\nvolkswagen\npassat\n2.0\n2008\n4\nauto(s6)\nf\n19\n28\np\nmidsize\n\n\n230\nvolkswagen\npassat\n2.0\n2008\n4\nmanual(m6)\nf\n21\n29\np\nmidsize\n\n\n231\nvolkswagen\npassat\n2.8\n1999\n6\nauto(l5)\nf\n16\n26\np\nmidsize\n\n\n232\nvolkswagen\npassat\n2.8\n1999\n6\nmanual(m5)\nf\n18\n26\np\nmidsize\n\n\n233\nvolkswagen\npassat\n3.6\n2008\n6\nauto(s6)\nf\n17\n26\np\nmidsize\n\n\n\n\n234 rows × 11 columns\n\n\n\n\n\n\nQ2. 복사본 데이터를 이용해 cty는 city로, hwy는 highway로 수정하세요.\n\n#cty -&gt; city\nmpg_new = mpg_new.rename(columns = {'cty' : 'city'})\n\n#hwy -&gt; highway\nmpg_new = mpg_new.rename(columns = {'hwy' : 'highway'})\n\n\n\n\nQ3. 데이터 일부를 출력해 변수명이 바뀌었는지 확인해 보세요. 다음과 같은 결과물이 출력되어야 합니다.\n\nmpg_new.head()\n\n\n\n\n\n\n\n\nmanufacturer\nmodel\ndispl\nyear\ncyl\ntrans\ndrv\ncity\nhighway\nfl\ncategory\n\n\n\n\n0\naudi\na4\n1.8\n1999\n4\nauto(l5)\nf\n18\n29\np\ncompact\n\n\n1\naudi\na4\n1.8\n1999\n4\nmanual(m5)\nf\n21\n29\np\ncompact\n\n\n2\naudi\na4\n2.0\n2008\n4\nmanual(m6)\nf\n20\n31\np\ncompact\n\n\n3\naudi\na4\n2.0\n2008\n4\nauto(av)\nf\n21\n30\np\ncompact\n\n\n4\naudi\na4\n2.8\n1999\n6\nauto(l5)\nf\n16\n26\np\ncompact"
  },
  {
    "objectID": "posts/hw1/index.html#페이지-2",
    "href": "posts/hw1/index.html#페이지-2",
    "title": "LS 빅데이터 스쿨 Homework 1",
    "section": "130 페이지",
    "text": "130 페이지\n\nQ1. midwest.csv를 불러와 데이터의 특징을 파악하세요.\n\n# midwest.csv 데이터 불러오기\nmidwest_raw = pd.read_csv('C:/Users/USER/Documents/LS빅데이터스쿨/lsbigdata-project1/data/midwest.csv')\nmidwest_new = midwest_raw.copy()\nmidwest_new\n\nmidwest_new.head()\nmidwest_new.tail()\nmidwest_new.shape\nmidwest_new.info()\nmidwest_new.describe()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 437 entries, 0 to 436\nData columns (total 28 columns):\n #   Column                Non-Null Count  Dtype  \n---  ------                --------------  -----  \n 0   PID                   437 non-null    int64  \n 1   county                437 non-null    object \n 2   state                 437 non-null    object \n 3   area                  437 non-null    float64\n 4   poptotal              437 non-null    int64  \n 5   popdensity            437 non-null    float64\n 6   popwhite              437 non-null    int64  \n 7   popblack              437 non-null    int64  \n 8   popamerindian         437 non-null    int64  \n 9   popasian              437 non-null    int64  \n 10  popother              437 non-null    int64  \n 11  percwhite             437 non-null    float64\n 12  percblack             437 non-null    float64\n 13  percamerindan         437 non-null    float64\n 14  percasian             437 non-null    float64\n 15  percother             437 non-null    float64\n 16  popadults             437 non-null    int64  \n 17  perchsd               437 non-null    float64\n 18  percollege            437 non-null    float64\n 19  percprof              437 non-null    float64\n 20  poppovertyknown       437 non-null    int64  \n 21  percpovertyknown      437 non-null    float64\n 22  percbelowpoverty      437 non-null    float64\n 23  percchildbelowpovert  437 non-null    float64\n 24  percadultpoverty      437 non-null    float64\n 25  percelderlypoverty    437 non-null    float64\n 26  inmetro               437 non-null    int64  \n 27  category              437 non-null    object \ndtypes: float64(15), int64(10), object(3)\nmemory usage: 95.7+ KB\n\n\n\n\n\n\n\n\n\nPID\narea\npoptotal\npopdensity\npopwhite\npopblack\npopamerindian\npopasian\npopother\npercwhite\n...\nperchsd\npercollege\npercprof\npoppovertyknown\npercpovertyknown\npercbelowpoverty\npercchildbelowpovert\npercadultpoverty\npercelderlypoverty\ninmetro\n\n\n\n\ncount\n437.000000\n437.000000\n4.370000e+02\n437.000000\n4.370000e+02\n4.370000e+02\n437.000000\n437.000000\n437.000000\n437.000000\n...\n437.000000\n437.000000\n437.000000\n4.370000e+02\n437.000000\n437.000000\n437.000000\n437.000000\n437.000000\n437.000000\n\n\nmean\n1437.338673\n0.033169\n9.613030e+04\n3097.742985\n8.183992e+04\n1.102388e+04\n343.109840\n1310.464531\n1612.931350\n95.558441\n...\n73.965546\n18.272736\n4.447259\n9.364228e+04\n97.110267\n12.510505\n16.447464\n10.918798\n11.389043\n0.343249\n\n\nstd\n876.390266\n0.014679\n2.981705e+05\n7664.751786\n2.001966e+05\n7.895827e+04\n868.926751\n9518.394189\n18526.540699\n7.087358\n...\n5.843177\n6.261908\n2.408427\n2.932351e+05\n2.749863\n5.150155\n7.228634\n5.109166\n3.661259\n0.475338\n\n\nmin\n561.000000\n0.005000\n1.701000e+03\n85.050000\n4.160000e+02\n0.000000e+00\n4.000000\n0.000000\n0.000000\n10.694087\n...\n46.912261\n7.336108\n0.520291\n1.696000e+03\n80.902441\n2.180168\n1.918955\n1.938504\n3.547067\n0.000000\n\n\n25%\n670.000000\n0.024000\n1.884000e+04\n622.407407\n1.863000e+04\n2.900000e+01\n44.000000\n35.000000\n20.000000\n94.886032\n...\n71.325329\n14.113725\n2.997957\n1.836400e+04\n96.894572\n9.198715\n11.624088\n7.668009\n8.911763\n0.000000\n\n\n50%\n1221.000000\n0.030000\n3.532400e+04\n1156.208330\n3.447100e+04\n2.010000e+02\n94.000000\n102.000000\n66.000000\n98.032742\n...\n74.246891\n16.797562\n3.814239\n3.378800e+04\n98.169562\n11.822313\n15.270164\n10.007610\n10.869119\n0.000000\n\n\n75%\n2059.000000\n0.038000\n7.565100e+04\n2330.000000\n7.296800e+04\n1.291000e+03\n288.000000\n401.000000\n345.000000\n99.074935\n...\n77.195345\n20.549893\n4.949324\n7.284000e+04\n98.598636\n15.133226\n20.351878\n13.182182\n13.412162\n1.000000\n\n\nmax\n3052.000000\n0.110000\n5.105067e+06\n88018.396600\n3.204947e+06\n1.317147e+06\n10289.000000\n188565.000000\n384119.000000\n99.822821\n...\n88.898674\n48.078510\n20.791321\n5.023523e+06\n99.860384\n48.691099\n64.308477\n43.312464\n31.161972\n1.000000\n\n\n\n\n8 rows × 25 columns\n\n\n\n\n\n\nQ2. poptotal(전체 인구) 변수를 total로, popasian(아시아 인구)변수를 asian으로 수정하세요.\n\n#poptotal -&gt; total\nmidwest_new = midwest_new.rename(columns = {'poptotal' : 'total'})\n\n#popasian -&gt; asian\nmidwest_new = midwest_new.rename(columns = {'popasian' : 'asian'})\n\n\n\n\nQ3. total, asian 변수를 이용해 ‘전체 인구 대비 아시아 인구 백분율’ 파생변수를 추가하고, 히스토그램을 만들어 분포를 살펴보세요.\n\nmidwest_new['a_ratio'] = (midwest_new[\"asian\"] / midwest_new[\"total\"]) * 100\nmidwest_new['a_ratio'].plot.hist()\nimport matplotlib.pyplot as plt\nplt.show()\nplt.clf()\n\n\n\n\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;\n\n\n\n\n\nQ4. 아시아 인구 백분율 전체 평균을 구하고, 평균을 초과하면 'large', 그 외에는 'small'을 부여한 파생변수를 만들어 보세요.\n\nimport numpy as np\n#아시아 인구 백분율 전체 평균\nmidwest_new['a_mean'] = (midwest_new['a_ratio'].mean())\n\n#평균을 초과하는지 비교\nmidwest_new['vs_mean'] = np.where(midwest_new['a_ratio'] &gt; midwest_new['a_mean'], 'large', 'small')\nmidwest_new\n\n\n\n\n\n\n\n\nPID\ncounty\nstate\narea\ntotal\npopdensity\npopwhite\npopblack\npopamerindian\nasian\n...\npercpovertyknown\npercbelowpoverty\npercchildbelowpovert\npercadultpoverty\npercelderlypoverty\ninmetro\ncategory\na_ratio\na_mean\nvs_mean\n\n\n\n\n0\n561\nADAMS\nIL\n0.052\n66090\n1270.961540\n63917\n1702\n98\n249\n...\n96.274777\n13.151443\n18.011717\n11.009776\n12.443812\n0\nAAR\n0.376759\n0.487246\nsmall\n\n\n1\n562\nALEXANDER\nIL\n0.014\n10626\n759.000000\n7054\n3496\n19\n48\n...\n99.087145\n32.244278\n45.826514\n27.385647\n25.228976\n0\nLHR\n0.451722\n0.487246\nsmall\n\n\n2\n563\nBOND\nIL\n0.022\n14991\n681.409091\n14477\n429\n35\n16\n...\n94.956974\n12.068844\n14.036061\n10.852090\n12.697410\n0\nAAR\n0.106731\n0.487246\nsmall\n\n\n3\n564\nBOONE\nIL\n0.017\n30806\n1812.117650\n29344\n127\n46\n150\n...\n98.477569\n7.209019\n11.179536\n5.536013\n6.217047\n1\nALU\n0.486918\n0.487246\nsmall\n\n\n4\n565\nBROWN\nIL\n0.018\n5836\n324.222222\n5264\n547\n14\n5\n...\n82.505140\n13.520249\n13.022889\n11.143211\n19.200000\n0\nAAR\n0.085675\n0.487246\nsmall\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n432\n3048\nWAUKESHA\nWI\n0.034\n304715\n8962.205880\n298313\n1096\n672\n2699\n...\n98.387674\n3.121060\n3.785820\n2.590061\n4.085479\n1\nHLU\n0.885746\n0.487246\nlarge\n\n\n433\n3049\nWAUPACA\nWI\n0.045\n46104\n1024.533330\n45695\n22\n125\n92\n...\n96.330036\n8.488697\n10.071411\n6.953799\n10.338641\n0\nAAR\n0.199549\n0.487246\nsmall\n\n\n434\n3050\nWAUSHARA\nWI\n0.037\n19385\n523.918919\n19094\n29\n70\n43\n...\n98.854785\n13.786985\n20.050708\n11.695784\n11.804558\n0\nAAR\n0.221821\n0.487246\nsmall\n\n\n435\n3051\nWINNEBAGO\nWI\n0.035\n140320\n4009.142860\n136822\n697\n685\n1728\n...\n95.460376\n8.804031\n10.592031\n8.660587\n6.661094\n1\nHAU\n1.231471\n0.487246\nlarge\n\n\n436\n3052\nWOOD\nWI\n0.048\n73605\n1533.437500\n72157\n90\n481\n722\n...\n98.750085\n8.525831\n11.162997\n7.375656\n7.882918\n0\nAAR\n0.980912\n0.487246\nlarge\n\n\n\n\n437 rows × 31 columns\n\n\n\n\n\n\nQ5. 'large'와 'small'에 해당하는 지역이 얼마나 많은지 빈도표와 빈도 막대 그래프를 만들어 확인해 보세요.\n\n#빈도 구하기\ncount_vs = midwest_new['vs_mean'].value_counts()\ncount_vs\n\n#막대 그래프 만들기\ncount_vs.plot.bar(rot = 0)"
  },
  {
    "objectID": "posts/hw2/index.html",
    "href": "posts/hw2/index.html",
    "title": "LS 빅데이터 스쿨 Homework 2",
    "section": "",
    "text": "# mpg 데이터 불러오기\nimport pandas as pd\nimport numpy as np\nmpg = pd.read_csv('C:/Users/USER/Documents/LS빅데이터스쿨/lsbigdata-project1/data/mpg.csv')\n\nmpg_a = mpg.query('displ &lt;= 4')\nmpg_b = mpg.query('displ &gt;= 5')\n\nmpg_a['hwy'].mean(), mpg_b['hwy'].mean()\n\n(np.float64(25.96319018404908), np.float64(18.07894736842105))\n\n\n\n\n\n\nmpg_audi = mpg.query(\"manufacturer == 'audi'\")\nmpg_toyota = mpg.query(\"manufacturer == 'toyota'\")\n\nmpg_audi['cty'].mean(), mpg_toyota['cty'].mean()\n\n(np.float64(17.61111111111111), np.float64(18.529411764705884))\n\n\n\n\n\n\nmpg_new = mpg.query('manufacturer in [\"chevrolet\", \"ford\", \"honda\"]')\nmpg_new['hwy'].mean()\n\nnp.float64(22.50943396226415)"
  },
  {
    "objectID": "posts/hw2/index.html#페이지",
    "href": "posts/hw2/index.html#페이지",
    "title": "LS 빅데이터 스쿨 Homework 2",
    "section": "144 페이지",
    "text": "144 페이지\n\nQ1. 자동차 배기량에 따라 고속도로 연비가 다른지 알아보려고 합니다. displ(배기량)이 4 이하인 자동차와 5 이상인 자동차 중 어떤 자동차의 hwy(고속도로 연비) 평균이 더 높은지 알아보세요.\n\n# mpg 데이터 불러오기\nimport pandas as pd\nimport numpy as np\nmpg = pd.read_csv('C:/Users/USER/Documents/LS빅데이터스쿨/lsbigdata-project1/data/mpg.csv')\n\nmpg_a = mpg.query('displ &lt;= 4')\nmpg_b = mpg.query('displ &gt;= 5')\n\nmpg_a['hwy'].mean(), mpg_b['hwy'].mean()\n\n(np.float64(25.96319018404908), np.float64(18.07894736842105))\n\n\n\n\nQ2. 자동차 제조 회사에 따라 도시 연비가 어떻게 다른지 알아보려고 합니다. 'audi'와 'toyota'중 어느 manufacture(자동차 제조 회사)의 cty(도시연비) 평균이 더 높은지 알아보세요.\n\nmpg_audi = mpg.query(\"manufacturer == 'audi'\")\nmpg_toyota = mpg.query(\"manufacturer == 'toyota'\")\n\nmpg_audi['cty'].mean(), mpg_toyota['cty'].mean()\n\n(np.float64(17.61111111111111), np.float64(18.529411764705884))\n\n\n\n\nQ3. 'chevrolet', 'ford', 'honda' 자동차의 고속도로 연비 평균을 알아보려고 합니다. 세 회사의 데이터를 추출한 다음 hwy전체 평균을 구해 보세요.\n\nmpg_new = mpg.query('manufacturer in [\"chevrolet\", \"ford\", \"honda\"]')\nmpg_new['hwy'].mean()\n\nnp.float64(22.50943396226415)"
  },
  {
    "objectID": "posts/hw2/index.html#페이지-1",
    "href": "posts/hw2/index.html#페이지-1",
    "title": "LS 빅데이터 스쿨 Homework 2",
    "section": "153 페이지",
    "text": "153 페이지\n\nQ1. 'audi'에서 생산한 자동차 중에 어떤 자동차 모델의 hwy(고속도로 연비)가 높은지 알아보려고 합니다. audi'에서 생산한 자동차 중 hwy가 1~5위에 해당하는 자동차의 데이터를 출력하세요.\n\naudi_mpg = mpg.query(\"manufacturer == 'audi'\")\naudi_mpg.sort_values('hwy', ascending = False).head()\n\nmpg.query(\"manufacturer == 'audi'\") \\\n   .sort_values('hwy', ascending = False) \\\n   .head()\n\n\n\n\n\n\n\n\nmanufacturer\nmodel\ndispl\nyear\ncyl\ntrans\ndrv\ncty\nhwy\nfl\ncategory\n\n\n\n\n2\naudi\na4\n2.0\n2008\n4\nmanual(m6)\nf\n20\n31\np\ncompact\n\n\n3\naudi\na4\n2.0\n2008\n4\nauto(av)\nf\n21\n30\np\ncompact\n\n\n1\naudi\na4\n1.8\n1999\n4\nmanual(m5)\nf\n21\n29\np\ncompact\n\n\n0\naudi\na4\n1.8\n1999\n4\nauto(l5)\nf\n18\n29\np\ncompact\n\n\n9\naudi\na4 quattro\n2.0\n2008\n4\nmanual(m6)\n4\n20\n28\np\ncompact"
  },
  {
    "objectID": "posts/hw2/index.html#페이지-2",
    "href": "posts/hw2/index.html#페이지-2",
    "title": "LS 빅데이터 스쿨 Homework 2",
    "section": "158 페이지",
    "text": "158 페이지\nmpg데이터는 연비를 나타내는 변수가 hwy(고속도로 연비), cty(도시 연비) 두 종류로 분리되어 있습니다. 두 변수는 각각 활용하는 대신 하나의 합산 연비 변수를 만들어 분석하려고 합니다.\n\nQ1. mpg데이터 복사본을 만들고, cty와 hwy를 더한 합산 연비 변수를 추가하세요.\n\nmpg_new = mpg.copy()\nmpg_new = mpg_new.assign(mileage = mpg_new['cty'] + mpg_new['hwy'])\nmpg_new.head()\n\n\n\n\n\n\n\n\nmanufacturer\nmodel\ndispl\nyear\ncyl\ntrans\ndrv\ncty\nhwy\nfl\ncategory\nmileage\n\n\n\n\n0\naudi\na4\n1.8\n1999\n4\nauto(l5)\nf\n18\n29\np\ncompact\n47\n\n\n1\naudi\na4\n1.8\n1999\n4\nmanual(m5)\nf\n21\n29\np\ncompact\n50\n\n\n2\naudi\na4\n2.0\n2008\n4\nmanual(m6)\nf\n20\n31\np\ncompact\n51\n\n\n3\naudi\na4\n2.0\n2008\n4\nauto(av)\nf\n21\n30\np\ncompact\n51\n\n\n4\naudi\na4\n2.8\n1999\n6\nauto(l5)\nf\n16\n26\np\ncompact\n42\n\n\n\n\n\n\n\n\n\n\nQ2. 앞에서 만든 ’합산 연비 변수’를 2로 나눠 ’평균 연비 변수’를 추가하세요.\n\nmpg_new = mpg_new.assign(mileage_mean = mpg_new['mileage'] / 2)\nmpg_new.head()\n\n\n\n\n\n\n\n\nmanufacturer\nmodel\ndispl\nyear\ncyl\ntrans\ndrv\ncty\nhwy\nfl\ncategory\nmileage\nmileage_mean\n\n\n\n\n0\naudi\na4\n1.8\n1999\n4\nauto(l5)\nf\n18\n29\np\ncompact\n47\n23.5\n\n\n1\naudi\na4\n1.8\n1999\n4\nmanual(m5)\nf\n21\n29\np\ncompact\n50\n25.0\n\n\n2\naudi\na4\n2.0\n2008\n4\nmanual(m6)\nf\n20\n31\np\ncompact\n51\n25.5\n\n\n3\naudi\na4\n2.0\n2008\n4\nauto(av)\nf\n21\n30\np\ncompact\n51\n25.5\n\n\n4\naudi\na4\n2.8\n1999\n6\nauto(l5)\nf\n16\n26\np\ncompact\n42\n21.0\n\n\n\n\n\n\n\n\n\n\nQ3. ’평균 연비 변수’가 가장 높은 자동차 3종의 데이터를 출력하세요.\n\nmpg_new.sort_values('mileage_mean', ascending = False).head(3)\n\n\n\n\n\n\n\n\nmanufacturer\nmodel\ndispl\nyear\ncyl\ntrans\ndrv\ncty\nhwy\nfl\ncategory\nmileage\nmileage_mean\n\n\n\n\n221\nvolkswagen\nnew beetle\n1.9\n1999\n4\nmanual(m5)\nf\n35\n44\nd\nsubcompact\n79\n39.5\n\n\n212\nvolkswagen\njetta\n1.9\n1999\n4\nmanual(m5)\nf\n33\n44\nd\ncompact\n77\n38.5\n\n\n222\nvolkswagen\nnew beetle\n1.9\n1999\n4\nauto(l4)\nf\n29\n41\nd\nsubcompact\n70\n35.0\n\n\n\n\n\n\n\n\n\n\nQ4. 1~3번 문제를 해결할 수 있는 하나로 연결된 pandas구문을 만들어 실행해 보세요. 데이터는 복사본 대신 mpg원본을 이용하세요.\n\nmpg.assign(mileage = mpg_new['cty'] + mpg_new['hwy']) \\\n   .assign(mileage_mean = mpg_new['mileage'] / 2) \\\n   .sort_values('mileage_mean', ascending = False).head(3)\n\n\n\n\n\n\n\n\nmanufacturer\nmodel\ndispl\nyear\ncyl\ntrans\ndrv\ncty\nhwy\nfl\ncategory\nmileage\nmileage_mean\n\n\n\n\n221\nvolkswagen\nnew beetle\n1.9\n1999\n4\nmanual(m5)\nf\n35\n44\nd\nsubcompact\n79\n39.5\n\n\n212\nvolkswagen\njetta\n1.9\n1999\n4\nmanual(m5)\nf\n33\n44\nd\ncompact\n77\n38.5\n\n\n222\nvolkswagen\nnew beetle\n1.9\n1999\n4\nauto(l4)\nf\n29\n41\nd\nsubcompact\n70\n35.0"
  },
  {
    "objectID": "posts/hw3/index.html#페이지",
    "href": "posts/hw3/index.html#페이지",
    "title": "LS 빅데이터 스쿨 Homework 3",
    "section": "173 페이지",
    "text": "173 페이지\n\nimport pandas as pd\nimport numpy as np\n\nmpg = pd.read_csv('C:/Users/USER/Documents/LS빅데이터스쿨/lsbigdata-project1/data/mpg.csv')\n\nfuel = pd.DataFrame({'fl'       : ['c','d','e','p','r'],\n                     'price_fl' : [2.35, 2.38, 2.11, 2.76, 2.22]})\nprint(fuel)\n\nprint(mpg)\n\n  fl  price_fl\n0  c      2.35\n1  d      2.38\n2  e      2.11\n3  p      2.76\n4  r      2.22\n    manufacturer   model  displ  year  cyl       trans drv  cty  hwy fl  \\\n0           audi      a4    1.8  1999    4    auto(l5)   f   18   29  p   \n1           audi      a4    1.8  1999    4  manual(m5)   f   21   29  p   \n2           audi      a4    2.0  2008    4  manual(m6)   f   20   31  p   \n3           audi      a4    2.0  2008    4    auto(av)   f   21   30  p   \n4           audi      a4    2.8  1999    6    auto(l5)   f   16   26  p   \n..           ...     ...    ...   ...  ...         ...  ..  ...  ... ..   \n229   volkswagen  passat    2.0  2008    4    auto(s6)   f   19   28  p   \n230   volkswagen  passat    2.0  2008    4  manual(m6)   f   21   29  p   \n231   volkswagen  passat    2.8  1999    6    auto(l5)   f   16   26  p   \n232   volkswagen  passat    2.8  1999    6  manual(m5)   f   18   26  p   \n233   volkswagen  passat    3.6  2008    6    auto(s6)   f   17   26  p   \n\n    category  \n0    compact  \n1    compact  \n2    compact  \n3    compact  \n4    compact  \n..       ...  \n229  midsize  \n230  midsize  \n231  midsize  \n232  midsize  \n233  midsize  \n\n[234 rows x 11 columns]\n\n\n\nQ1. mpg데이터에는 연료 종류를 나타낸 fl변수는 있지만 연료 가격을 나타낸 변수는 없습니다. 앞에서 만든 fuel데이터를 이용해 mpg데이터에 price_fl(연료 가격) 변수를 추가하세요.\n\nmpg = pd.merge(mpg, fuel, how = 'left', on = 'fl')\nprint(mpg)\n\n    manufacturer   model  displ  year  cyl       trans drv  cty  hwy fl  \\\n0           audi      a4    1.8  1999    4    auto(l5)   f   18   29  p   \n1           audi      a4    1.8  1999    4  manual(m5)   f   21   29  p   \n2           audi      a4    2.0  2008    4  manual(m6)   f   20   31  p   \n3           audi      a4    2.0  2008    4    auto(av)   f   21   30  p   \n4           audi      a4    2.8  1999    6    auto(l5)   f   16   26  p   \n..           ...     ...    ...   ...  ...         ...  ..  ...  ... ..   \n229   volkswagen  passat    2.0  2008    4    auto(s6)   f   19   28  p   \n230   volkswagen  passat    2.0  2008    4  manual(m6)   f   21   29  p   \n231   volkswagen  passat    2.8  1999    6    auto(l5)   f   16   26  p   \n232   volkswagen  passat    2.8  1999    6  manual(m5)   f   18   26  p   \n233   volkswagen  passat    3.6  2008    6    auto(s6)   f   17   26  p   \n\n    category  price_fl  \n0    compact      2.76  \n1    compact      2.76  \n2    compact      2.76  \n3    compact      2.76  \n4    compact      2.76  \n..       ...       ...  \n229  midsize      2.76  \n230  midsize      2.76  \n231  midsize      2.76  \n232  midsize      2.76  \n233  midsize      2.76  \n\n[234 rows x 12 columns]\n\n\n\n\n\nQ2. 연료 가격 변수가 잘 추가됐는지 확인하기 위해 model,fl,price_fl 변수를 추출해 앞부분 5행을 출력해 보세요.\n\nmpg[['model','fl','price_fl']].head()\n\n\n\n\n\n\n\n\nmodel\nfl\nprice_fl\n\n\n\n\n0\na4\np\n2.76\n\n\n1\na4\np\n2.76\n\n\n2\na4\np\n2.76\n\n\n3\na4\np\n2.76\n\n\n4\na4\np\n2.76"
  },
  {
    "objectID": "posts/hw4/index.html",
    "href": "posts/hw4/index.html",
    "title": "LS 빅데이터 스쿨 Homework 4",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import uniform\n\n# X ~ U(3,7)\nx=uniform.rvs(loc=3, scale=4, size=20*10000).reshape(-1,20)\nx.shape\n\n# s_2 정의\ns_2 = np.var(x, axis=1, ddof=1)\ns_2\n\n# s_2 그리기\nsns.histplot(s_2, stat=\"density\", color = 'red', label = 'n-1')\nplt.legend()\nplt.show()\nplt.clf()\n\n\n\n\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;\n\n\n\n# k_2 정의\nk_2 = np.var(x, axis=1, ddof=0)\nk_2\n\n# k_2 그리기\nsns.histplot(k_2, stat=\"density\", color = 'blue', label = 'n')\nplt.legend()\nplt.show()\nplt.clf()\n\n\n\n\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;\n\n\n\n\n\n\n# 모분산\nv = np.var(x)\n\n# s_2 그래프에 모분산 표시\nsns.histplot(s_2, stat=\"density\", color = 'red', label = 'n-1')\nplt.axvline(v, color='green', linestyle ='-', linewidth=2)\nplt.legend()\nplt.show()\nplt.clf()\n\n\n\n\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;\n\n\n\n# k_2 그래프에 모분산 표시\nsns.histplot(k_2, stat=\"density\", color = 'blue', label = 'n')\nplt.axvline(v, color='green', linestyle ='-', linewidth=2)\nplt.legend()\nplt.show()\nplt.clf()\n\n\n\n\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;\n\n\n\n\n\n\ns_2에 중앙이 모분산 막대에 더 가깝게 위치하고 있음.\nk_2의 분산은 모분산보다 왼쪽으로 치우쳐 있음.\ns_2(n-1로 나누는 것)가 보다 정확한 분산 추정자료라고 생각됨."
  },
  {
    "objectID": "posts/hw4/index.html#페이지",
    "href": "posts/hw4/index.html#페이지",
    "title": "LS 빅데이터 스쿨 Homework 4",
    "section": "204 페이지",
    "text": "204 페이지\nmpg데이터와 midwest데이터를 이용해 분석 문제를 해결해 보세요.\n\nQ1. mpg데이터의 cty(도시 연비)와 hwy(고속도로 연비) 간에 어떤 관계가 있는지 알아보려고 합니다. x축은 cty, y축은 hwy로 된 산점도를 만들어 보세요.\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nmpg = pd.read_csv('C:/Users/USER/Documents/LS빅데이터스쿨/lsbigdata-project1/data/mpg.csv')\n\nsns.scatterplot(data = mpg, x='cty', y='hwy')\n\n\n\n\n\n\n\n\n\n\n\nQ2. 미국의 지역별 인구통계 정보를 담은 midwest.csv를 이용해 전체 인구와 아시아인 인구 간에 어떤 관계가 있는지 알아보려고 합니다. x축은 poptotal(전체 인구), y축은 popasian(아시아인 인구)으로 된 산점도를 만들어 보세요. 전체 인구는 50만 명 이하, 아시아인 인구는 1만 명 이하인 지역만 산점도에 표시되게 설정하세요.\n\ndf = pd.read_csv('C:/Users/USER/Documents/LS빅데이터스쿨/lsbigdata-project1/data/midwest.csv')\ndf\nsns.scatterplot(data = df, x = 'poptotal', y = 'popasian') \\\n   .set(xlim = [0,500000], ylim = [0,10000])"
  },
  {
    "objectID": "posts/hw4/index.html#페이지-1",
    "href": "posts/hw4/index.html#페이지-1",
    "title": "LS 빅데이터 스쿨 Homework 4",
    "section": "211 페이지",
    "text": "211 페이지\nmpg데이터를 이용해 분석 문제를 해결해 보세요.\n\nQ1. 어떤 회사에서 생산한 'suv'차종의 도시 연비가 높은지 알아보려고 합니다. 'suv'차종을 대상으로 cty(도시 연비) 평균이 가장 높은 회사 다섯 곳을 막대 그래프로 표현해 보세요. 막대는 연비가 가장 높은 순으로 정렬하세요.\n\nmpg_suv = mpg.query('category == \"suv\"').groupby('manufacturer', as_index = True) \\\n       .agg(n = ('cty', 'mean'))\n\nsns.barplot(data = mpg_suv.sort_values(\"n\", ascending = False).head(5), x = 'manufacturer', y = 'n')\n\n\n\n\n\n\n\n\n\n\n\nQ2. 자동차 중에 어떤 category(자동차 종류)가 많은지 알아보려고 합니다. sns.barplot()을 이용해 자동차 종류별 빈도를 표현한 막대 그래프를 만들어 보세요. 막대는 빈도가 높은 순으로 정렬하세요.\n\nsns.countplot(data = mpg, x = 'category',\n              order = mpg['category'].value_counts().index)"
  },
  {
    "objectID": "posts/교과서 챕터 8/index.html",
    "href": "posts/교과서 챕터 8/index.html",
    "title": "교과서 챕터 8",
    "section": "",
    "text": "데이터 불러오기\n\n\nimport pandas as pd\n\nmpg = pd.read_csv('C:/Users/USER/Documents/LS빅데이터스쿨/lsbigdata-project1/data/mpg.csv')\nmpg.head()\nmpg.shape\n\n(234, 11)\n\n\n\nSeaborn 패키지 불러오기\n\n\n!pip install seaborn\n!pip install plotly.express\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\n\nRequirement already satisfied: seaborn in c:\\ds\\python\\python312\\lib\\site-packages (0.13.2)\nRequirement already satisfied: numpy!=1.24.0,&gt;=1.20 in c:\\ds\\python\\python312\\lib\\site-packages (from seaborn) (2.0.0)\nRequirement already satisfied: pandas&gt;=1.2 in c:\\ds\\python\\python312\\lib\\site-packages (from seaborn) (2.2.2)\nRequirement already satisfied: matplotlib!=3.6.1,&gt;=3.4 in c:\\ds\\python\\python312\\lib\\site-packages (from seaborn) (3.9.1)\nRequirement already satisfied: contourpy&gt;=1.0.1 in c:\\ds\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,&gt;=3.4-&gt;seaborn) (1.2.1)\nRequirement already satisfied: cycler&gt;=0.10 in c:\\ds\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,&gt;=3.4-&gt;seaborn) (0.12.1)\nRequirement already satisfied: fonttools&gt;=4.22.0 in c:\\ds\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,&gt;=3.4-&gt;seaborn) (4.53.1)\nRequirement already satisfied: kiwisolver&gt;=1.3.1 in c:\\ds\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,&gt;=3.4-&gt;seaborn) (1.4.5)\nRequirement already satisfied: packaging&gt;=20.0 in c:\\ds\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,&gt;=3.4-&gt;seaborn) (24.1)\nRequirement already satisfied: pillow&gt;=8 in c:\\ds\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,&gt;=3.4-&gt;seaborn) (10.4.0)\nRequirement already satisfied: pyparsing&gt;=2.3.1 in c:\\ds\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,&gt;=3.4-&gt;seaborn) (3.1.2)\nRequirement already satisfied: python-dateutil&gt;=2.7 in c:\\ds\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,&gt;=3.4-&gt;seaborn) (2.9.0.post0)\nRequirement already satisfied: pytz&gt;=2020.1 in c:\\ds\\python\\python312\\lib\\site-packages (from pandas&gt;=1.2-&gt;seaborn) (2024.1)\nRequirement already satisfied: tzdata&gt;=2022.7 in c:\\ds\\python\\python312\\lib\\site-packages (from pandas&gt;=1.2-&gt;seaborn) (2024.1)\nRequirement already satisfied: six&gt;=1.5 in c:\\ds\\python\\python312\\lib\\site-packages (from python-dateutil&gt;=2.7-&gt;matplotlib!=3.6.1,&gt;=3.4-&gt;seaborn) (1.16.0)\nRequirement already satisfied: plotly.express in c:\\ds\\python\\python312\\lib\\site-packages (0.4.1)\nRequirement already satisfied: pandas&gt;=0.20.0 in c:\\ds\\python\\python312\\lib\\site-packages (from plotly.express) (2.2.2)\nRequirement already satisfied: plotly&gt;=4.1.0 in c:\\ds\\python\\python312\\lib\\site-packages (from plotly.express) (5.22.0)\nRequirement already satisfied: statsmodels&gt;=0.9.0 in c:\\ds\\python\\python312\\lib\\site-packages (from plotly.express) (0.14.2)\nRequirement already satisfied: scipy&gt;=0.18 in c:\\ds\\python\\python312\\lib\\site-packages (from plotly.express) (1.14.0)\nRequirement already satisfied: patsy&gt;=0.5 in c:\\ds\\python\\python312\\lib\\site-packages (from plotly.express) (0.5.6)\nRequirement already satisfied: numpy&gt;=1.11 in c:\\ds\\python\\python312\\lib\\site-packages (from plotly.express) (2.0.0)\nRequirement already satisfied: python-dateutil&gt;=2.8.2 in c:\\ds\\python\\python312\\lib\\site-packages (from pandas&gt;=0.20.0-&gt;plotly.express) (2.9.0.post0)\nRequirement already satisfied: pytz&gt;=2020.1 in c:\\ds\\python\\python312\\lib\\site-packages (from pandas&gt;=0.20.0-&gt;plotly.express) (2024.1)\nRequirement already satisfied: tzdata&gt;=2022.7 in c:\\ds\\python\\python312\\lib\\site-packages (from pandas&gt;=0.20.0-&gt;plotly.express) (2024.1)\nRequirement already satisfied: six in c:\\ds\\python\\python312\\lib\\site-packages (from patsy&gt;=0.5-&gt;plotly.express) (1.16.0)\nRequirement already satisfied: tenacity&gt;=6.2.0 in c:\\ds\\python\\python312\\lib\\site-packages (from plotly&gt;=4.1.0-&gt;plotly.express) (8.5.0)\nRequirement already satisfied: packaging in c:\\ds\\python\\python312\\lib\\site-packages (from plotly&gt;=4.1.0-&gt;plotly.express) (24.1)\n\n\n\n[notice] A new release of pip is available: 24.0 -&gt; 24.1.2\n[notice] To update, run: python.exe -m pip install --upgrade pip\n\n[notice] A new release of pip is available: 24.0 -&gt; 24.1.2\n[notice] To update, run: python.exe -m pip install --upgrade pip\n\n\n\n\n\nseaborn을 사용한 산점도\n\n\nsns.scatterplot(data=mpg,\n                x=\"displ\",\n                y=\"hwy\",\n                hue=\"drv\") \\\n    .set(xlim = [3,6], ylim = [10,30])\n\n\n\n\n\n\n\n\n\n\nplotly를 사용한 산점도\n\n\npx.scatter(data_frame = mpg,\n           x='displ', y='hwy', color='drv')\n\n                                                \n\n\n\n\n\n\n데이터 전처리\n\n\ndf_mpg = mpg.groupby(\"drv\", as_index = False) \\\n            .agg(mean_hwy = ('hwy','mean'))\ndf_mpg\n\n\n\n\n\n\n\n\ndrv\nmean_hwy\n\n\n\n\n0\n4\n19.174757\n\n\n1\nf\n28.160377\n\n\n2\nr\n21.000000\n\n\n\n\n\n\n\n\n\n그래프로 표현\n\n\nsns.barplot(data = df_mpg.sort_values(\"mean_hwy\", ascending = False),\n            x = 'drv', y = 'mean_hwy', hue = 'drv')"
  },
  {
    "objectID": "posts/교과서 챕터 8/index.html#빈도-막대-그래프-그리기",
    "href": "posts/교과서 챕터 8/index.html#빈도-막대-그래프-그리기",
    "title": "교과서 챕터 8",
    "section": "빈도 막대 그래프 그리기",
    "text": "빈도 막대 그래프 그리기\n\n데이터 불러오기\n\n\nimport pandas as pd\n\nmpg = pd.read_csv('C:/Users/USER/Documents/LS빅데이터스쿨/lsbigdata-project1/data/mpg.csv')\nmpg.head()\nmpg.shape\n\n(234, 11)\n\n\n\nSeaborn 패키지 불러오기\n\n\n!pip install seaborn\n!pip install plotly.express\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\n\nRequirement already satisfied: seaborn in c:\\ds\\python\\python312\\lib\\site-packages (0.13.2)\nRequirement already satisfied: numpy!=1.24.0,&gt;=1.20 in c:\\ds\\python\\python312\\lib\\site-packages (from seaborn) (2.0.0)\nRequirement already satisfied: pandas&gt;=1.2 in c:\\ds\\python\\python312\\lib\\site-packages (from seaborn) (2.2.2)\nRequirement already satisfied: matplotlib!=3.6.1,&gt;=3.4 in c:\\ds\\python\\python312\\lib\\site-packages (from seaborn) (3.9.1)\nRequirement already satisfied: contourpy&gt;=1.0.1 in c:\\ds\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,&gt;=3.4-&gt;seaborn) (1.2.1)\nRequirement already satisfied: cycler&gt;=0.10 in c:\\ds\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,&gt;=3.4-&gt;seaborn) (0.12.1)\nRequirement already satisfied: fonttools&gt;=4.22.0 in c:\\ds\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,&gt;=3.4-&gt;seaborn) (4.53.1)\nRequirement already satisfied: kiwisolver&gt;=1.3.1 in c:\\ds\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,&gt;=3.4-&gt;seaborn) (1.4.5)\nRequirement already satisfied: packaging&gt;=20.0 in c:\\ds\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,&gt;=3.4-&gt;seaborn) (24.1)\nRequirement already satisfied: pillow&gt;=8 in c:\\ds\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,&gt;=3.4-&gt;seaborn) (10.4.0)\nRequirement already satisfied: pyparsing&gt;=2.3.1 in c:\\ds\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,&gt;=3.4-&gt;seaborn) (3.1.2)\nRequirement already satisfied: python-dateutil&gt;=2.7 in c:\\ds\\python\\python312\\lib\\site-packages (from matplotlib!=3.6.1,&gt;=3.4-&gt;seaborn) (2.9.0.post0)\nRequirement already satisfied: pytz&gt;=2020.1 in c:\\ds\\python\\python312\\lib\\site-packages (from pandas&gt;=1.2-&gt;seaborn) (2024.1)\nRequirement already satisfied: tzdata&gt;=2022.7 in c:\\ds\\python\\python312\\lib\\site-packages (from pandas&gt;=1.2-&gt;seaborn) (2024.1)\nRequirement already satisfied: six&gt;=1.5 in c:\\ds\\python\\python312\\lib\\site-packages (from python-dateutil&gt;=2.7-&gt;matplotlib!=3.6.1,&gt;=3.4-&gt;seaborn) (1.16.0)\nRequirement already satisfied: plotly.express in c:\\ds\\python\\python312\\lib\\site-packages (0.4.1)\nRequirement already satisfied: pandas&gt;=0.20.0 in c:\\ds\\python\\python312\\lib\\site-packages (from plotly.express) (2.2.2)\nRequirement already satisfied: plotly&gt;=4.1.0 in c:\\ds\\python\\python312\\lib\\site-packages (from plotly.express) (5.22.0)\nRequirement already satisfied: statsmodels&gt;=0.9.0 in c:\\ds\\python\\python312\\lib\\site-packages (from plotly.express) (0.14.2)\nRequirement already satisfied: scipy&gt;=0.18 in c:\\ds\\python\\python312\\lib\\site-packages (from plotly.express) (1.14.0)\nRequirement already satisfied: patsy&gt;=0.5 in c:\\ds\\python\\python312\\lib\\site-packages (from plotly.express) (0.5.6)\nRequirement already satisfied: numpy&gt;=1.11 in c:\\ds\\python\\python312\\lib\\site-packages (from plotly.express) (2.0.0)\nRequirement already satisfied: python-dateutil&gt;=2.8.2 in c:\\ds\\python\\python312\\lib\\site-packages (from pandas&gt;=0.20.0-&gt;plotly.express) (2.9.0.post0)\nRequirement already satisfied: pytz&gt;=2020.1 in c:\\ds\\python\\python312\\lib\\site-packages (from pandas&gt;=0.20.0-&gt;plotly.express) (2024.1)\nRequirement already satisfied: tzdata&gt;=2022.7 in c:\\ds\\python\\python312\\lib\\site-packages (from pandas&gt;=0.20.0-&gt;plotly.express) (2024.1)\nRequirement already satisfied: six in c:\\ds\\python\\python312\\lib\\site-packages (from patsy&gt;=0.5-&gt;plotly.express) (1.16.0)\nRequirement already satisfied: tenacity&gt;=6.2.0 in c:\\ds\\python\\python312\\lib\\site-packages (from plotly&gt;=4.1.0-&gt;plotly.express) (8.5.0)\nRequirement already satisfied: packaging in c:\\ds\\python\\python312\\lib\\site-packages (from plotly&gt;=4.1.0-&gt;plotly.express) (24.1)\n\n\n\n[notice] A new release of pip is available: 24.0 -&gt; 24.2\n[notice] To update, run: python.exe -m pip install --upgrade pip\n\n[notice] A new release of pip is available: 24.0 -&gt; 24.2\n[notice] To update, run: python.exe -m pip install --upgrade pip\n\n\n\nscatter() 사용하기\n\nseaborn을 사용한 산점도\n\n\nsns.scatterplot(data=mpg,\n                x=\"displ\",\n                y=\"hwy\",\n                hue=\"drv\") \\\n    .set(xlim = [3,6], ylim = [10,30])\n\n\n\n\n\n\n\n\n\n\nplotly를 사용한 산점도\n\n\npx.scatter(data_frame = mpg,\n           x='displ', y='hwy', color='drv')\n\n                                                \n\n\n\n\nbarplot() 사용하기\n\n데이터 전처리\n\n\ndf_mpg = mpg.groupby(\"drv\", as_index = False) \\\n            .agg(mean_hwy = ('hwy','mean'))\ndf_mpg\n\n\n\n\n\n\n\n\ndrv\nmean_hwy\n\n\n\n\n0\n4\n19.174757\n\n\n1\nf\n28.160377\n\n\n2\nr\n21.000000\n\n\n\n\n\n\n\n\n\n그래프로 표현\n\n\nsns.barplot(data = df_mpg.sort_values(\"mean_hwy\", ascending = False),\n            x = 'drv', y = 'mean_hwy', hue = 'drv')\n\n\n\n\n\n\n\n\n\n\n\np.318 px.bar()를 이용한 막대 그래프 만들기\n\n자동차 종류별 빈도 구하기\n\n\ndf = mpg.groupby('category', as_index = False) \\\n        .agg(n = ('category', 'count'))\ndf\n\n\n\n\n\n\n\n\ncategory\nn\n\n\n\n\n0\n2seater\n5\n\n\n1\ncompact\n47\n\n\n2\nmidsize\n41\n\n\n3\nminivan\n11\n\n\n4\npickup\n33\n\n\n5\nsubcompact\n35\n\n\n6\nsuv\n62\n\n\n\n\n\n\n\n\n\n막대 그래프 만들기\n\n\npx.bar(data_frame = df, x = 'category', y = 'n', color = 'category')\n\n                                                \n\n\n\n\n\np.319 px.line()를 이용한 선 그래프 만들기\n\neconomics 불러오기\n\n\neconomics = pd.read_csv('C:/Users/USER/Documents/LS빅데이터스쿨/lsbigdata-project1/data/economics.csv')\n\n\n\n선 그래프 만들기\n\n\npx.line(data_frame = economics, x = 'date', y = 'psavert')"
  },
  {
    "objectID": "posts/hw2-2/index.html#페이지",
    "href": "posts/hw2-2/index.html#페이지",
    "title": "LS 빅데이터 스쿨 Homework 2-2",
    "section": "173 페이지",
    "text": "173 페이지\n\nimport pandas as pd\nimport numpy as np\n\nmpg = pd.read_csv('C:/Users/USER/Documents/LS빅데이터스쿨/lsbigdata-project1/data/mpg.csv')\n\nfuel = pd.DataFrame({'fl'       : ['c','d','e','p','r'],\n                     'price_fl' : [2.35, 2.38, 2.11, 2.76, 2.22]})\nprint(fuel)\n\nprint(mpg)\n\n  fl  price_fl\n0  c      2.35\n1  d      2.38\n2  e      2.11\n3  p      2.76\n4  r      2.22\n    manufacturer   model  displ  year  cyl       trans drv  cty  hwy fl  \\\n0           audi      a4    1.8  1999    4    auto(l5)   f   18   29  p   \n1           audi      a4    1.8  1999    4  manual(m5)   f   21   29  p   \n2           audi      a4    2.0  2008    4  manual(m6)   f   20   31  p   \n3           audi      a4    2.0  2008    4    auto(av)   f   21   30  p   \n4           audi      a4    2.8  1999    6    auto(l5)   f   16   26  p   \n..           ...     ...    ...   ...  ...         ...  ..  ...  ... ..   \n229   volkswagen  passat    2.0  2008    4    auto(s6)   f   19   28  p   \n230   volkswagen  passat    2.0  2008    4  manual(m6)   f   21   29  p   \n231   volkswagen  passat    2.8  1999    6    auto(l5)   f   16   26  p   \n232   volkswagen  passat    2.8  1999    6  manual(m5)   f   18   26  p   \n233   volkswagen  passat    3.6  2008    6    auto(s6)   f   17   26  p   \n\n    category  \n0    compact  \n1    compact  \n2    compact  \n3    compact  \n4    compact  \n..       ...  \n229  midsize  \n230  midsize  \n231  midsize  \n232  midsize  \n233  midsize  \n\n[234 rows x 11 columns]\n\n\n\n\nQ1. mpg데이터에는 연료 종류를 나타낸 fl변수는 있지만 연료 가격을 나타낸 변수는 없습니다. 앞에서 만든 fuel데이터를 이용해 mpg데이터에 price_fl(연료 가격) 변수를 추가하세요.\n\nmpg = pd.merge(mpg, fuel, how = 'left', on = 'fl')\nprint(mpg)\n\n    manufacturer   model  displ  year  cyl       trans drv  cty  hwy fl  \\\n0           audi      a4    1.8  1999    4    auto(l5)   f   18   29  p   \n1           audi      a4    1.8  1999    4  manual(m5)   f   21   29  p   \n2           audi      a4    2.0  2008    4  manual(m6)   f   20   31  p   \n3           audi      a4    2.0  2008    4    auto(av)   f   21   30  p   \n4           audi      a4    2.8  1999    6    auto(l5)   f   16   26  p   \n..           ...     ...    ...   ...  ...         ...  ..  ...  ... ..   \n229   volkswagen  passat    2.0  2008    4    auto(s6)   f   19   28  p   \n230   volkswagen  passat    2.0  2008    4  manual(m6)   f   21   29  p   \n231   volkswagen  passat    2.8  1999    6    auto(l5)   f   16   26  p   \n232   volkswagen  passat    2.8  1999    6  manual(m5)   f   18   26  p   \n233   volkswagen  passat    3.6  2008    6    auto(s6)   f   17   26  p   \n\n    category  price_fl  \n0    compact      2.76  \n1    compact      2.76  \n2    compact      2.76  \n3    compact      2.76  \n4    compact      2.76  \n..       ...       ...  \n229  midsize      2.76  \n230  midsize      2.76  \n231  midsize      2.76  \n232  midsize      2.76  \n233  midsize      2.76  \n\n[234 rows x 12 columns]\n\n\n\n\n\n\nQ2. 연료 가격 변수가 잘 추가됐는지 확인하기 위해 model,fl,price_fl 변수를 추출해 앞부분 5행을 출력해 보세요.\n\nmpg[['model','fl','price_fl']].head()\n\n\n\n\n\n\n\n\nmodel\nfl\nprice_fl\n\n\n\n\n0\na4\np\n2.76\n\n\n1\na4\np\n2.76\n\n\n2\na4\np\n2.76\n\n\n3\na4\np\n2.76\n\n\n4\na4\np\n2.76"
  },
  {
    "objectID": "posts/hw2-1/index.html#페이지",
    "href": "posts/hw2-1/index.html#페이지",
    "title": "LS 빅데이터 스쿨 Homework 2-1",
    "section": "144 페이지",
    "text": "144 페이지\n\nQ1. 자동차 배기량에 따라 고속도로 연비가 다른지 알아보려고 합니다. displ(배기량)이 4 이하인 자동차와 5 이상인 자동차 중 어떤 자동차의 hwy(고속도로 연비) 평균이 더 높은지 알아보세요.\n\n# mpg 데이터 불러오기\nimport pandas as pd\nimport numpy as np\nmpg = pd.read_csv('C:/Users/USER/Documents/LS빅데이터스쿨/lsbigdata-project1/data/mpg.csv')\n\nmpg_a = mpg.query('displ &lt;= 4')\nmpg_b = mpg.query('displ &gt;= 5')\n\nmpg_a['hwy'].mean(), mpg_b['hwy'].mean()\n\n(np.float64(25.96319018404908), np.float64(18.07894736842105))\n\n\n\n\nQ2. 자동차 제조 회사에 따라 도시 연비가 어떻게 다른지 알아보려고 합니다. 'audi'와 'toyota'중 어느 manufacture(자동차 제조 회사)의 cty(도시연비) 평균이 더 높은지 알아보세요.\n\nmpg_audi = mpg.query(\"manufacturer == 'audi'\")\nmpg_toyota = mpg.query(\"manufacturer == 'toyota'\")\n\nmpg_audi['cty'].mean(), mpg_toyota['cty'].mean()\n\n(np.float64(17.61111111111111), np.float64(18.529411764705884))\n\n\n\n\nQ3. 'chevrolet', 'ford', 'honda' 자동차의 고속도로 연비 평균을 알아보려고 합니다. 세 회사의 데이터를 추출한 다음 hwy전체 평균을 구해 보세요.\n\nmpg_new = mpg.query('manufacturer in [\"chevrolet\", \"ford\", \"honda\"]')\nmpg_new['hwy'].mean()\n\nnp.float64(22.50943396226415)"
  },
  {
    "objectID": "posts/hw2-1/index.html#페이지-1",
    "href": "posts/hw2-1/index.html#페이지-1",
    "title": "LS 빅데이터 스쿨 Homework 2-1",
    "section": "153 페이지",
    "text": "153 페이지\n\nQ1. 'audi'에서 생산한 자동차 중에 어떤 자동차 모델의 hwy(고속도로 연비)가 높은지 알아보려고 합니다. audi'에서 생산한 자동차 중 hwy가 1~5위에 해당하는 자동차의 데이터를 출력하세요.\n\naudi_mpg = mpg.query(\"manufacturer == 'audi'\")\naudi_mpg.sort_values('hwy', ascending = False).head()\n\nmpg.query(\"manufacturer == 'audi'\") \\\n   .sort_values('hwy', ascending = False) \\\n   .head()\n\n\n\n\n\n\n\n\nmanufacturer\nmodel\ndispl\nyear\ncyl\ntrans\ndrv\ncty\nhwy\nfl\ncategory\n\n\n\n\n2\naudi\na4\n2.0\n2008\n4\nmanual(m6)\nf\n20\n31\np\ncompact\n\n\n3\naudi\na4\n2.0\n2008\n4\nauto(av)\nf\n21\n30\np\ncompact\n\n\n1\naudi\na4\n1.8\n1999\n4\nmanual(m5)\nf\n21\n29\np\ncompact\n\n\n0\naudi\na4\n1.8\n1999\n4\nauto(l5)\nf\n18\n29\np\ncompact\n\n\n9\naudi\na4 quattro\n2.0\n2008\n4\nmanual(m6)\n4\n20\n28\np\ncompact"
  },
  {
    "objectID": "posts/hw2-1/index.html#페이지-2",
    "href": "posts/hw2-1/index.html#페이지-2",
    "title": "LS 빅데이터 스쿨 Homework 2-1",
    "section": "158 페이지",
    "text": "158 페이지\nmpg데이터는 연비를 나타내는 변수가 hwy(고속도로 연비), cty(도시 연비) 두 종류로 분리되어 있습니다. 두 변수는 각각 활용하는 대신 하나의 합산 연비 변수를 만들어 분석하려고 합니다.\n\nQ1. mpg데이터 복사본을 만들고, cty와 hwy를 더한 합산 연비 변수를 추가하세요.\n\nmpg_new = mpg.copy()\nmpg_new = mpg_new.assign(mileage = mpg_new['cty'] + mpg_new['hwy'])\nmpg_new.head()\n\n\n\n\n\n\n\n\nmanufacturer\nmodel\ndispl\nyear\ncyl\ntrans\ndrv\ncty\nhwy\nfl\ncategory\nmileage\n\n\n\n\n0\naudi\na4\n1.8\n1999\n4\nauto(l5)\nf\n18\n29\np\ncompact\n47\n\n\n1\naudi\na4\n1.8\n1999\n4\nmanual(m5)\nf\n21\n29\np\ncompact\n50\n\n\n2\naudi\na4\n2.0\n2008\n4\nmanual(m6)\nf\n20\n31\np\ncompact\n51\n\n\n3\naudi\na4\n2.0\n2008\n4\nauto(av)\nf\n21\n30\np\ncompact\n51\n\n\n4\naudi\na4\n2.8\n1999\n6\nauto(l5)\nf\n16\n26\np\ncompact\n42\n\n\n\n\n\n\n\n\n\n\nQ2. 앞에서 만든 ’합산 연비 변수’를 2로 나눠 ’평균 연비 변수’를 추가하세요.\n\nmpg_new = mpg_new.assign(mileage_mean = mpg_new['mileage'] / 2)\nmpg_new.head()\n\n\n\n\n\n\n\n\nmanufacturer\nmodel\ndispl\nyear\ncyl\ntrans\ndrv\ncty\nhwy\nfl\ncategory\nmileage\nmileage_mean\n\n\n\n\n0\naudi\na4\n1.8\n1999\n4\nauto(l5)\nf\n18\n29\np\ncompact\n47\n23.5\n\n\n1\naudi\na4\n1.8\n1999\n4\nmanual(m5)\nf\n21\n29\np\ncompact\n50\n25.0\n\n\n2\naudi\na4\n2.0\n2008\n4\nmanual(m6)\nf\n20\n31\np\ncompact\n51\n25.5\n\n\n3\naudi\na4\n2.0\n2008\n4\nauto(av)\nf\n21\n30\np\ncompact\n51\n25.5\n\n\n4\naudi\na4\n2.8\n1999\n6\nauto(l5)\nf\n16\n26\np\ncompact\n42\n21.0\n\n\n\n\n\n\n\n\n\n\nQ3. ’평균 연비 변수’가 가장 높은 자동차 3종의 데이터를 출력하세요.\n\nmpg_new.sort_values('mileage_mean', ascending = False).head(3)\n\n\n\n\n\n\n\n\nmanufacturer\nmodel\ndispl\nyear\ncyl\ntrans\ndrv\ncty\nhwy\nfl\ncategory\nmileage\nmileage_mean\n\n\n\n\n221\nvolkswagen\nnew beetle\n1.9\n1999\n4\nmanual(m5)\nf\n35\n44\nd\nsubcompact\n79\n39.5\n\n\n212\nvolkswagen\njetta\n1.9\n1999\n4\nmanual(m5)\nf\n33\n44\nd\ncompact\n77\n38.5\n\n\n222\nvolkswagen\nnew beetle\n1.9\n1999\n4\nauto(l4)\nf\n29\n41\nd\nsubcompact\n70\n35.0\n\n\n\n\n\n\n\n\n\n\nQ4. 1~3번 문제를 해결할 수 있는 하나로 연결된 pandas구문을 만들어 실행해 보세요. 데이터는 복사본 대신 mpg원본을 이용하세요.\n\nmpg.assign(mileage = mpg_new['cty'] + mpg_new['hwy']) \\\n   .assign(mileage_mean = mpg_new['mileage'] / 2) \\\n   .sort_values('mileage_mean', ascending = False).head(3)\n\n\n\n\n\n\n\n\nmanufacturer\nmodel\ndispl\nyear\ncyl\ntrans\ndrv\ncty\nhwy\nfl\ncategory\nmileage\nmileage_mean\n\n\n\n\n221\nvolkswagen\nnew beetle\n1.9\n1999\n4\nmanual(m5)\nf\n35\n44\nd\nsubcompact\n79\n39.5\n\n\n212\nvolkswagen\njetta\n1.9\n1999\n4\nmanual(m5)\nf\n33\n44\nd\ncompact\n77\n38.5\n\n\n222\nvolkswagen\nnew beetle\n1.9\n1999\n4\nauto(l4)\nf\n29\n41\nd\nsubcompact\n70\n35.0"
  },
  {
    "objectID": "posts/hw2-3/index.html#페이지",
    "href": "posts/hw2-3/index.html#페이지",
    "title": "LS 빅데이터 스쿨 Homework 2-3",
    "section": "204 페이지",
    "text": "204 페이지\nmpg데이터와 midwest데이터를 이용해 분석 문제를 해결해 보세요.\n\nQ1. mpg데이터의 cty(도시 연비)와 hwy(고속도로 연비) 간에 어떤 관계가 있는지 알아보려고 합니다. x축은 cty, y축은 hwy로 된 산점도를 만들어 보세요.\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nmpg = pd.read_csv('C:/Users/USER/Documents/LS빅데이터스쿨/lsbigdata-project1/data/mpg.csv')\n\nsns.scatterplot(data = mpg, x='cty', y='hwy')\n\n\n\n\n\n\n\n\n\n\n\nQ2. 미국의 지역별 인구통계 정보를 담은 midwest.csv를 이용해 전체 인구와 아시아인 인구 간에 어떤 관계가 있는지 알아보려고 합니다. x축은 poptotal(전체 인구), y축은 popasian(아시아인 인구)으로 된 산점도를 만들어 보세요. 전체 인구는 50만 명 이하, 아시아인 인구는 1만 명 이하인 지역만 산점도에 표시되게 설정하세요.\n\ndf = pd.read_csv('C:/Users/USER/Documents/LS빅데이터스쿨/lsbigdata-project1/data/midwest.csv')\ndf\nsns.scatterplot(data = df, x = 'poptotal', y = 'popasian') \\\n   .set(xlim = [0,500000], ylim = [0,10000])"
  },
  {
    "objectID": "posts/hw2-3/index.html#페이지-1",
    "href": "posts/hw2-3/index.html#페이지-1",
    "title": "LS 빅데이터 스쿨 Homework 2-3",
    "section": "211 페이지",
    "text": "211 페이지\nmpg데이터를 이용해 분석 문제를 해결해 보세요.\n\nQ1. 어떤 회사에서 생산한 'suv'차종의 도시 연비가 높은지 알아보려고 합니다. 'suv'차종을 대상으로 cty(도시 연비) 평균이 가장 높은 회사 다섯 곳을 막대 그래프로 표현해 보세요. 막대는 연비가 가장 높은 순으로 정렬하세요.\n\nmpg_suv = mpg.query('category == \"suv\"').groupby('manufacturer', as_index = True) \\\n       .agg(n = ('cty', 'mean'))\n\nsns.barplot(data = mpg_suv.sort_values(\"n\", ascending = False).head(5), x = 'manufacturer', y = 'n')\n\n\n\n\n\n\n\n\n\n\n\nQ2. 자동차 중에 어떤 category(자동차 종류)가 많은지 알아보려고 합니다. sns.barplot()을 이용해 자동차 종류별 빈도를 표현한 막대 그래프를 만들어 보세요. 막대는 빈도가 높은 순으로 정렬하세요.\n\nsns.countplot(data = mpg, x = 'category',\n              order = mpg['category'].value_counts().index)"
  },
  {
    "objectID": "posts/hw3/index.html",
    "href": "posts/hw3/index.html",
    "title": "LS 빅데이터 스쿨 Homework 3",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport math"
  },
  {
    "objectID": "posts/hw3/index.html#정규분포-pdf-값을-계산하는-자신만의-파이썬-함수를-정의하고-정규분포-mu3-sigma2의-pdf를-그릴-것.",
    "href": "posts/hw3/index.html#정규분포-pdf-값을-계산하는-자신만의-파이썬-함수를-정의하고-정규분포-mu3-sigma2의-pdf를-그릴-것.",
    "title": "LS 빅데이터 스쿨 Homework 3",
    "section": "1. 정규분포 pdf 값을 계산하는 자신만의 파이썬 함수를 정의하고, 정규분포 mu=3, sigma=2의 pdf를 그릴 것.",
    "text": "1. 정규분포 pdf 값을 계산하는 자신만의 파이썬 함수를 정의하고, 정규분포 mu=3, sigma=2의 pdf를 그릴 것.\n\ndef pdf(x, mu, sigma):\n    a = 1 / (sigma * np.sqrt(2 * math.pi))\n    b = (x - mu) / sigma\n    return a * np.exp((-1/2) * b**2)\n\n\nk = np.linspace(-7, 13)\ny = pdf(k, 3, 2)\nplt.plot(k, y, color=\"orchid\", linewidth=4)\nplt.show()\nplt.clf()\n\n\n\n\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;"
  },
  {
    "objectID": "posts/hw3/index.html#파이썬-scipy-패키지를-사용해서-다음과-같은-확률을-구하시오.",
    "href": "posts/hw3/index.html#파이썬-scipy-패키지를-사용해서-다음과-같은-확률을-구하시오.",
    "title": "LS 빅데이터 스쿨 Homework 3",
    "section": "2. 파이썬 scipy 패키지를 사용해서 다음과 같은 확률을 구하시오.",
    "text": "2. 파이썬 scipy 패키지를 사용해서 다음과 같은 확률을 구하시오.\n\nfrom scipy.stats import bernoulli\nfrom scipy.stats import binom\nfrom scipy.stats import norm\n\n\nX~N(2, 3^2)\n\n\nP(X&lt;3)\n\n\n\na = norm.cdf(3,loc=2,scale=3)\nprint('확률은 ' + str(a.round(3)) + '입니다.')\n\n확률은 0.631입니다.\n\n\n\n\n\nP(2&lt;X&lt;5)\n\n\n\nb = norm.cdf(5,loc=2,scale=3) - norm.cdf(2,loc=2,scale=3)\nprint('확률은 ' + str(b.round(3)) + '입니다.')\n\n확률은 0.341입니다.\n\n\n\n\n\nP(X&lt;3 or X&gt;7)\n\n\n\nc = 1 - (norm.cdf(7,loc=2,scale=3) - norm.cdf(3,loc=2,scale=3))\nprint('확률은 ' + str(c.round(3)) + '입니다.')\n\n확률은 0.678입니다."
  },
  {
    "objectID": "posts/hw3/index.html#ls-빅데이터스쿨-학생들의-중간고사-점수는-평균이-30이고-분산이-4인-정규분포를-따른다.-상위-5에-해당하는-학생의-점수는",
    "href": "posts/hw3/index.html#ls-빅데이터스쿨-학생들의-중간고사-점수는-평균이-30이고-분산이-4인-정규분포를-따른다.-상위-5에-해당하는-학생의-점수는",
    "title": "LS 빅데이터 스쿨 Homework 3",
    "section": "3. LS 빅데이터스쿨 학생들의 중간고사 점수는 평균이 30이고, 분산이 4인 정규분포를 따른다. 상위 5%에 해당하는 학생의 점수는?",
    "text": "3. LS 빅데이터스쿨 학생들의 중간고사 점수는 평균이 30이고, 분산이 4인 정규분포를 따른다. 상위 5%에 해당하는 학생의 점수는?\n\n# X~N(30,2)\nd = norm.ppf(0.95,30,2)\nprint('해당 학생의 점수는 ' + str(d.round(3)) + '입니다.')\n\n해당 학생의 점수는 33.29입니다."
  },
  {
    "objectID": "posts/hw3/index.html#정규분포-pdf-값을-계산하는-자신만의-파이썬-함수를-정의하고-정규분포-mu-3-sigma-2의-pdf를-그려보시오.",
    "href": "posts/hw3/index.html#정규분포-pdf-값을-계산하는-자신만의-파이썬-함수를-정의하고-정규분포-mu-3-sigma-2의-pdf를-그려보시오.",
    "title": "LS 빅데이터 스쿨 Homework 3",
    "section": "1. 정규분포 pdf 값을 계산하는 자신만의 파이썬 함수를 정의하고, 정규분포 mu = 3, sigma = 2의 pdf를 그려보시오.",
    "text": "1. 정규분포 pdf 값을 계산하는 자신만의 파이썬 함수를 정의하고, 정규분포 mu = 3, sigma = 2의 pdf를 그려보시오.\n\ndef pdf(x, mu, sigma):\n    a = 1 / (sigma * np.sqrt(2 * math.pi))\n    b = (x - mu) / sigma\n    return a * np.exp((-1/2) * b**2)\n\n\nk = np.linspace(-7, 13)\ny = pdf(k, 3, 2)\nplt.plot(k, y, color=\"orchid\", linewidth=4, marker='o', markerfacecolor = 'aqua')\nplt.grid(True)\nplt.show()\nplt.clf()\n\n\n\n\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;"
  },
  {
    "objectID": "posts/hw4/index.html#숙제-표본-분산-n-1-vs.-n",
    "href": "posts/hw4/index.html#숙제-표본-분산-n-1-vs.-n",
    "title": "LS 빅데이터 스쿨 Homework 4",
    "section": "",
    "text": "###표본 분산 계산 시 왜 n-1로 나누는지 알아보도록 하겠습니다. 균일분포 (3, 7)에서 20개의 표본을 뽑아서 분산을 2가지 방법으로 추정해보세요."
  },
  {
    "objectID": "posts/hw4/index.html#표본-분산-n-1-vs.-n",
    "href": "posts/hw4/index.html#표본-분산-n-1-vs.-n",
    "title": "LS 빅데이터 스쿨 Homework 4",
    "section": "표본 분산 n-1 vs. n",
    "text": "표본 분산 n-1 vs. n\n\n표본 분산 계산 시 왜 n-1로 나누는지 알아보도록 하겠습니다. 균일분포 (3, 7)에서 20개의 표본을 뽑아서 분산을 2가지 방법으로 추정해보세요."
  },
  {
    "objectID": "posts/hw4/index.html#n-1로-나눈-것을-s_2-n으로-나눈-것을-k_2로-정의하고-s_2의-분포와-k_2의-분포를-그려주세요-10000개-사용",
    "href": "posts/hw4/index.html#n-1로-나눈-것을-s_2-n으로-나눈-것을-k_2로-정의하고-s_2의-분포와-k_2의-분포를-그려주세요-10000개-사용",
    "title": "LS 빅데이터 스쿨 Homework 4",
    "section": "1. n-1로 나눈 것을 s_2, n으로 나눈 것을 k_2로 정의하고, s_2의 분포와 k_2의 분포를 그려주세요! (10000개 사용)",
    "text": "1. n-1로 나눈 것을 s_2, n으로 나눈 것을 k_2로 정의하고, s_2의 분포와 k_2의 분포를 그려주세요! (10000개 사용)\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import uniform\n\n# X ~ U(3,7)에서 20개의 표본을 추출\nx=uniform.rvs(loc=3, scale=4, size=20*10000).reshape(-1,20)\nx.shape\n\n# s_2 정의\ns_2 = np.var(x, axis=1, ddof=1)\ns_2\n\n# s_2 그리기\nsns.histplot(s_2, stat=\"density\", color = 'red', label = 'n-1')\nplt.legend()\nplt.show()\nplt.clf()\n\n\n\n\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;\n\n\n\n# k_2 정의\nk_2 = np.var(x, axis=1, ddof=0)\nk_2\n\n# k_2 그리기\nsns.histplot(k_2, stat=\"density\", color = 'blue', label = 'n')\nplt.legend()\nplt.show()\nplt.clf()\n\n\n\n\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;"
  },
  {
    "objectID": "posts/hw4/index.html#각-분포-그래프에-모분산의-위치에-녹색-막대를-그려주세요.",
    "href": "posts/hw4/index.html#각-분포-그래프에-모분산의-위치에-녹색-막대를-그려주세요.",
    "title": "LS 빅데이터 스쿨 Homework 4",
    "section": "2. 각 분포 그래프에 모분산의 위치에 녹색 막대를 그려주세요.",
    "text": "2. 각 분포 그래프에 모분산의 위치에 녹색 막대를 그려주세요.\n\n# 모분산\npop_var = uniform.var(loc=3, scale=4)\n\n# s_2 그래프에 모분산 표시\nsns.histplot(s_2, stat=\"density\", color = 'red', label = 'n-1')\nplt.axvline(x = pop_var, color='green', linestyle ='-', linewidth=2)\nplt.legend()\nplt.show()\nplt.clf()\n\n\n\n\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;\n\n\n\n# k_2 그래프에 모분산 표시\nsns.histplot(k_2, stat=\"density\", color = 'blue', label = 'n')\nplt.axvline(x = pop_var, color='green', linestyle ='-', linewidth=2)\nplt.legend()\nplt.show()\nplt.clf()\n\n\n\n\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;"
  },
  {
    "objectID": "posts/hw4/index.html#결과를-살펴보고-왜-n-1로-나눈-것을-분산을-추정하는-지표로-사용하는-것이-타당한지-써주세요",
    "href": "posts/hw4/index.html#결과를-살펴보고-왜-n-1로-나눈-것을-분산을-추정하는-지표로-사용하는-것이-타당한지-써주세요",
    "title": "LS 빅데이터 스쿨 Homework 4",
    "section": "3. 결과를 살펴보고, 왜 n-1로 나눈 것을 분산을 추정하는 지표로 사용하는 것이 타당한지 써주세요!",
    "text": "3. 결과를 살펴보고, 왜 n-1로 나눈 것을 분산을 추정하는 지표로 사용하는 것이 타당한지 써주세요!\n\ns_2에 중앙이 모분산 막대에 더 가깝게 위치하고 있음.\nk_2의 분산은 모분산보다 왼쪽으로 치우쳐 있음.\ns_2(n-1로 나누는 것)가 보다 정확한 분산 추정자료라고 생각됨."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Hyeun-Wook Oh",
    "section": "Education",
    "text": "Education\n\nKorea University (2016~2022) - German Studies, Saejong Campus (2016~2017)\n\n - Health Policy and Management, Seoul Campus (2018~2022)"
  },
  {
    "objectID": "posts/hw4/index.html#어떤-것이-이론적인-값에-더-가까울까-일준님-자료-참고",
    "href": "posts/hw4/index.html#어떤-것이-이론적인-값에-더-가까울까-일준님-자료-참고",
    "title": "LS 빅데이터 스쿨 Homework 4",
    "section": "어떤 것이 이론적인 값에 더 가까울까? (일준님 자료 참고)",
    "text": "어떤 것이 이론적인 값에 더 가까울까? (일준님 자료 참고)\n\n# 10,000개의 분산값을 각각 비교해서 이론적인 분산에 더 가까우면 그 방법에 1점을 주는 반복문.\n\nresult = []\nfor i in range(10000):\n    if (s_2[i] - pop_var)**2 &lt; (k_2[i] - pop_var)**2:\n        result.append(\"n-1\")\n    elif (s_2[i] - pop_var)**2 &gt; (k_2[i] - pop_var)**2:\n        result.append(\"n\")\n        \n        \nsns.countplot(data = result)\nplt.show()\nplt.clf()\n\n\n\n\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;"
  },
  {
    "objectID": "index.html#전-토리에욤",
    "href": "index.html#전-토리에욤",
    "title": "Hyeun-Wook Oh",
    "section": "",
    "text": "Hyeun-Wook Oh(a.k.a. yongraegod) is a person who is interested in studying Big data analysis and National health insurance service."
  },
  {
    "objectID": "posts/hw5/index.html#챕터-9-2-설문조사-그래프에서-각-성별-95-신뢰구간-계산후-그리기.-norm.ppf-사용해서-그릴-것.-모분산은-표본-분산을-사용해서-추정.-위-아래-수직-막대기로-표시-아래-그림-참조",
    "href": "posts/hw5/index.html#챕터-9-2-설문조사-그래프에서-각-성별-95-신뢰구간-계산후-그리기.-norm.ppf-사용해서-그릴-것.-모분산은-표본-분산을-사용해서-추정.-위-아래-수직-막대기로-표시-아래-그림-참조",
    "title": "LS 빅데이터 스쿨 Homework 5",
    "section": "챕터 9-2 설문조사 그래프에서 각 성별 95% 신뢰구간 계산후 그리기. norm.ppf() 사용해서 그릴 것. 모분산은 표본 분산을 사용해서 추정. 위 아래 수직 막대기로 표시 (아래 그림 참조)",
    "text": "챕터 9-2 설문조사 그래프에서 각 성별 95% 신뢰구간 계산후 그리기. norm.ppf() 사용해서 그릴 것. 모분산은 표본 분산을 사용해서 추정. 위 아래 수직 막대기로 표시 (아래 그림 참조)"
  },
  {
    "objectID": "posts/hw5/index.html#챕터-9-2-설문조사-그래프에서-각-성별-95-신뢰구간-계산후-그리기.",
    "href": "posts/hw5/index.html#챕터-9-2-설문조사-그래프에서-각-성별-95-신뢰구간-계산후-그리기.",
    "title": "LS 빅데이터 스쿨 Homework 5",
    "section": "챕터 9-2 설문조사 그래프에서 각 성별 95% 신뢰구간 계산후 그리기.",
    "text": "챕터 9-2 설문조사 그래프에서 각 성별 95% 신뢰구간 계산후 그리기.\n\nnorm.ppf() 사용해서 그릴 것.\n모분산은 표본 분산을 사용해서 추정.\n위 아래 수직 막대기로 표시 (아래 그림 참조)\n\n\n\n\n!pip install pyreadstat\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# 데이터 불러오기\nraw_welfare = pd.read_spss('C:/Users/USER/Documents/LS빅데이터스쿨/lsbigdata-project1/data/koweps/Koweps_hpwc14_2019_beta2.sav')\n\n# 복사본 만들기\nwelfare = raw_welfare.copy()\nwelfare.shape\nwelfare.info()\n\n# 변수명 바꾸기\nwelfare = welfare.rename(\n    columns = {'h14_g3'     : 'sex',\n               'h14_g4'     : 'birth',\n               'h14_g10'    : 'marriage_type',\n               'h14_g11'    : 'religion',\n               'p1402_8aq1' : 'income',\n               'h14_eco9'   : 'code_job',\n               'h14_reg7'   : 'code_region'}\n)\n\n# 분석에 필요한 부분만 추출해서 저장\nwelfare = welfare[['sex','birth','marriage_type','religion',\n                   'income','code_job','code_region']]\n\n# 성별 항목에 이름 부여                 \nwelfare['sex'] = np.where(welfare['sex'] == 1, 'male', 'female')\n\nRequirement already satisfied: pyreadstat in c:\\ds\\python\\python312\\lib\\site-packages (1.2.7)\nRequirement already satisfied: pandas&gt;=1.2.0 in c:\\ds\\python\\python312\\lib\\site-packages (from pyreadstat) (2.2.2)\nRequirement already satisfied: numpy&gt;=1.26.0 in c:\\ds\\python\\python312\\lib\\site-packages (from pandas&gt;=1.2.0-&gt;pyreadstat) (2.0.0)\nRequirement already satisfied: python-dateutil&gt;=2.8.2 in c:\\ds\\python\\python312\\lib\\site-packages (from pandas&gt;=1.2.0-&gt;pyreadstat) (2.9.0.post0)\nRequirement already satisfied: pytz&gt;=2020.1 in c:\\ds\\python\\python312\\lib\\site-packages (from pandas&gt;=1.2.0-&gt;pyreadstat) (2024.1)\nRequirement already satisfied: tzdata&gt;=2022.7 in c:\\ds\\python\\python312\\lib\\site-packages (from pandas&gt;=1.2.0-&gt;pyreadstat) (2024.1)\nRequirement already satisfied: six&gt;=1.5 in c:\\ds\\python\\python312\\lib\\site-packages (from python-dateutil&gt;=2.8.2-&gt;pandas&gt;=1.2.0-&gt;pyreadstat) (1.16.0)\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 14418 entries, 0 to 14417\nColumns: 830 entries, h14_id to h14_pers_income5\ndtypes: float64(826), object(4)\nmemory usage: 91.3+ MB\n\n\n\n[notice] A new release of pip is available: 24.0 -&gt; 24.2\n[notice] To update, run: python.exe -m pip install --upgrade pip"
  },
  {
    "objectID": "posts/hw5/index.html#각-성별-95-신뢰구간-계산하기",
    "href": "posts/hw5/index.html#각-성별-95-신뢰구간-계산하기",
    "title": "LS 빅데이터 스쿨 Homework 5",
    "section": "각 성별 95% 신뢰구간 계산하기",
    "text": "각 성별 95% 신뢰구간 계산하기"
  },
  {
    "objectID": "posts/hw5/index.html#각-성별-데이터-나누기",
    "href": "posts/hw5/index.html#각-성별-데이터-나누기",
    "title": "LS 빅데이터 스쿨 Homework 5",
    "section": "각 성별 데이터 나누기",
    "text": "각 성별 데이터 나누기\n\nmale_data = welfare.query('sex == \"male\"')[[\"sex\", \"income\"]]\n\nfemale_data = welfare.query('sex == \"female\"')[[\"sex\", \"income\"]]\n\nprint(male_data)\nprint(female_data)\n\n        sex  income\n1      male     NaN\n2      male   107.0\n3      male   192.0\n6      male     NaN\n11     male     NaN\n...     ...     ...\n14407  male     NaN\n14410  male   200.0\n14412  male     NaN\n14415  male     NaN\n14417  male     NaN\n\n[6505 rows x 2 columns]\n          sex  income\n0      female     NaN\n4      female     NaN\n5      female     NaN\n7      female    27.0\n8      female    27.0\n...       ...     ...\n14409  female     NaN\n14411  female     NaN\n14413  female     NaN\n14414  female     NaN\n14416  female   200.0\n\n[7913 rows x 2 columns]"
  },
  {
    "objectID": "posts/hw5/index.html#각-성별-평균-구하기",
    "href": "posts/hw5/index.html#각-성별-평균-구하기",
    "title": "LS 빅데이터 스쿨 Homework 5",
    "section": "각 성별 평균 구하기",
    "text": "각 성별 평균 구하기\n\nmale_mean = male_data['income'].mean()\nfemale_mean = female_data['income'].mean()\n\nprint(\"남성의 평균은\", male_mean)\nprint(\"여성의 평균은\", female_mean)\n\n남성의 평균은 349.03757099169945\n여성의 평균은 186.29309576837417"
  },
  {
    "objectID": "posts/hw5/index.html#각-성별-표본분산-구하기",
    "href": "posts/hw5/index.html#각-성별-표본분산-구하기",
    "title": "LS 빅데이터 스쿨 Homework 5",
    "section": "각 성별 표본분산 구하기",
    "text": "각 성별 표본분산 구하기\n\nmale_s_2 = np.var(male_data['income'], ddof = 1)\nfemale_s_2 = np.var(female_data['income'], ddof = 1)\n\nprint(\"남성의 표본분산은\", male_s_2)\nprint(\"여성의 표본분산은\", female_s_2)\n\n남성의 표본분산은 47463.96187451692\n여성의 표본분산은 17439.157372096437"
  },
  {
    "objectID": "posts/hw5/index.html#각-성별-표준편차-구하기",
    "href": "posts/hw5/index.html#각-성별-표준편차-구하기",
    "title": "LS 빅데이터 스쿨 Homework 5",
    "section": "각 성별 표준편차 구하기",
    "text": "각 성별 표준편차 구하기\n\nmale_scale = np.sqrt(male_s_2 / male_n)\nfemale_scale = np.sqrt(female_s_2 / female_n)\n\n\nprint(\"남성의 표준편차는\", male_scale)\nprint(\"여성의 표준편차는\", female_scale)\n\n남성의 표준편차는 4.553644231399566\n여성의 표준편차는 2.7871129918683994"
  },
  {
    "objectID": "posts/hw5/index.html#각-성별-표본수-구하기",
    "href": "posts/hw5/index.html#각-성별-표본수-구하기",
    "title": "LS 빅데이터 스쿨 Homework 5",
    "section": "각 성별 표본수 구하기",
    "text": "각 성별 표본수 구하기\n\nmale_n = male_data['income'].count()\nfemale_n = female_data['income'].count()\n\nprint(\"남성의 표본수는\", male_n)\nprint(\"여성의 표본수는\", female_n)\n\n남성의 표본수는 2289\n여성의 표본수는 2245"
  },
  {
    "objectID": "posts/hw5/index.html#각-성별-신뢰구간-95-구하기",
    "href": "posts/hw5/index.html#각-성별-신뢰구간-95-구하기",
    "title": "LS 빅데이터 스쿨 Homework 5",
    "section": "각 성별 신뢰구간 95% 구하기",
    "text": "각 성별 신뢰구간 95% 구하기\n\nfrom scipy.stats import norm\nz = norm.ppf(0.975,loc=0,scale=1)\n\nmale_0975 = male_mean + z * male_scale\nmale_0025 = male_mean - z * male_scale\n\nfemale_0975 = female_mean + z * female_scale\nfemale_0025 = female_mean - z * female_scale\n\nprint(\"남성의 신뢰구간은 (\", male_0025, \",\", male_0975, \")\")\nprint(\"여성의 신뢰구간은 (\", female_0025, \",\", female_0975, \")\")\n\n남성의 신뢰구간은 ( 340.11259229974775 , 357.96254968365116 )\n여성의 신뢰구간은 ( 180.83045468346845 , 191.7557368532799 )"
  },
  {
    "objectID": "posts/hw5/index.html#각-성별-신뢰구간-95-구하기-2",
    "href": "posts/hw5/index.html#각-성별-신뢰구간-95-구하기-2",
    "title": "LS 빅데이터 스쿨 Homework 5",
    "section": "각 성별 신뢰구간 95% 구하기 2",
    "text": "각 성별 신뢰구간 95% 구하기 2\n\nz=norm.ppf(0.975,loc=0,scale=1)\n\nmale_a = male_mean + z * male_scale / np.sqrt(male_n)\nmale_b = male_mean - z * male_scale / np.sqrt(male_n)\n\nfemale_a = female_mean + z * female_scale / np.sqrt(female_n)\nfemale_b = female_mean - z * female_scale / np.sqrt(female_n)\n\nprint(\"남성의 신뢰구간은 (\", male_b, \",\", male_a, \")\")\nprint(\"여성의 신뢰구간은 (\", female_b, \",\", female_a, \")\")\n\n남성의 신뢰구간은 ( 340.11259229974775 , 357.96254968365116 )\n여성의 신뢰구간은 ( 180.83045468346845 , 191.7557368532799 )"
  },
  {
    "objectID": "posts/hw5/index.html#그래프-그리기",
    "href": "posts/hw5/index.html#그래프-그리기",
    "title": "LS 빅데이터 스쿨 Homework 5",
    "section": "그래프 그리기",
    "text": "그래프 그리기\n\nsex_income = welfare.dropna(subset = 'income') \\\n                    .groupby('sex', as_index = False) \\\n                    .agg(mean_income = ('income', 'mean'))\n\nsns.barplot(data = sex_income, x = 'sex', y = 'mean_income', hue = 'sex')\n\n# 남성 그래프\n# plt.axhline(y = male_0975, color = \"red\", linestyle = '--', linewidth = 0.5)\n# plt.axhline(y = male_0025, color = \"red\", linestyle = '--', linewidth = 0.5)\nplt.plot([1,1], [male_0025, male_0975], color = \"red\", linestyle = '-')\nplt.plot([0.9,1.1], [male_0025, male_0025], color = \"red\", linestyle = '--')\nplt.plot([0.9,1.1], [male_0975, male_0975], color = \"red\", linestyle = '--')\n\n# 여성 그래프\n# plt.axhline(y = female_0975, color = \"red\", linestyle = '--', linewidth = 0.5)\n# plt.axhline(y = female_0025, color = \"red\", linestyle = '--', linewidth = 0.5)\nplt.plot([0,0], [female_0025, female_0975], color = \"red\", linestyle = '-')\nplt.plot([-0.1,0.1], [female_0025, female_0025], color = \"red\", linestyle = '--')\nplt.plot([-0.1,0.1], [female_0975, female_0975], color = \"red\", linestyle = '--')\n\nplt.show()\nplt.clf()\n\n\n\n\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;"
  },
  {
    "objectID": "posts/hw6/index.html",
    "href": "posts/hw6/index.html",
    "title": "LS 빅데이터 스쿨 Homework 6",
    "section": "",
    "text": "슬통 자동자는 매해 출시되는 신형 자동차의 에너지 소비효율 등급을 1등급으로 유지하고 있다. 신형 모델이 에너지 소비 효율등급 1등급을 받을 수 있을지 검정하려한다. 한국 자동차 평가원에 따르면 1등급의 기준은 평균 복합 에너지 소비효율이 16.0 이상인 경우 부여한다고 한다. 다음은 신형 자동차 15대의 복합 에너지 소비효율을 측정한 결과이다. 15.078, 15.752, 15.549, 15.56, 16.098, 13.277, 15.462, 16.116, 15.214, 16.93, 14.118, 14.927, 15.382, 16.709, 16.804\n표본에 의하여 판단해볼때, 현대자동차의 신형 모델은 에너지 효율 1등급으로 판단할 수 있을지 판단해보시오. (유의수준 1%로 설정)"
  },
  {
    "objectID": "posts/hw6/index.html#문제",
    "href": "posts/hw6/index.html#문제",
    "title": "LS 빅데이터 스쿨 Homework 6",
    "section": "문제",
    "text": "문제\n\n슬통 자동자는 매해 출시되는 신형 자동차의 에너지 소비효율 등급을 1등급으로 유지하고 있다.\n신형 모델이 에너지 소비 효율등급 1등급을 받을 수 있을지 검정하려한다.\n한국 자동차 평가원에 따르면 1등급의 기준은 평균 복합 에너지 소비효율이 16.0 이상인 경우 부여한다고 한다.\n다음은 신형 자동차 15대의 복합 에너지 소비효율을 측정한 결과이다.\n15.078, 15.752, 15.549, 15.56, 16.098, 13.277, 15.462, 16.116, 15.214, 16.93, 14.118, 14.927, 15.382, 16.709, 16.804\n표본에 의하여 판단해볼때, 현대자동차의 신형 모델은 에너지 효율 1등급으로 판단할 수 있을지 판단해보시오. (유의수준 1%로 설정)"
  },
  {
    "objectID": "posts/hw6/index.html#검정을-위한-가설을-명확하게-서술하시오.",
    "href": "posts/hw6/index.html#검정을-위한-가설을-명확하게-서술하시오.",
    "title": "LS 빅데이터 스쿨 Homework 6",
    "section": "검정을 위한 가설을 명확하게 서술하시오.",
    "text": "검정을 위한 가설을 명확하게 서술하시오.\n귀무가설: 𝐻0 ∶ 𝜇0 &gt;= 16.0\n대립가설: 𝐻𝐴 ∶ 𝜇 &lt; 16.0\n이러한 경우, 아래 그림과 같은 단측검정을 해야 한다."
  },
  {
    "objectID": "posts/hw6/index.html#검정통계량-계산하시오.",
    "href": "posts/hw6/index.html#검정통계량-계산하시오.",
    "title": "LS 빅데이터 스쿨 Homework 6",
    "section": "검정통계량 계산하시오.",
    "text": "검정통계량 계산하시오.\n\nimport matplotlib.pyplot as plt\nimport numpy as np \nfrom scipy.stats import t \nfrom scipy.stats import norm\n\n\nx = np.array([15.078, 15.752, 15.549, 15.56, 16.098, 13.277, 15.462, 16.116, 15.214, 16.93, 14.118, 14.927, 15.382, 16.709, 16.804])\n\nn = 15\ns_2 = np.var(x)\nx_bar = np.mean(x)\nx_scale = np.sqrt((s_2)/15)\n\nt = (x_bar - 16) / x_scale\n\nprint(\"t 값은\",t)\n\nt 값은 -1.9149782433102691"
  },
  {
    "objectID": "posts/hw6/index.html#pvalue을-구하세요.",
    "href": "posts/hw6/index.html#pvalue을-구하세요.",
    "title": "LS 빅데이터 스쿨 Homework 6",
    "section": "p‑value을 구하세요.",
    "text": "p‑value을 구하세요.\n\np_value = t.cdf(t_stat, df=n-1)\n\nprint(\"p-value은\", round(p_value, 3))\nprint(\"결론: p-value\", round(p_value, 3), \"&gt; 유의수준 0.01로 귀무가설을 기각할 수 없음\")\n\np-value은 0.043\n결론: p-value 0.043 &gt; 유의수준 0.01로 귀무가설을 기각할 수 없음"
  },
  {
    "objectID": "posts/hw6/index.html#슬통자동차의-신형-모델의-평균-복합-에너지-소비효율에-대하여-95-신뢰구간을-구해보세요.",
    "href": "posts/hw6/index.html#슬통자동차의-신형-모델의-평균-복합-에너지-소비효율에-대하여-95-신뢰구간을-구해보세요.",
    "title": "LS 빅데이터 스쿨 Homework 6",
    "section": "슬통자동차의 신형 모델의 평균 복합 에너지 소비효율에 대하여 95% 신뢰구간을 구해보세요.",
    "text": "슬통자동차의 신형 모델의 평균 복합 에너지 소비효율에 대하여 95% 신뢰구간을 구해보세요.\n\na = round(x_bar + t.ppf(0.975, df=n-1) * x_std / np.sqrt(n), 3)\nb = round(x_bar - t.ppf(0.975, df=n-1) * x_std / np.sqrt(n), 3)\nprint(\"95% 신뢰구간은 (\", b, \",\", a, \")\")\n\n95% 신뢰구간은 ( 14.989 , 16.075 )"
  },
  {
    "objectID": "posts/hw6/index.html#adp-교재-p.57-문제",
    "href": "posts/hw6/index.html#adp-교재-p.57-문제",
    "title": "LS 빅데이터 스쿨 Homework 6",
    "section": "ADP 교재 p.57 문제",
    "text": "ADP 교재 p.57 문제\n\n슬통 자동자는 매해 출시되는 신형 자동차의 에너지 소비효율 등급을 1등급으로 유지하고 있다.\n신형 모델이 에너지 소비 효율등급 1등급을 받을 수 있을지 검정하려한다.\n한국 자동차 평가원에 따르면 1등급의 기준은 평균 복합 에너지 소비효율이 16.0 이상인 경우 부여한다고 한다.\n다음은 신형 자동차 15대의 복합 에너지 소비효율을 측정한 결과이다.\n15.078, 15.752, 15.549, 15.56, 16.098, 13.277, 15.462, 16.116, 15.214, 16.93, 14.118, 14.927, 15.382, 16.709, 16.804\n표본에 의하여 판단해볼때, 현대자동차의 신형 모델은 에너지 효율 1등급으로 판단할 수 있을지 판단해보시오. (유의수준 1%로 설정)"
  },
  {
    "objectID": "posts/hw6/index.html#검정통계량을-계산하시오.",
    "href": "posts/hw6/index.html#검정통계량을-계산하시오.",
    "title": "LS 빅데이터 스쿨 Homework 6",
    "section": "검정통계량을 계산하시오.",
    "text": "검정통계량을 계산하시오.\n\nimport matplotlib.pyplot as plt\nimport numpy as np \nfrom scipy.stats import t \nfrom scipy.stats import norm\nfrom scipy import stats\n\n\n# 데이터\nx = np.array([15.078, 15.752, 15.549, 15.56, 16.098, 13.277, 15.462, 16.116, 15.214, 16.93, 14.118, 14.927, 15.382, 16.709, 16.804])\n\n# 표본 크기\nn = len(x)\n\n# 표본 평균\nx_bar = np.mean(x)\n\n# 표본 표준편차\nx_std = np.std(x, ddof = 1)\n\n# t값 찾기: (X_bar - 𝜇0) / (s / sqrt(n))\nt_stat = (x_bar - 16) / (x_std / np.sqrt(n))\n\nprint(\"표본 크기는\", n)\nprint(\"표본 평균은\", round(x_bar, 3))\nprint(\"표본 표준편차는\", round(x_std, 3))\nprint(\"t 값은\", round(t_stat, 3))\n\n표본 크기는 15\n표본 평균은 15.532\n표본 표준편차는 0.98\nt 값은 -1.85"
  },
  {
    "objectID": "posts/index.html",
    "href": "posts/index.html",
    "title": "Recent posts",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\nLS 빅데이터 스쿨 Homework 6\n\n\n\nAug 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nLS 빅데이터 스쿨 Homework 5\n\n\n\nJul 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nLS 빅데이터 스쿨 Homework 4\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nLS 빅데이터 스쿨 Homework 3\n\n\n\nJul 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nLS 빅데이터 스쿨 Homework 2-3\n\n\n\nJul 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n교과서 챕터 8\n\n\n\nJul 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nLS 빅데이터 스쿨 Homework 2-2\n\n\n\nJul 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nLS 빅데이터 스쿨 Homework 2-1\n\n\n\nJul 16, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nLS 빅데이터 스쿨 Homework 1\n\n\n\nJul 12, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/hw7/index.html",
    "href": "posts/hw7/index.html",
    "title": "LS 빅데이터 스쿨 Homework 7",
    "section": "",
    "text": "2022년에 실시 된 ADP 실기 시험의 통계파트 표준점수는 평균이 30, 표준편차가 5인 정규분포를 따른다고 한다.\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\nx = np.linspace(0, 60, 300)\ny = norm.pdf(x, loc=30, scale=5)\nplt.plot(x, y)\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nover_45 = 1 - norm.cdf(45, 30, 5)\nprint(f\"45점 보다 높을 확률: \", round(over_45, 3))\n\n45점 보다 높을 확률:  0.001\n\n\n\n\n\n\n슬통_score = norm.ppf(0.9, loc=30, scale=5)\nprint(f\"슬통이의 점수: \", round(슬통_score, 3))\n\n슬통이의 점수:  36.408\n\n\n\n\n\n\n# 1번 그래프\nx = np.linspace(0, 60, 300)\ny = norm.pdf(x, loc=30, scale=5)\nplt.plot(x, y)\n\n# 4번 그래프\ny2 = norm.pdf(x, loc=30, scale=5/np.sqrt(16))\nplt.plot(x, y2)\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nover_38 = 1 - norm.cdf(38, loc=30, scale=5/np.sqrt(16))\nprint(f\"38점보다 높게 나올 확률: \", over_38)\n\n38점보다 높게 나올 확률:  7.76885222819601e-11\n\n\n\n\n\n\n\nCovid‑19의 발병률은 1%라고 한다. 다음은 이번 코로나 사태로 인하여 코로나 의심 환자들 1,085명을 대상으로 슬통 회사의 “다잡아” 키트를 사용하여 양성 반응을 체크한 결과이다. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-같은 방법으로 500개의 𝑠2 들, 𝑠21, 𝑠22, …, 𝑠2 500 발생시킵니다.\n\n발생한 500개의 𝑠2 들 각각에 4.75를 곱하고, 그것들의 히스토그램을 그려보세요. (히스토그램을 그릴 때 probability = TRUE 옵션을 사용해서 그릴 것)\n위에서 그린 히스토그램에 자유도가 19인 카이제곱분포 확률밀도함수를 겹쳐그려보세요."
  },
  {
    "objectID": "posts/hw7/index.html#adp-교재-p.3738-문제",
    "href": "posts/hw7/index.html#adp-교재-p.3738-문제",
    "title": "LS 빅데이터 스쿨 Homework 7",
    "section": "",
    "text": "2022년에 실시 된 ADP 실기 시험의 통계파트 표준점수는 평균이 30, 표준편차가 5인 정규분포를 따른다고 한다.\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\nx = np.linspace(0, 60, 300)\ny = norm.pdf(x, loc=30, scale=5)\nplt.plot(x, y)\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nover_45 = 1 - norm.cdf(45, 30, 5)\nprint(f\"45점 보다 높을 확률: \", round(over_45, 3))\n\n45점 보다 높을 확률:  0.001\n\n\n\n\n\n\n슬통_score = norm.ppf(0.9, loc=30, scale=5)\nprint(f\"슬통이의 점수: \", round(슬통_score, 3))\n\n슬통이의 점수:  36.408\n\n\n\n\n\n\n# 1번 그래프\nx = np.linspace(0, 60, 300)\ny = norm.pdf(x, loc=30, scale=5)\nplt.plot(x, y)\n\n# 4번 그래프\ny2 = norm.pdf(x, loc=30, scale=5/np.sqrt(16))\nplt.plot(x, y2)\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nover_38 = 1 - norm.cdf(38, loc=30, scale=5/np.sqrt(16))\nprint(f\"38점보다 높게 나올 확률: \", over_38)\n\n38점보다 높게 나올 확률:  7.76885222819601e-11\n\n\n\n\n\n\n\nCovid‑19의 발병률은 1%라고 한다. 다음은 이번 코로나 사태로 인하여 코로나 의심 환자들 1,085명을 대상으로 슬통 회사의 “다잡아” 키트를 사용하여 양성 반응을 체크한 결과이다. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-같은 방법으로 500개의 𝑠2 들, 𝑠21, 𝑠22, …, 𝑠2 500 발생시킵니다.\n\n발생한 500개의 𝑠2 들 각각에 4.75를 곱하고, 그것들의 히스토그램을 그려보세요. (히스토그램을 그릴 때 probability = TRUE 옵션을 사용해서 그릴 것)\n위에서 그린 히스토그램에 자유도가 19인 카이제곱분포 확률밀도함수를 겹쳐그려보세요."
  },
  {
    "objectID": "posts/hw7/index.html#adp-표본점수",
    "href": "posts/hw7/index.html#adp-표본점수",
    "title": "LS 빅데이터 스쿨 Homework 7",
    "section": "ADP 표본점수",
    "text": "ADP 표본점수\n\n2022년에 실시 된 ADP 실기 시험의 통계파트 표준점수는 평균이 30, 표준편차가 5인 정규분포를 따른다고 한다.\n\n\n1) ADP 실기 시험의 통계파트 표준점수의 밀도함수를 그려보세요.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\nx = np.linspace(0, 60, 300)\ny = norm.pdf(x, loc=30, scale=5)\nplt.plot(x, y)\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n2) ADP 수험생을 임의로 1명을 선택하여 통계 점수를 조회했을때 45점 보다 높은 점수를 받았을 확률을 구하세요.\n\nover_45 = 1 - norm.cdf(45, 30, 5)\nprint(f\"45점 보다 높을 확률: \", round(over_45, 3))\n\n45점 보다 높을 확률:  0.001\n\n\n\n\n3) 슬통이는 상위 10%에 해당하는 점수를 얻었다고 한다면, 슬통이의 점수는 얼마인지 계산해보세요.\n\n슬통_score = norm.ppf(0.9, loc=30, scale=5)\nprint(f\"슬통이의 점수: \", round(슬통_score, 3))\n\n슬통이의 점수:  36.408\n\n\n\n\n4) 슬기로운 통계생활의 해당 회차 수강생은 16명이었다고 한다. 16명의 통계 파트 점수를 평균내었을 때, 이 평균값이 따르는 분포의 확률밀도 함수를 1번의 그래프와 겹쳐 그려보세요.\n\n# 1번 그래프\nx = np.linspace(0, 60, 300)\ny = norm.pdf(x, loc=30, scale=5)\nplt.plot(x, y)\n\n# 4번 그래프\ny2 = norm.pdf(x, loc=30, scale=5/np.sqrt(16))\nplt.plot(x, y2)\n\nplt.show()\nplt.clf()\n\n\n\n\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;\n\n\n\n\n5) 슬기로운 통계생활 ADP 반 수강생들의 통계점수를 평균내었다고 할 때, 이 값이 38점보다 높게 나올 확률을 구하세요.\n\nover_38 = 1 - norm.cdf(38, loc=30, scale=5/np.sqrt(16))\nprint(f\"38점보다 높게 나올 확률: \", over_38)\n\n38점보다 높게 나올 확률:  7.76885222819601e-11"
  },
  {
    "objectID": "posts/hw7/index.html#covid-19-발병률",
    "href": "posts/hw7/index.html#covid-19-발병률",
    "title": "LS 빅데이터 스쿨 Homework 7",
    "section": "Covid 19 발병률",
    "text": "Covid 19 발병률\n\nCovid‑19의 발병률은 1%라고 한다. 다음은 이번 코로나 사태로 인하여 코로나 의심 환자들 1,085명을 대상으로 슬통 회사의 “다잡아” 키트를 사용하여 양성 반응을 체크한 결과이다. \n\n\n1) 다잡아 키트가 코로나 바이러스에 걸린 사람을 양성으로 잡아낼 확률을 계산하세요.\n\nmat_kit = np.array([370, 10, 15, 690]).reshape(2,2)\nmat_kit\n\narray([[370,  10],\n       [ 15, 690]])\n\n\n\nprint(round(370/(370 + 15),3))\n\n0.961\n\n\n\n\n2) 슬통 회사에서 다잡아 키트를 사용해 양성으로 나온 사람이 실제로는 코로나 바이러스에 걸려있을 확률을 97%라며, 키트의 우수성을 주장했다. 이 주장이 옳지 않은 이유를 서술하세요.\n\nprint(f\"실제로는 0.96의 확률이 나온다. 이는 0.97의 확률보다 낮기에 키트의 우수성을 주장하기는 바람직하지 않다.\")\n\n실제로는 0.96의 확률이 나온다. 이는 0.97의 확률보다 낮기에 키트의 우수성을 주장하기는 바람직하지 않다.\n\n\n\n\n3) Covid‑19 발병률을 사용하여, 키트의 결과값이 양성으로 나온 사람이 실제로 코로나 바이러스에 걸려있을 확률을 구하세요.\n\nround((0.01 * (370 / 385) / (0.01 * (370 / 385) + (0.99 * (10 / 700)))), 3)\n\n0.405"
  },
  {
    "objectID": "posts/hw7/index.html#카이제곱분포와-표본분산",
    "href": "posts/hw7/index.html#카이제곱분포와-표본분산",
    "title": "LS 빅데이터 스쿨 Homework 7",
    "section": "카이제곱분포와 표본분산",
    "text": "카이제곱분포와 표본분산\n\n1) 자유도가 4인 카이제곱분포의 확률밀도함수를 그려보세요.\n\nfrom scipy.stats import chi2\n\nk = np.linspace(0, 40, 500)\ny = chi2.pdf(k, df=4)\nplt.plot(k,y)\nplt.show()\nplt.clf()\n\n\n\n\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;\n\n\n\n\n2) 다음의 확률을 구해보세요. 𝑃(3 ≤ 𝑋 ≤ 5)\n\nprint(f\"확률은 : \", round((chi2.cdf(5, df=4) - chi2.cdf(3, df=4)), 3))\n\n확률은 :  0.271\n\n\n\n\n3) 자유도가 4인 카이제곱분포에서 크기가 1000인 표본을 뽑은 후, 히스토그램을 그려보세요.\n\nx = chi2.rvs(df=4, size=1000)\nplt.hist(x)\nplt.show()\nplt.clf()\n\n\n\n\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;\n\n\n\n\n4) 자유도가 4인 카이제곱분포를 따르는 확률변수에서 나올 수 있는 값 중 상위 5%에 해당하는 값은 얼마인지 계산해보세요.\n\nchi2.ppf(0.95, df=4)\n\nnp.float64(9.487729036781154)\n\n\n\n\n5) 3번에서 뽑힌 표본값들 중 상위 5%에 위치한 표본의 값은 얼마인가요?\n\nnp.percentile(x, 95)\n\nnp.float64(9.13357496495028)\n\n\n\n\n6) 평균이 3, 표준편차가 2인 정규분포를 따르는 확률변수에서 크기가 20인 표본, 𝑥1, …, 𝑥20을 뽑은 후 표본분산을 계산한 것을 𝑠21이라 생각해보죠. 다음을 수행해보세요!\n\n같은 방법으로 500개의 𝑠2 들, 𝑠21, 𝑠22, …, 𝑠2 500 발생시킵니다.\n발생한 500개의 𝑠2 들 각각에 4.75를 곱하고, 그것들의 히스토그램을 그려보세요. (히스토그램을 그릴 때 probability = TRUE 옵션을 사용해서 그릴 것)\n위에서 그린 히스토그램에 자유도가 19인 카이제곱분포 확률밀도함수를 겹쳐그려보세요.\n\n\nn=20\nvar = []\n\nfor i in range(500):\n    x = norm.rvs(loc=3, scale=2, size=n)\n    var.append(np.var(x, ddof=1))\n\nscaled_var = np.array(var) * 4.75\n\nplt.hist(scaled_var, bins=50, density=True, color=\"blue\")\n\nk = np.linspace(0, max(scaled_var), 1000)\ny = chi2.pdf(k, df=19)\nplt.plot(k, y, color =\"red\")"
  },
  {
    "objectID": "docs/posts/교과서 챕터 8/index.html",
    "href": "docs/posts/교과서 챕터 8/index.html",
    "title": "로지스틱 회귀분석 문제세트",
    "section": "",
    "text": "종속변수:  백혈병 세포 관측 불가 여부 (REMISS), 1이면 관측 안됨을 의미\n\n\n\n\n독립변수:  골수의 세포성 (CELL)  골수편의 백혈구 비율 (SMEAR)  골수의 백혈병 세포 침투 비율 (INFIL)  골수 백혈병 세포의 라벨링 인덱스 (LI)  말초혈액의 백혈병 세포 수 (BLAST)  치료 시작 전 최고 체온 (TEMP)"
  },
  {
    "objectID": "docs/posts/교과서 챕터 8/index.html#로지스틱-회귀분석-문제세트",
    "href": "docs/posts/교과서 챕터 8/index.html#로지스틱-회귀분석-문제세트",
    "title": "로지스틱 회귀분석 문제세트",
    "section": "",
    "text": "종속변수:  백혈병 세포 관측 불가 여부 (REMISS), 1이면 관측 안됨을 의미\n\n\n\n\n독립변수:  골수의 세포성 (CELL)  골수편의 백혈구 비율 (SMEAR)  골수의 백혈병 세포 침투 비율 (INFIL)  골수 백혈병 세포의 라벨링 인덱스 (LI)  말초혈액의 백혈병 세포 수 (BLAST)  치료 시작 전 최고 체온 (TEMP)"
  },
  {
    "objectID": "docs/posts/교과서 챕터 8/index.html#문제-1.-데이터를-로드하고-로지스틱-회귀모델을-적합하고-회귀-표를-작성하세요.",
    "href": "docs/posts/교과서 챕터 8/index.html#문제-1.-데이터를-로드하고-로지스틱-회귀모델을-적합하고-회귀-표를-작성하세요.",
    "title": "로지스틱 회귀분석 문제세트",
    "section": "문제 1. 데이터를 로드하고, 로지스틱 회귀모델을 적합하고, 회귀 표를 작성하세요.",
    "text": "문제 1. 데이터를 로드하고, 로지스틱 회귀모델을 적합하고, 회귀 표를 작성하세요.\n\nimport pandas as pd\n\nimport os\ncwd = os.getcwd()\nparent_dir = os.path.dirname(cwd)\nos.chdir(parent_dir)\n\n# 데이터 로드\ndf = pd.read_csv(\"C:/Users/USER/Documents/LS빅데이터스쿨/mywebsite/posts/로지스틱 회귀분석 문제세트/leukemia_remission.txt\", sep='\\t')\ndf.head()\n\n\n\n\n\n\n\n\nREMISS\nCELL\nSMEAR\nINFIL\nLI\nBLAST\nTEMP\n\n\n\n\n0\n1\n0.8\n0.83\n0.66\n1.9\n1.10\n1.00\n\n\n1\n1\n0.9\n0.36\n0.32\n1.4\n0.74\n0.99\n\n\n2\n0\n0.8\n0.88\n0.70\n0.8\n0.18\n0.98\n\n\n3\n0\n1.0\n0.87\n0.87\n0.7\n1.05\n0.99\n\n\n4\n1\n0.9\n0.75\n0.68\n1.3\n0.52\n0.98\n\n\n\n\n\n\n\n\n# 로지스틱 회귀모델 적합\nimport statsmodels.api as sm\n\nmodel = sm.formula.logit(\"REMISS ~ CELL + SMEAR + INFIL + LI + BLAST + TEMP\", data=df).fit()\n\nprint(model.summary())\n\nOptimization terminated successfully.\n         Current function value: 0.399886\n         Iterations 10\n                           Logit Regression Results                           \n==============================================================================\nDep. Variable:                 REMISS   No. Observations:                   27\nModel:                          Logit   Df Residuals:                       20\nMethod:                           MLE   Df Model:                            6\nDate:                Tue, 10 Sep 2024   Pseudo R-squ.:                  0.3718\nTime:                        10:29:21   Log-Likelihood:                -10.797\nconverged:                       True   LL-Null:                       -17.186\nCovariance Type:            nonrobust   LLR p-value:                   0.04670\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     64.2581     74.965      0.857      0.391     -82.670     211.187\nCELL          30.8301     52.135      0.591      0.554     -71.353     133.013\nSMEAR         24.6863     61.526      0.401      0.688     -95.903     145.275\nINFIL        -24.9745     65.281     -0.383      0.702    -152.923     102.974\nLI             4.3605      2.658      1.641      0.101      -0.849       9.570\nBLAST         -0.0115      2.266     -0.005      0.996      -4.453       4.430\nTEMP        -100.1734     77.753     -1.288      0.198    -252.567      52.220\n==============================================================================\n\nPossibly complete quasi-separation: A fraction 0.11 of observations can be\nperfectly predicted. This might indicate that there is complete\nquasi-separation. In this case some parameters will not be identified."
  },
  {
    "objectID": "docs/posts/교과서 챕터 8/index.html#문제-2.-해당-모델은-통계적으로-유의한가요-그-이유를-검정통계량를-사용해서-설명하시오.",
    "href": "docs/posts/교과서 챕터 8/index.html#문제-2.-해당-모델은-통계적으로-유의한가요-그-이유를-검정통계량를-사용해서-설명하시오.",
    "title": "로지스틱 회귀분석 문제세트",
    "section": "문제 2. 해당 모델은 통계적으로 유의한가요? 그 이유를 검정통계량를 사용해서 설명하시오.",
    "text": "문제 2. 해당 모델은 통계적으로 유의한가요? 그 이유를 검정통계량를 사용해서 설명하시오.\n\n모델 전체 유의성: LLR p-value가 0.04670로, 귀무가설을 기각할 수 있으며, 모델이 통계적으로 유의하다고 볼 수 있다. \n\n\n그러나 개별 변수들 중에서는 LI 변수만 0.1 수준에서 약간의 유의미성을 보이며, 나머지 변수들은 유의수준 0.05에서 유의하지 않다."
  },
  {
    "objectID": "docs/posts/교과서 챕터 8/index.html#문제-3.-유의수준이-0.2를-기준으로-통계적으로-유의한-변수는-몇개이며-어느-변수-인가요",
    "href": "docs/posts/교과서 챕터 8/index.html#문제-3.-유의수준이-0.2를-기준으로-통계적으로-유의한-변수는-몇개이며-어느-변수-인가요",
    "title": "로지스틱 회귀분석 문제세트",
    "section": "문제 3. 유의수준이 0.2를 기준으로 통계적으로 유의한 변수는 몇개이며, 어느 변수 인가요?",
    "text": "문제 3. 유의수준이 0.2를 기준으로 통계적으로 유의한 변수는 몇개이며, 어느 변수 인가요?\n\n2개  LI: 0.101  TEMP: 0.198"
  },
  {
    "objectID": "docs/posts/교과서 챕터 8/index.html#문제-4.-다음-환자에-대한-오즈는-얼마인가요",
    "href": "docs/posts/교과서 챕터 8/index.html#문제-4.-다음-환자에-대한-오즈는-얼마인가요",
    "title": "로지스틱 회귀분석 문제세트",
    "section": "문제 4. 다음 환자에 대한 오즈는 얼마인가요?",
    "text": "문제 4. 다음 환자에 대한 오즈는 얼마인가요?\n\nCELL (골수의 세포성): 65%  SMEAR (골수편의 백혈구 비율): 45%  INFIL (골수의 백혈병 세포 침투 비율): 55%  LI (골수 백혈병 세포의 라벨링 인덱스): 1.2  BLAST (말초혈액의 백혈병 세포 수): 1.1세포/μL  TEMP (치료 시작 전 최고 체온): 0.9\n\n\n# odds = exp(64.2581 + 30.8301 * x1 +  24.6863 * x2 -24.9745 * x3 + 4.3605 * x4 -0.0115 * x5 -100.1734 * x6)\n\nimport numpy as np\nmy_odds = np.exp(64.2581 + 30.8301 * 0.65 +  24.6863 * 0.45 -24.9745 * 0.55 + 4.3605 * 1.2 -0.0115 * 1.1 -100.1734 * 1.0)\nprint(my_odds)\n\n1.70333068025198e-06"
  },
  {
    "objectID": "docs/posts/교과서 챕터 8/index.html#문제-5.-위-환자의-혈액에서-백혈병-세포가-관측되지-않은-확률은-얼마인가요",
    "href": "docs/posts/교과서 챕터 8/index.html#문제-5.-위-환자의-혈액에서-백혈병-세포가-관측되지-않은-확률은-얼마인가요",
    "title": "로지스틱 회귀분석 문제세트",
    "section": "문제 5. 위 환자의 혈액에서 백혈병 세포가 관측되지 않은 확률은 얼마인가요?",
    "text": "문제 5. 위 환자의 혈액에서 백혈병 세포가 관측되지 않은 확률은 얼마인가요?\n\np_hat = my_odds / (my_odds + 1)\nprint(p_hat)\n\n1.7033277789215156e-06"
  },
  {
    "objectID": "docs/posts/교과서 챕터 8/index.html#문제-6.-temp-변수의-계수는-얼마이며-해당-계수를-사용해서-temp-변수가-백혈병-치료에-대한-영향을-설명하시오.",
    "href": "docs/posts/교과서 챕터 8/index.html#문제-6.-temp-변수의-계수는-얼마이며-해당-계수를-사용해서-temp-변수가-백혈병-치료에-대한-영향을-설명하시오.",
    "title": "로지스틱 회귀분석 문제세트",
    "section": "문제 6. TEMP 변수의 계수는 얼마이며, 해당 계수를 사용해서 TEMP 변수가 백혈병 치료에 대한 영향을 설명하시오.",
    "text": "문제 6. TEMP 변수의 계수는 얼마이며, 해당 계수를 사용해서 TEMP 변수가 백혈병 치료에 대한 영향을 설명하시오.\n\n# TEMP 변수의 계수\ntemp_coef = -100.1734\n\n# TEMP 변수의 오즈비\ntemp_odds_ratio = np.exp(temp_coef)\nprint(f\"TEMP 변수의 오즈비: {temp_odds_ratio}\")\n\nTEMP 변수의 오즈비: 3.1278444454718357e-44\n\n\n\nTEMP 높을수록 백혈병 세포가 관측되지 않을 확률이 매우 낮아짐"
  },
  {
    "objectID": "docs/posts/교과서 챕터 8/index.html#문제-7.-cell-변수의-99-오즈비에-대한-신뢰구간을-구하시오.",
    "href": "docs/posts/교과서 챕터 8/index.html#문제-7.-cell-변수의-99-오즈비에-대한-신뢰구간을-구하시오.",
    "title": "로지스틱 회귀분석 문제세트",
    "section": "문제 7. CELL 변수의 99% 오즈비에 대한 신뢰구간을 구하시오.",
    "text": "문제 7. CELL 변수의 99% 오즈비에 대한 신뢰구간을 구하시오.\n\n# CELL 변수의 계수와 표준 오차\ncell_coef = 30.8301\ncell_std_err = 52.135\n\n# 99% 신뢰구간의 z-값 (양쪽 검정 기준)\nfrom scipy.stats import norm\nz_value = norm.ppf(0.995)\n\n# 신뢰구간 계산\nlower_bound = cell_coef - z_value * cell_std_err\nupper_bound = cell_coef + z_value * cell_std_err\n\n# 오즈비 계산\ncell_odds_ratio_lower = np.exp(lower_bound)\ncell_odds_ratio_upper = np.exp(upper_bound)\n\n# 결과 출력\nprint(f\"CELL 변수의 99% 오즈비에 대한 신뢰구간:\")\nprint(f\"Lower bound (99% CI): {cell_odds_ratio_lower}\")\nprint(f\"Upper bound (99% CI): {cell_odds_ratio_upper}\")\n\nCELL 변수의 99% 오즈비에 대한 신뢰구간:\nLower bound (99% CI): 1.1683218982002717e-45\nUpper bound (99% CI): 5.141881884993857e+71"
  },
  {
    "objectID": "docs/posts/교과서 챕터 8/index.html#문제-8.-주어진-데이터에-대하여-로지스틱-회귀-모델의-예측-확률을-구한-후-50-이상인-경우-1로-처리하여-혼동-행렬를-구하시오.",
    "href": "docs/posts/교과서 챕터 8/index.html#문제-8.-주어진-데이터에-대하여-로지스틱-회귀-모델의-예측-확률을-구한-후-50-이상인-경우-1로-처리하여-혼동-행렬를-구하시오.",
    "title": "로지스틱 회귀분석 문제세트",
    "section": "문제 8. 주어진 데이터에 대하여 로지스틱 회귀 모델의 예측 확률을 구한 후, 50% 이상인 경우 1로 처리하여, 혼동 행렬를 구하시오.",
    "text": "문제 8. 주어진 데이터에 대하여 로지스틱 회귀 모델의 예측 확률을 구한 후, 50% 이상인 경우 1로 처리하여, 혼동 행렬를 구하시오.\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n\n# 예측 확률 구하기\npred_probs = model.predict(df)\n\n# 50% 기준으로 예측값을 이진 값으로 변환\npredicted_classes = np.where(pred_probs &gt;= 0.5, 1, 0)\n\n# 실제값 (종속변수)\nactual_classes = df['REMISS']\n\n# 혼동 행렬 구하기\nconf_matrix = confusion_matrix(actual_classes, predicted_classes)\n\nprint(\"혼동 행렬:\")\nprint(conf_matrix)\n\n혼동 행렬:\n[[15  3]\n [ 4  5]]"
  },
  {
    "objectID": "docs/posts/교과서 챕터 8/index.html#문제-9.-해당-모델의-accuracy는-얼마인가요",
    "href": "docs/posts/교과서 챕터 8/index.html#문제-9.-해당-모델의-accuracy는-얼마인가요",
    "title": "로지스틱 회귀분석 문제세트",
    "section": "문제 9. 해당 모델의 Accuracy는 얼마인가요?",
    "text": "문제 9. 해당 모델의 Accuracy는 얼마인가요?\n\n# Accuracy 계산\naccuracy = accuracy_score(actual_classes, predicted_classes)\nprint(f\"모델의 Accuracy: {accuracy}\")\n\n모델의 Accuracy: 0.7407407407407407"
  },
  {
    "objectID": "docs/posts/교과서 챕터 8/index.html#문제-10.-해당-모델의-f1-score를-구하세요.",
    "href": "docs/posts/교과서 챕터 8/index.html#문제-10.-해당-모델의-f1-score를-구하세요.",
    "title": "로지스틱 회귀분석 문제세트",
    "section": "문제 10. 해당 모델의 F1 Score를 구하세요.",
    "text": "문제 10. 해당 모델의 F1 Score를 구하세요.\n\nf1 = f1_score(actual_classes, predicted_classes)\nprint(f\"모델의 F1 Score: {f1}\")\n\n모델의 F1 Score: 0.5882352941176471\n\n\n\n\n\n\n\n\n\nPlease enable JavaScript to view the comments powered by Disqus."
  },
  {
    "objectID": "posts/로지스틱 회귀분석 문제세트/index.html",
    "href": "posts/로지스틱 회귀분석 문제세트/index.html",
    "title": "로지스틱 회귀분석 문제세트",
    "section": "",
    "text": "종속변수:  백혈병 세포 관측 불가 여부 (REMISS), 1이면 관측 안됨을 의미\n\n\n\n\n독립변수:  골수의 세포성 (CELL)  골수편의 백혈구 비율 (SMEAR)  골수의 백혈병 세포 침투 비율 (INFIL)  골수 백혈병 세포의 라벨링 인덱스 (LI)  말초혈액의 백혈병 세포 수 (BLAST)  치료 시작 전 최고 체온 (TEMP)"
  },
  {
    "objectID": "posts/로지스틱 회귀분석 문제세트/index.html#로지스틱-회귀분석-문제세트",
    "href": "posts/로지스틱 회귀분석 문제세트/index.html#로지스틱-회귀분석-문제세트",
    "title": "로지스틱 회귀분석 문제세트",
    "section": "",
    "text": "종속변수:  백혈병 세포 관측 불가 여부 (REMISS), 1이면 관측 안됨을 의미\n\n\n\n\n독립변수:  골수의 세포성 (CELL)  골수편의 백혈구 비율 (SMEAR)  골수의 백혈병 세포 침투 비율 (INFIL)  골수 백혈병 세포의 라벨링 인덱스 (LI)  말초혈액의 백혈병 세포 수 (BLAST)  치료 시작 전 최고 체온 (TEMP)"
  },
  {
    "objectID": "posts/로지스틱 회귀분석 문제세트/index.html#문제-1.-데이터를-로드하고-로지스틱-회귀모델을-적합하고-회귀-표를-작성하세요.",
    "href": "posts/로지스틱 회귀분석 문제세트/index.html#문제-1.-데이터를-로드하고-로지스틱-회귀모델을-적합하고-회귀-표를-작성하세요.",
    "title": "로지스틱 회귀분석 문제세트",
    "section": "문제 1. 데이터를 로드하고, 로지스틱 회귀모델을 적합하고, 회귀 표를 작성하세요.",
    "text": "문제 1. 데이터를 로드하고, 로지스틱 회귀모델을 적합하고, 회귀 표를 작성하세요.\n\nimport pandas as pd\n\nimport os\ncwd = os.getcwd()\nparent_dir = os.path.dirname(cwd)\nos.chdir(parent_dir)\n\n# 데이터 로드\ndf = pd.read_csv(\"C:/Users/USER/Documents/LS빅데이터스쿨/mywebsite/posts/로지스틱 회귀분석 문제세트/leukemia_remission.txt\", sep='\\t')\ndf.head()\n\n\n\n\n\n\n\n\nREMISS\nCELL\nSMEAR\nINFIL\nLI\nBLAST\nTEMP\n\n\n\n\n0\n1\n0.8\n0.83\n0.66\n1.9\n1.10\n1.00\n\n\n1\n1\n0.9\n0.36\n0.32\n1.4\n0.74\n0.99\n\n\n2\n0\n0.8\n0.88\n0.70\n0.8\n0.18\n0.98\n\n\n3\n0\n1.0\n0.87\n0.87\n0.7\n1.05\n0.99\n\n\n4\n1\n0.9\n0.75\n0.68\n1.3\n0.52\n0.98\n\n\n\n\n\n\n\n\n# 로지스틱 회귀모델 적합\nimport statsmodels.api as sm\n\nmodel = sm.formula.logit(\"REMISS ~ CELL + SMEAR + INFIL + LI + BLAST + TEMP\", data=df).fit()\n\nprint(model.summary())\n\nOptimization terminated successfully.\n         Current function value: 0.399886\n         Iterations 10\n                           Logit Regression Results                           \n==============================================================================\nDep. Variable:                 REMISS   No. Observations:                   27\nModel:                          Logit   Df Residuals:                       20\nMethod:                           MLE   Df Model:                            6\nDate:                Tue, 10 Sep 2024   Pseudo R-squ.:                  0.3718\nTime:                        10:38:34   Log-Likelihood:                -10.797\nconverged:                       True   LL-Null:                       -17.186\nCovariance Type:            nonrobust   LLR p-value:                   0.04670\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     64.2581     74.965      0.857      0.391     -82.670     211.187\nCELL          30.8301     52.135      0.591      0.554     -71.353     133.013\nSMEAR         24.6863     61.526      0.401      0.688     -95.903     145.275\nINFIL        -24.9745     65.281     -0.383      0.702    -152.923     102.974\nLI             4.3605      2.658      1.641      0.101      -0.849       9.570\nBLAST         -0.0115      2.266     -0.005      0.996      -4.453       4.430\nTEMP        -100.1734     77.753     -1.288      0.198    -252.567      52.220\n==============================================================================\n\nPossibly complete quasi-separation: A fraction 0.11 of observations can be\nperfectly predicted. This might indicate that there is complete\nquasi-separation. In this case some parameters will not be identified."
  },
  {
    "objectID": "posts/로지스틱 회귀분석 문제세트/index.html#문제-2.-해당-모델은-통계적으로-유의한가요-그-이유를-검정통계량를-사용해서-설명하시오.",
    "href": "posts/로지스틱 회귀분석 문제세트/index.html#문제-2.-해당-모델은-통계적으로-유의한가요-그-이유를-검정통계량를-사용해서-설명하시오.",
    "title": "로지스틱 회귀분석 문제세트",
    "section": "문제 2. 해당 모델은 통계적으로 유의한가요? 그 이유를 검정통계량를 사용해서 설명하시오.",
    "text": "문제 2. 해당 모델은 통계적으로 유의한가요? 그 이유를 검정통계량를 사용해서 설명하시오.\n\n모델 전체 유의성: LLR p-value가 0.04670로, 귀무가설을 기각할 수 있으며, 모델이 통계적으로 유의하다고 볼 수 있다. \n\n\n그러나 개별 변수들 중에서는 LI 변수만 0.1 수준에서 약간의 유의미성을 보이며, 나머지 변수들은 유의수준 0.05에서 유의하지 않다."
  },
  {
    "objectID": "posts/로지스틱 회귀분석 문제세트/index.html#문제-3.-유의수준이-0.2를-기준으로-통계적으로-유의한-변수는-몇개이며-어느-변수-인가요",
    "href": "posts/로지스틱 회귀분석 문제세트/index.html#문제-3.-유의수준이-0.2를-기준으로-통계적으로-유의한-변수는-몇개이며-어느-변수-인가요",
    "title": "로지스틱 회귀분석 문제세트",
    "section": "문제 3. 유의수준이 0.2를 기준으로 통계적으로 유의한 변수는 몇개이며, 어느 변수 인가요?",
    "text": "문제 3. 유의수준이 0.2를 기준으로 통계적으로 유의한 변수는 몇개이며, 어느 변수 인가요?\n\n2개  LI: 0.101  TEMP: 0.198"
  },
  {
    "objectID": "posts/로지스틱 회귀분석 문제세트/index.html#문제-4.-다음-환자에-대한-오즈는-얼마인가요",
    "href": "posts/로지스틱 회귀분석 문제세트/index.html#문제-4.-다음-환자에-대한-오즈는-얼마인가요",
    "title": "로지스틱 회귀분석 문제세트",
    "section": "문제 4. 다음 환자에 대한 오즈는 얼마인가요?",
    "text": "문제 4. 다음 환자에 대한 오즈는 얼마인가요?\n\nCELL (골수의 세포성): 65%  SMEAR (골수편의 백혈구 비율): 45%  INFIL (골수의 백혈병 세포 침투 비율): 55%  LI (골수 백혈병 세포의 라벨링 인덱스): 1.2  BLAST (말초혈액의 백혈병 세포 수): 1.1세포/μL  TEMP (치료 시작 전 최고 체온): 0.9\n\n\n# odds = exp(64.2581 + 30.8301 * x1 +  24.6863 * x2 -24.9745 * x3 + 4.3605 * x4 -0.0115 * x5 -100.1734 * x6)\n\nimport numpy as np\nmy_odds = np.exp(64.2581 + 30.8301 * 0.65 +  24.6863 * 0.45 -24.9745 * 0.55 + 4.3605 * 1.2 -0.0115 * 1.1 -100.1734 * 1.0)\nprint(my_odds)\n\n1.70333068025198e-06"
  },
  {
    "objectID": "posts/로지스틱 회귀분석 문제세트/index.html#문제-5.-위-환자의-혈액에서-백혈병-세포가-관측되지-않은-확률은-얼마인가요",
    "href": "posts/로지스틱 회귀분석 문제세트/index.html#문제-5.-위-환자의-혈액에서-백혈병-세포가-관측되지-않은-확률은-얼마인가요",
    "title": "로지스틱 회귀분석 문제세트",
    "section": "문제 5. 위 환자의 혈액에서 백혈병 세포가 관측되지 않은 확률은 얼마인가요?",
    "text": "문제 5. 위 환자의 혈액에서 백혈병 세포가 관측되지 않은 확률은 얼마인가요?\n\np_hat = my_odds / (my_odds + 1)\nprint(p_hat)\n\n1.7033277789215156e-06"
  },
  {
    "objectID": "posts/로지스틱 회귀분석 문제세트/index.html#문제-6.-temp-변수의-계수는-얼마이며-해당-계수를-사용해서-temp-변수가-백혈병-치료에-대한-영향을-설명하시오.",
    "href": "posts/로지스틱 회귀분석 문제세트/index.html#문제-6.-temp-변수의-계수는-얼마이며-해당-계수를-사용해서-temp-변수가-백혈병-치료에-대한-영향을-설명하시오.",
    "title": "로지스틱 회귀분석 문제세트",
    "section": "문제 6. TEMP 변수의 계수는 얼마이며, 해당 계수를 사용해서 TEMP 변수가 백혈병 치료에 대한 영향을 설명하시오.",
    "text": "문제 6. TEMP 변수의 계수는 얼마이며, 해당 계수를 사용해서 TEMP 변수가 백혈병 치료에 대한 영향을 설명하시오.\n\n# TEMP 변수의 계수\ntemp_coef = -100.1734\n\n# TEMP 변수의 오즈비\ntemp_odds_ratio = np.exp(temp_coef)\nprint(f\"TEMP 변수의 오즈비: {temp_odds_ratio}\")\n\nTEMP 변수의 오즈비: 3.1278444454718357e-44\n\n\n\nTEMP 높을수록 백혈병 세포가 관측되지 않을 확률이 매우 낮아짐"
  },
  {
    "objectID": "posts/로지스틱 회귀분석 문제세트/index.html#문제-7.-cell-변수의-99-오즈비에-대한-신뢰구간을-구하시오.",
    "href": "posts/로지스틱 회귀분석 문제세트/index.html#문제-7.-cell-변수의-99-오즈비에-대한-신뢰구간을-구하시오.",
    "title": "로지스틱 회귀분석 문제세트",
    "section": "문제 7. CELL 변수의 99% 오즈비에 대한 신뢰구간을 구하시오.",
    "text": "문제 7. CELL 변수의 99% 오즈비에 대한 신뢰구간을 구하시오.\n\n# CELL 변수의 계수와 표준 오차\ncell_coef = 30.8301\ncell_std_err = 52.135\n\n# 99% 신뢰구간의 z-값 (양쪽 검정 기준)\nfrom scipy.stats import norm\nz_value = norm.ppf(0.995)\n\n# 신뢰구간 계산\nlower_bound = cell_coef - z_value * cell_std_err\nupper_bound = cell_coef + z_value * cell_std_err\n\n# 오즈비 계산\ncell_odds_ratio_lower = np.exp(lower_bound)\ncell_odds_ratio_upper = np.exp(upper_bound)\n\n# 결과 출력\nprint(f\"CELL 변수의 99% 오즈비에 대한 신뢰구간:\")\nprint(f\"Lower bound (99% CI): {cell_odds_ratio_lower}\")\nprint(f\"Upper bound (99% CI): {cell_odds_ratio_upper}\")\n\nCELL 변수의 99% 오즈비에 대한 신뢰구간:\nLower bound (99% CI): 1.1683218982002717e-45\nUpper bound (99% CI): 5.141881884993857e+71"
  },
  {
    "objectID": "posts/로지스틱 회귀분석 문제세트/index.html#문제-8.-주어진-데이터에-대하여-로지스틱-회귀-모델의-예측-확률을-구한-후-50-이상인-경우-1로-처리하여-혼동-행렬를-구하시오.",
    "href": "posts/로지스틱 회귀분석 문제세트/index.html#문제-8.-주어진-데이터에-대하여-로지스틱-회귀-모델의-예측-확률을-구한-후-50-이상인-경우-1로-처리하여-혼동-행렬를-구하시오.",
    "title": "로지스틱 회귀분석 문제세트",
    "section": "문제 8. 주어진 데이터에 대하여 로지스틱 회귀 모델의 예측 확률을 구한 후, 50% 이상인 경우 1로 처리하여, 혼동 행렬를 구하시오.",
    "text": "문제 8. 주어진 데이터에 대하여 로지스틱 회귀 모델의 예측 확률을 구한 후, 50% 이상인 경우 1로 처리하여, 혼동 행렬를 구하시오.\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# 예측 확률 구하기\npred_probs = model.predict(df)\n\n# 50% 기준으로 예측값을 이진 값으로 변환\npredicted_classes = np.where(pred_probs &gt;= 0.5, 1, 0)\n\n# 실제값 (종속변수)\nactual_classes = df['REMISS']\n\n# 혼동 행렬 구하기\nconf_matrix = confusion_matrix(actual_classes, predicted_classes)\n\nprint(\"혼동 행렬:\")\nprint(conf_matrix)\n\n# 혼동행렬 시각화\nplt.figure(figsize=(6, 4))\nsns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()\n\n혼동 행렬:\n[[15  3]\n [ 4  5]]"
  },
  {
    "objectID": "posts/로지스틱 회귀분석 문제세트/index.html#문제-9.-해당-모델의-accuracy는-얼마인가요",
    "href": "posts/로지스틱 회귀분석 문제세트/index.html#문제-9.-해당-모델의-accuracy는-얼마인가요",
    "title": "로지스틱 회귀분석 문제세트",
    "section": "문제 9. 해당 모델의 Accuracy는 얼마인가요?",
    "text": "문제 9. 해당 모델의 Accuracy는 얼마인가요?\n\n# Accuracy 계산\naccuracy = accuracy_score(actual_classes, predicted_classes)\nprint(f\"모델의 Accuracy: {accuracy}\")\n\n모델의 Accuracy: 0.7407407407407407"
  },
  {
    "objectID": "posts/로지스틱 회귀분석 문제세트/index.html#문제-10.-해당-모델의-f1-score를-구하세요.",
    "href": "posts/로지스틱 회귀분석 문제세트/index.html#문제-10.-해당-모델의-f1-score를-구하세요.",
    "title": "로지스틱 회귀분석 문제세트",
    "section": "문제 10. 해당 모델의 F1 Score를 구하세요.",
    "text": "문제 10. 해당 모델의 F1 Score를 구하세요.\n\nf1 = f1_score(actual_classes, predicted_classes)\nprint(f\"모델의 F1 Score: {f1}\")\n\n모델의 F1 Score: 0.5882352941176471\n\n\n\n\n\n\n\n\n\nPlease enable JavaScript to view the comments powered by Disqus."
  }
]